{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "DDPG.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OttoJursch/DRL_robot_exploration/blob/master/DDPG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJBqQwnOM5hX",
        "outputId": "04a8bdc7-b07d-4e56-a125-f9a8f6b09140"
      },
      "source": [
        "#Install pybind11\n",
        "!git clone https://github.com/pybind/pybind11.git\n",
        "!cd pybind11 && mkdir build && cd build && cmake .. && make install"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pybind11'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 13942 (delta 1), reused 0 (delta 0), pack-reused 13933\u001b[K\n",
            "Receiving objects: 100% (13942/13942), 5.40 MiB | 24.81 MiB/s, done.\n",
            "Resolving deltas: 100% (9486/9486), done.\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- pybind11 v2.6.2 dev1\n",
            "-- CMake 3.12.0\n",
            "-- Found PythonInterp: /usr/bin/python3.6 (found version \"3.6.9\") \n",
            "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so\n",
            "-- PYTHON 3.6.9\n",
            "-- Performing Test HAS_FLTO\n",
            "-- Performing Test HAS_FLTO - Success\n",
            "-- pybind11::lto enabled\n",
            "-- pybind11::thin_lto enabled\n",
            "-- Setting tests build type to MinSizeRel as none was specified\n",
            "-- Building tests WITHOUT Eigen, use -DDOWNLOAD_EIGEN on CMake 3.11+ to download\n",
            "-- Boost version: 1.65.1\n",
            "-- Found pytest 3.6.4\n",
            "-- Catch not detected. Interpreter tests will be skipped. Install Catch headers manually or use `cmake -DDOWNLOAD_CATCH=ON` to fetch them automatically.\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/pybind11/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target pybind11_cross_module_tests\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_cross_module_tests.dir/pybind11_cross_module_tests.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32m\u001b[1mLinking CXX shared module pybind11_cross_module_tests.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[  4%] Built target pybind11_cross_module_tests\n",
            "\u001b[35m\u001b[1mScanning dependencies of target pybind11_tests\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/pybind11_tests.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_async.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_buffers.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_builtin_casters.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_call_policies.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_callbacks.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_chrono.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_class.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_constants_and_functions.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_copy_move.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_custom_type_casters.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_docstring_options.cpp.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_enum.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_eval.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_exceptions.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_factory_constructors.cpp.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_gil_scoped.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_iostream.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_kwargs_and_defaults.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_local_bindings.cpp.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_methods_and_attributes.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_modules.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_multiple_inheritance.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_array.cpp.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_dtypes.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_vectorize.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_opaque_types.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_operator_overloading.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_pickling.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_pytypes.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_sequences_and_iterators.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_smart_ptr.cpp.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_stl.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_stl_binders.cpp.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_tagbased_polymorphic.cpp.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_union.cpp.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_virtual_functions.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX shared module pybind11_tests.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "------ pybind11_tests.cpython-36m-x86_64-linux-gnu.so file size: 2032248\n",
            "[ 95%] Built target pybind11_tests\n",
            "\u001b[35m\u001b[1mScanning dependencies of target cross_module_gil_utils\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object tests/CMakeFiles/cross_module_gil_utils.dir/cross_module_gil_utils.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared module cross_module_gil_utils.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[100%] Built target cross_module_gil_utils\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"MinSizeRel\"\n",
            "-- Installing: /usr/local/include/pybind11\n",
            "-- Installing: /usr/local/include/pybind11/operators.h\n",
            "-- Installing: /usr/local/include/pybind11/stl_bind.h\n",
            "-- Installing: /usr/local/include/pybind11/numpy.h\n",
            "-- Installing: /usr/local/include/pybind11/cast.h\n",
            "-- Installing: /usr/local/include/pybind11/options.h\n",
            "-- Installing: /usr/local/include/pybind11/functional.h\n",
            "-- Installing: /usr/local/include/pybind11/iostream.h\n",
            "-- Installing: /usr/local/include/pybind11/eval.h\n",
            "-- Installing: /usr/local/include/pybind11/stl.h\n",
            "-- Installing: /usr/local/include/pybind11/detail\n",
            "-- Installing: /usr/local/include/pybind11/detail/class.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/typeid.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/common.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/descr.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/internals.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/init.h\n",
            "-- Installing: /usr/local/include/pybind11/common.h\n",
            "-- Installing: /usr/local/include/pybind11/attr.h\n",
            "-- Installing: /usr/local/include/pybind11/complex.h\n",
            "-- Installing: /usr/local/include/pybind11/pybind11.h\n",
            "-- Installing: /usr/local/include/pybind11/buffer_info.h\n",
            "-- Installing: /usr/local/include/pybind11/pytypes.h\n",
            "-- Installing: /usr/local/include/pybind11/embed.h\n",
            "-- Installing: /usr/local/include/pybind11/eigen.h\n",
            "-- Installing: /usr/local/include/pybind11/chrono.h\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Config.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11ConfigVersion.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/FindPythonLibsNew.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Common.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Tools.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11NewTools.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Targets.cmake\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwAQeZFoM8IL",
        "outputId": "b2ecb398-e690-48f3-ee54-e62cbcf169c6"
      },
      "source": [
        "#Install Eigen\n",
        "!apt install libeigen3-dev\n",
        "!ln -sf /usr/include/eigen3/Eigen /usr/include/Eigen"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libeigen3-doc libmrpt-dev\n",
            "The following NEW packages will be installed:\n",
            "  libeigen3-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 810 kB of archives.\n",
            "After this operation, 7,128 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libeigen3-dev all 3.3.4-4 [810 kB]\n",
            "Fetched 810 kB in 1s (1,499 kB/s)\n",
            "Selecting previously unselected package libeigen3-dev.\n",
            "(Reading database ... 144865 files and directories currently installed.)\n",
            "Preparing to unpack .../libeigen3-dev_3.3.4-4_all.deb ...\n",
            "Unpacking libeigen3-dev (3.3.4-4) ...\n",
            "Setting up libeigen3-dev (3.3.4-4) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wohYNJjVNAs3",
        "outputId": "eb130439-c614-4c65-bf31-dc917cb58362"
      },
      "source": [
        "# Install dependencies on colab\n",
        "!git clone https://github.com/OttoJursch/DRL_robot_exploration.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DRL_robot_exploration'...\n",
            "remote: Enumerating objects: 209, done.\u001b[K\n",
            "remote: Counting objects: 100% (209/209), done.\u001b[K\n",
            "remote: Compressing objects: 100% (172/172), done.\u001b[K\n",
            "remote: Total 11258 (delta 126), reused 74 (delta 36), pack-reused 11049\u001b[K\n",
            "Receiving objects: 100% (11258/11258), 287.58 MiB | 35.60 MiB/s, done.\n",
            "Resolving deltas: 100% (219/219), done.\n",
            "Checking out files: 100% (10922/10922), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdbx9dj_zRQ_",
        "outputId": "d76681c9-491d-4c12-fa39-8860479993a6"
      },
      "source": [
        "!#Build the C++/pybind stuff\n",
        "!rm -rf DRL_robot_exploration/build\n",
        "!cd DRL_robot_exploration && mkdir build && cd build && cmake .. && make"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found PythonInterp: /usr/bin/python3 (found version \"3.6.9\") \n",
            "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so\n",
            "-- Performing Test HAS_FLTO\n",
            "-- Performing Test HAS_FLTO - Success\n",
            "-- Found pybind11: /usr/local/include (found version \"2.6.2\" dev1)\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/DRL_robot_exploration/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target astar\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/astar.dir/src/astar.cpp.o\u001b[0m\n",
            "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/astar.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* pybind11_init()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/astar.cpp:140:32:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kpybind11::module_::module_(const char*, const char*)\u001b[m\u001b[K’ is deprecated: Use PYBIND11_MODULE or module_::create_extension_module instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   py::module m(\"astar\", \"astar\"\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/include/pybind11/numpy.h:12:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/include/pybind11/eigen.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/DRL_robot_exploration/src/astar.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/include/pybind11/pybind11.h:897:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "     explicit \u001b[01;36m\u001b[Kmodule_\u001b[m\u001b[K(const char *name, const char *doc = nullptr) {\n",
            "              \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module astar.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[ 50%] Built target astar\n",
            "\u001b[35m\u001b[1mScanning dependencies of target inverse_sensor_model\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/inverse_sensor_model.dir/src/inverse_sensor_model.cpp.o\u001b[0m\n",
            "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/inverse_sensor_model.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* pybind11_init()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/inverse_sensor_model.cpp:64:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kpybind11::module_::module_(const char*, const char*)\u001b[m\u001b[K’ is deprecated: Use PYBIND11_MODULE or module_::create_extension_module instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   py::module m(\"inverse_sensor_model\", \"inverse_sensor_model\"\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/include/pybind11/numpy.h:12:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/include/pybind11/eigen.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/DRL_robot_exploration/src/inverse_sensor_model.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/include/pybind11/pybind11.h:897:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "     explicit \u001b[01;36m\u001b[Kmodule_\u001b[m\u001b[K(const char *name, const char *doc = nullptr) {\n",
            "              \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared module inverse_sensor_model.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[100%] Built target inverse_sensor_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH4Hccvf4Pdh",
        "outputId": "89b1e254-9904-4bf7-8984-99c3b809a8f7"
      },
      "source": [
        "!cd DRL_robot_exploration && git pull"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5BsFx_f9ONI"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "class PaperRewardFunction:\n",
        "    '''\n",
        "    Reward function from the paper\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def get_reward(self, robot_position, old_op_map, op_map, coll_index):\n",
        "        '''\n",
        "        Takes in map before step and map after step. Measures effect of sensor\n",
        "        input from last step\n",
        "        '''\n",
        "        if not coll_index:\n",
        "            reward = float(\n",
        "                np.size(np.where(op_map == 255)) - np.size(np.where(old_op_map == 255))) / 14000\n",
        "            if reward > 1:\n",
        "                reward = 1\n",
        "        else:\n",
        "            reward = -300\n",
        "        return reward\n",
        "\n",
        "\n",
        "class FrontierRewardFunction:\n",
        "    def __init__(self, reward_scale):\n",
        "        self.reward_scale = reward_scale\n",
        "        self.paper_reward = PaperRewardFunction()\n",
        "\n",
        "    def frontiers(self, op_map, map_size, points):\n",
        "        y_len = map_size[0]\n",
        "        x_len = map_size[1]\n",
        "        mapping = op_map.copy()\n",
        "        # 0-1 unknown area map\n",
        "        mapping = (mapping == 127) * 1\n",
        "        mapping = np.lib.pad(mapping, ((1, 1), (1, 1)),\n",
        "                             'constant',\n",
        "                             constant_values=0)\n",
        "        fro_map = mapping[2:][:, 1:x_len + 1] + mapping[:y_len][:, 1:x_len + 1] + mapping[1:y_len + 1][:, 2:] + \\\n",
        "                  mapping[1:y_len + 1][:, :x_len] + mapping[:y_len][:, 2:] + mapping[2:][:, :x_len] + mapping[2:][:,\n",
        "                                                                                                      2:] + \\\n",
        "                  mapping[:y_len][:, :x_len]\n",
        "\n",
        "        ind_free = np.where(op_map.ravel(order='F') == 255)[0]\n",
        "        ind_fron_1 = np.where(1 < fro_map.ravel(order='F'))[0]\n",
        "        ind_fron_2 = np.where(fro_map.ravel(order='F') < 8)[0]\n",
        "        ind_fron = np.intersect1d(ind_fron_1, ind_fron_2)\n",
        "        ind_to = np.intersect1d(ind_free, ind_fron)\n",
        "        f = points[ind_to]\n",
        "        f = f.astype(int)\n",
        "        return f\n",
        "\n",
        "    def map_points(self, map_glo):\n",
        "        map_x = map_glo.shape[1]\n",
        "        map_y = map_glo.shape[0]\n",
        "        x = np.linspace(0, map_x - 1, map_x)\n",
        "        y = np.linspace(0, map_y - 1, map_y)\n",
        "        t1, t2 = np.meshgrid(x, y)\n",
        "        points = np.vstack([t1.T.ravel(), t2.T.ravel()]).T\n",
        "        return points\n",
        "\n",
        "    def get_reward(self, robot_pos, old_op_map, op_map, coll_index):\n",
        "        paper_reward = self.paper_reward.get_reward(robot_pos, old_op_map,\n",
        "                                                    op_map, coll_index)\n",
        "\n",
        "        #If there was a collision return the collision reward\n",
        "        if coll_index:\n",
        "            return paper_reward\n",
        "\n",
        "        frontiers = np.array(\n",
        "            self.frontiers(op_map, op_map.shape, self.map_points(op_map)))\n",
        "\n",
        "        min_frontier_dist = -np.min(np.linalg.norm(robot_pos - frontiers, axis=1))\n",
        "        return self.reward_scale * min_frontier_dist + paper_reward\n",
        "\n",
        "sqrt2 = 2**0.5 +0.1\n",
        "class PolarActionSpace:\n",
        "    '''\n",
        "    Action space is polar representation of vector robot should take from its\n",
        "    current position\n",
        "\n",
        "    This class will take that and add it to the current robot position to get \n",
        "    '''\n",
        "    def __init__(self, min_travel, max_travel):\n",
        "        self.max_distance = max_travel\n",
        "        self.min_travel = min_travel\n",
        "\n",
        "    def get_action(self, action_polar_coords, robot_position):\n",
        "        angle = action_polar_coords[0] * (2 * np.pi)\n",
        "        dist = action_polar_coords[1] * (self.max_distance - self.min_travel) + self.min_travel\n",
        "        dx = dist * np.sin(angle)\n",
        "        dy = dist * np.cos(angle)\n",
        "\n",
        "        return np.array([dx, dy])\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l08KzoEf_xt3"
      },
      "source": [
        "from scipy import spatial\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import numpy.ma as ma\n",
        "import time\n",
        "import sys\n",
        "from scipy import ndimage\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sys.path.append('DRL_robot_exploration')\n",
        "from DRL_robot_exploration.build.inverse_sensor_model import *\n",
        "from DRL_robot_exploration.build.astar import *\n",
        "from random import shuffle\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "class Robot:\n",
        "    def __init__(self,\n",
        "                 index_map,\n",
        "                 train,\n",
        "                 plot,\n",
        "                 root_dir,\n",
        "                 action_space,\n",
        "                 reward_function,\n",
        "                 do_rescue,\n",
        "                 shuffle=True):\n",
        "        self.mode = train\n",
        "        self.action_space = action_space\n",
        "        self.plot = plot\n",
        "        self.root_dir = root_dir\n",
        "        self.index_map = index_map\n",
        "        self.do_rescue = do_rescue\n",
        "        self.reward_function = reward_function\n",
        "        self.reset(index_map, shuffle)\n",
        "\n",
        "    def reset(self, index_map=None, do_shuffle=True):\n",
        "        if self.mode:\n",
        "            self.map_dir = os.path.join(self.root_dir, 'train')\n",
        "        else:\n",
        "            self.map_dir = os.path.join(self.root_dir, 'test')\n",
        "        self.map_list = os.listdir(self.map_dir)\n",
        "        self.map_number = np.size(self.map_list)\n",
        "        if self.mode and do_shuffle:\n",
        "            shuffle(self.map_list)\n",
        "        if index_map is None:\n",
        "            index_map = random.choice(range(len(self.map_list)))\n",
        "        self.li_map = index_map\n",
        "        self.global_map, self.robot_position = self.map_setup(\n",
        "            self.map_dir + '/' + self.map_list[self.li_map])\n",
        "        self.op_map = np.ones(self.global_map.shape) * 127\n",
        "        self.map_size = np.shape(self.global_map)\n",
        "        self.finish_percent = 0.985\n",
        "        self.resolution = 1\n",
        "        self.sensor_range = 80\n",
        "        self.old_position = np.zeros([2])\n",
        "        self.old_op_map = np.empty([0])\n",
        "        #current_dir = os.path.dirname(os.path.realpath(__file__))\n",
        "        self.t = self.map_points(self.global_map)\n",
        "        self.free_tree = spatial.KDTree(\n",
        "            self.free_points(self.global_map).tolist())\n",
        "        self.robot_size = 6\n",
        "        self.local_size = 40\n",
        "        if self.plot:\n",
        "            self.xPoint = np.array([self.robot_position[0]])\n",
        "            self.yPoint = np.array([self.robot_position[1]])\n",
        "            self.x2frontier = np.empty([0])\n",
        "            self.y2frontier = np.empty([0])\n",
        "\n",
        "\n",
        "        return self.begin(), self.robot_position\n",
        "\n",
        "    def begin(self):\n",
        "        self.op_map = self.inverse_sensor(self.robot_position,\n",
        "                                          self.sensor_range, self.op_map,\n",
        "                                          self.global_map)\n",
        "        step_map = self.robot_model(self.robot_position, self.robot_size,\n",
        "                                    self.t, self.op_map)\n",
        "        map_local = self.local_map(self.robot_position, step_map,\n",
        "                                   self.map_size,\n",
        "                                   self.sensor_range + self.local_size)\n",
        "        if self.plot:\n",
        "            self.plot_env()\n",
        "        return self.op_map\n",
        "\n",
        "    def step(self, action_index):\n",
        "        terminal = False\n",
        "        complete = False\n",
        "        new_location = False\n",
        "        all_map = False\n",
        "        self.old_position = self.robot_position.copy()\n",
        "        self.old_op_map = self.op_map.copy()\n",
        "\n",
        "        # take action\n",
        "        self.take_action(action_index, self.robot_position)\n",
        "\n",
        "        # collision check\n",
        "        collision_points, collision_index = self.collision_check(\n",
        "            self.old_position, self.robot_position, self.map_size,\n",
        "            self.global_map)\n",
        "\n",
        "        if collision_index:\n",
        "            self.robot_position = self.nearest_free(self.free_tree,\n",
        "                                                    collision_points)\n",
        "            self.op_map = self.inverse_sensor(self.robot_position,\n",
        "                                              self.sensor_range, self.op_map,\n",
        "                                              self.global_map)\n",
        "            step_map = self.robot_model(self.robot_position, self.robot_size,\n",
        "                                        self.t, self.op_map)\n",
        "        else:\n",
        "            self.op_map = self.inverse_sensor(self.robot_position,\n",
        "                                              self.sensor_range, self.op_map,\n",
        "                                              self.global_map)\n",
        "            step_map = self.robot_model(self.robot_position, self.robot_size,\n",
        "                                        self.t, self.op_map)\n",
        "\n",
        "        map_local = self.local_map(self.robot_position, step_map,\n",
        "                                   self.map_size,\n",
        "                                   self.sensor_range + self.local_size)\n",
        "        reward = self.reward_function.get_reward(self.robot_position,\n",
        "                                                 self.old_op_map, self.op_map,\n",
        "                                                 collision_index)\n",
        "\n",
        "        if reward <= 0.02 and not collision_index:\n",
        "            reward = -0.8\n",
        "            new_location = True\n",
        "            #terminal = True\n",
        "\n",
        "        # during training, the robot is relocated if it has a collision\n",
        "        # during testing, the robot will use collision check to avoid the collision\n",
        "        if collision_index:\n",
        "            if not self.mode:\n",
        "                new_location = False\n",
        "                terminal = False\n",
        "            else:\n",
        "                new_location = True\n",
        "                terminal = True\n",
        "            if self.plot and self.mode:\n",
        "                self.xPoint = ma.append(self.xPoint, self.robot_position[0])\n",
        "                self.yPoint = ma.append(self.yPoint, self.robot_position[1])\n",
        "                self.plot_env()\n",
        "            self.robot_position = self.old_position.copy()\n",
        "            self.op_map = self.old_op_map.copy()\n",
        "            if self.plot and self.mode:\n",
        "                self.xPoint[self.xPoint.size - 1] = ma.masked\n",
        "                self.yPoint[self.yPoint.size - 1] = ma.masked\n",
        "        else:\n",
        "            if self.plot:\n",
        "                self.xPoint = ma.append(self.xPoint, self.robot_position[0])\n",
        "                self.yPoint = ma.append(self.yPoint, self.robot_position[1])\n",
        "                self.plot_env()\n",
        "\n",
        "        # check if exploration is finished\n",
        "        if np.size(np.where(self.op_map == 255)) / np.size(\n",
        "                np.where(self.global_map == 255)) > self.finish_percent:\n",
        "            self.li_map += 1\n",
        "            if self.li_map == self.map_number:\n",
        "                self.li_map = 0\n",
        "                all_map = True\n",
        "            #self.__init__(self.li_map, self.mode, self.plot)\n",
        "            complete = True\n",
        "            new_location = False\n",
        "            terminal = True\n",
        "\n",
        "        return (\n",
        "            self.op_map, self.robot_position\n",
        "        ), reward, terminal, complete, new_location, collision_index, all_map\n",
        "\n",
        "    def rescuer(self):\n",
        "        complete = False\n",
        "        all_map = False\n",
        "        pre_position = self.robot_position.copy()\n",
        "        self.robot_position = self.frontier(self.op_map, self.map_size, self.t)\n",
        "        self.op_map = self.inverse_sensor(self.robot_position,\n",
        "                                          self.sensor_range, self.op_map,\n",
        "                                          self.global_map)\n",
        "        step_map = self.robot_model(self.robot_position, self.robot_size,\n",
        "                                    self.t, self.op_map)\n",
        "        map_local = self.local_map(self.robot_position, step_map,\n",
        "                                   self.map_size,\n",
        "                                   self.sensor_range + self.local_size)\n",
        "\n",
        "        if self.plot:\n",
        "            path = self.astar_path(self.op_map, pre_position.tolist(),\n",
        "                                   self.robot_position.tolist())\n",
        "            self.x2frontier = ma.append(self.x2frontier, ma.masked)\n",
        "            self.y2frontier = ma.append(self.y2frontier, ma.masked)\n",
        "            self.x2frontier = ma.append(self.x2frontier, path[1, :])\n",
        "            self.y2frontier = ma.append(self.y2frontier, path[0, :])\n",
        "            self.xPoint = ma.append(self.xPoint, ma.masked)\n",
        "            self.yPoint = ma.append(self.yPoint, ma.masked)\n",
        "            self.xPoint = ma.append(self.xPoint, self.robot_position[0])\n",
        "            self.yPoint = ma.append(self.yPoint, self.robot_position[1])\n",
        "            self.plot_env()\n",
        "\n",
        "        if np.size(np.where(self.op_map == 255)) / np.size(\n",
        "                np.where(self.global_map == 255)) > self.finish_percent:\n",
        "            self.li_map += 1\n",
        "            if self.li_map == self.map_number:\n",
        "                self.li_map = 0\n",
        "                all_map = True\n",
        "            #self.__init__(self.li_map, self.mode, self.plot)\n",
        "            complete = True\n",
        "            new_location = False\n",
        "            terminal = True\n",
        "        return map_local, complete, all_map\n",
        "\n",
        "    def take_action(self, action_index, robot_position):\n",
        "        move_action = self.action_space.get_action(action_index,\n",
        "                                                   robot_position)\n",
        "\n",
        "        robot_position[0] = np.round(robot_position[0] + move_action[0])\n",
        "        robot_position[1] = np.round(robot_position[1] + move_action[1])\n",
        "\n",
        "    def map_setup(self, location):\n",
        "        global_map = (io.imread(location, 1) * 255).astype(int)\n",
        "        robot_location = np.nonzero(global_map == 208)\n",
        "        robot_location = np.array([\n",
        "            np.array(robot_location)[1, 127],\n",
        "            np.array(robot_location)[0, 127]\n",
        "        ])\n",
        "        global_map = (global_map > 150)\n",
        "        global_map = global_map * 254 + 1\n",
        "        return global_map, robot_location\n",
        "\n",
        "    def map_points(self, map_glo):\n",
        "        map_x = map_glo.shape[1]\n",
        "        map_y = map_glo.shape[0]\n",
        "        x = np.linspace(0, map_x - 1, map_x)\n",
        "        y = np.linspace(0, map_y - 1, map_y)\n",
        "        t1, t2 = np.meshgrid(x, y)\n",
        "        points = np.vstack([t1.T.ravel(), t2.T.ravel()]).T\n",
        "        return points\n",
        "\n",
        "    def local_map(self, robot_location, map_glo, map_size, local_size):\n",
        "        minX = robot_location[0] - local_size\n",
        "        maxX = robot_location[0] + local_size\n",
        "        minY = robot_location[1] - local_size\n",
        "        maxY = robot_location[1] + local_size\n",
        "\n",
        "        if minX < 0:\n",
        "            maxX = abs(minX) + maxX\n",
        "            minX = 0\n",
        "        if maxX > map_size[1]:\n",
        "            minX = minX - (maxX - map_size[1])\n",
        "            maxX = map_size[1]\n",
        "        if minY < 0:\n",
        "            maxY = abs(minY) + maxY\n",
        "            minY = 0\n",
        "        if maxY > map_size[0]:\n",
        "            minY = minY - (maxY - map_size[0])\n",
        "            maxY = map_size[0]\n",
        "\n",
        "        map_loc = map_glo[minY:maxY][:, minX:maxX]\n",
        "        return map_loc\n",
        "\n",
        "    def free_points(self, op_map):\n",
        "        index = np.where(op_map == 255)\n",
        "        free = np.asarray([index[1], index[0]]).T\n",
        "        return free\n",
        "\n",
        "    def nearest_free(self, tree, point):\n",
        "        pts = np.atleast_2d(point)\n",
        "        index = tuple(tree.query(pts)[1])\n",
        "        nearest = tree.data[index]\n",
        "        return nearest\n",
        "\n",
        "    def robot_model(self, position, robot_size, points, map_glo):\n",
        "        map_copy = map_glo.copy()\n",
        "        robot_points = self.range_search(position, robot_size, points)\n",
        "        for i in range(0, robot_points.shape[0]):\n",
        "            rob_loc = np.int32(robot_points[i, :])\n",
        "            rob_loc = np.flipud(rob_loc)\n",
        "            map_copy[tuple(rob_loc)] = 76\n",
        "        map_with_robot = map_copy\n",
        "        return map_with_robot\n",
        "\n",
        "    def range_search(self, position, r, points):\n",
        "        nvar = position.shape[0]\n",
        "        r2 = r**2\n",
        "        s = 0\n",
        "        for d in range(0, nvar):\n",
        "            s += (points[:, d] - position[d])**2\n",
        "        idx = np.nonzero(s <= r2)\n",
        "        idx = np.asarray(idx).ravel()\n",
        "        inrange_points = points[idx, :]\n",
        "        return inrange_points\n",
        "\n",
        "    def collision_check(self, start_point, end_point, map_size, map_glo):\n",
        "        x0, y0 = start_point.round()\n",
        "        x1, y1 = end_point.round()\n",
        "        dx, dy = abs(x1 - x0), abs(y1 - y0)\n",
        "        x, y = x0, y0\n",
        "        error = dx - dy\n",
        "        x_inc = 1 if x1 > x0 else -1\n",
        "        y_inc = 1 if y1 > y0 else -1\n",
        "        dx *= 2\n",
        "        dy *= 2\n",
        "\n",
        "        coll_points = np.ones((1, 2), np.uint8) * -1\n",
        "\n",
        "        while 0 <= x < map_size[1] and 0 <= y < map_size[0]:\n",
        "            k = map_glo.item(y, x)\n",
        "            if k == 1:\n",
        "                coll_points.itemset((0, 0), x)\n",
        "                coll_points.itemset((0, 1), y)\n",
        "                break\n",
        "\n",
        "            if x == end_point[0] and y == end_point[1]:\n",
        "                break\n",
        "\n",
        "            if error > 0:\n",
        "                x += x_inc\n",
        "                error -= dy\n",
        "            else:\n",
        "                y += y_inc\n",
        "                error += dx\n",
        "        if np.sum(coll_points) == -2:\n",
        "            coll_index = False\n",
        "        else:\n",
        "            coll_index = True\n",
        "\n",
        "        return coll_points, coll_index\n",
        "\n",
        "    def inverse_sensor(self, robot_position, sensor_range, op_map, map_glo):\n",
        "        op_map = inverse_sensor_model(robot_position[0], robot_position[1],\n",
        "                                      sensor_range, op_map, map_glo)\n",
        "        return op_map\n",
        "\n",
        "    def frontier(self, op_map, map_size, points):\n",
        "        y_len = map_size[0]\n",
        "        x_len = map_size[1]\n",
        "        mapping = op_map.copy()\n",
        "        # 0-1 unknown area map\n",
        "        mapping = (mapping == 127) * 1\n",
        "        mapping = np.lib.pad(mapping, ((1, 1), (1, 1)),\n",
        "                             'constant',\n",
        "                             constant_values=0)\n",
        "        fro_map = mapping[2:][:, 1:x_len + 1] + mapping[:y_len][:, 1:x_len + 1] + mapping[1:y_len + 1][:, 2:] + \\\n",
        "                  mapping[1:y_len + 1][:, :x_len] + mapping[:y_len][:, 2:] + mapping[2:][:, :x_len] + mapping[2:][:,\n",
        "                                                                                                      2:] + \\\n",
        "                  mapping[:y_len][:, :x_len]\n",
        "        ind_free = np.where(op_map.ravel(order='F') == 255)[0]\n",
        "        ind_fron_1 = np.where(1 < fro_map.ravel(order='F'))[0]\n",
        "        ind_fron_2 = np.where(fro_map.ravel(order='F') < 8)[0]\n",
        "        ind_fron = np.intersect1d(ind_fron_1, ind_fron_2)\n",
        "        ind_to = np.intersect1d(ind_free, ind_fron)\n",
        "        f = points[ind_to]\n",
        "        f = f.astype(int)\n",
        "        return f[0]\n",
        "\n",
        "    def unique_rows(self, a):\n",
        "        a = np.ascontiguousarray(a)\n",
        "        unique_a = np.unique(a.view([('', a.dtype)] * a.shape[1]))\n",
        "        result = unique_a.view(a.dtype).reshape(\n",
        "            (unique_a.shape[0], a.shape[1]))\n",
        "        result = result[~np.isnan(result).any(axis=1)]\n",
        "        return result\n",
        "\n",
        "    def astar_path(self, weights, start, goal, allow_diagonal=True):\n",
        "        temp_start = [start[1], start[0]]\n",
        "        temp_goal = [goal[1], goal[0]]\n",
        "        temp_weight = (weights < 150) * 254 + 1\n",
        "        # For the heuristic to be valid, each move must cost at least 1.\n",
        "        if temp_weight.min(axis=None) < 1.:\n",
        "            raise ValueError(\"Minimum cost to move must be 1, but got %f\" %\n",
        "                             (temp_weight.min(axis=None)))\n",
        "        # Ensure start is within bounds.\n",
        "        if (temp_start[0] < 0 or temp_start[0] >= temp_weight.shape[0]\n",
        "                or temp_start[1] < 0 or temp_start[1] >= temp_weight.shape[1]):\n",
        "            raise ValueError(\"Start lies outside grid.\")\n",
        "        # Ensure goal is within bounds.\n",
        "        if (temp_goal[0] < 0 or temp_goal[0] >= temp_weight.shape[0]\n",
        "                or temp_goal[1] < 0 or temp_goal[1] >= temp_weight.shape[1]):\n",
        "            raise ValueError(\"Goal of lies outside grid.\")\n",
        "\n",
        "        height, width = temp_weight.shape\n",
        "        start_idx = np.ravel_multi_index(temp_start, (height, width))\n",
        "        goal_idx = np.ravel_multi_index(temp_goal, (height, width))\n",
        "\n",
        "        path = astar(\n",
        "            temp_weight.flatten(),\n",
        "            height,\n",
        "            width,\n",
        "            start_idx,\n",
        "            goal_idx,\n",
        "            allow_diagonal,\n",
        "        )\n",
        "        return path\n",
        "\n",
        "    def plot_env(self):\n",
        "        plt.cla()\n",
        "        plt.imshow(self.op_map, cmap='gray')\n",
        "        plt.axis((0, self.map_size[1], self.map_size[0], 0))\n",
        "        plt.plot(self.xPoint, self.yPoint, 'b', linewidth=2)\n",
        "        plt.plot(self.x2frontier, self.y2frontier, 'r', linewidth=2)\n",
        "        plt.plot(self.robot_position[0],\n",
        "                 self.robot_position[1],\n",
        "                 'mo',\n",
        "                 markersize=8)\n",
        "        plt.plot(self.xPoint[0], self.yPoint[0], 'co', markersize=8)\n",
        "        plt.pause(0.05)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edUqbZxCxIKW",
        "outputId": "c020c1e3-8692-4848-c0f2-5a03ff78f10f"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "np.random.seed(1000)\n",
        "random.seed(10)\n",
        "\n",
        "reward_func = PaperRewardFunction()\n",
        "action_space = PolarActionSpace(30, 60)\n",
        "\n",
        "robot = Robot(0, True, False, 'DRL_robot_exploration/DungeonMaps',action_space,reward_func, False)\n",
        "\n",
        "test_action = np.array([0.75, 0.5])\n",
        "print('start')\n",
        "print(robot.robot_position)\n",
        "\n",
        "for i in range(10):\n",
        "  (map, loc), reward, terminal, complete, new_loc, collision, all_map = robot.step(test_action)\n",
        "  print('reward', reward)\n",
        "  print('robot loc', loc)\n",
        "  print(collision)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start\n",
            "[463  71]\n",
            "reward 0.2057142857142857\n",
            "robot loc [418  71]\n",
            "False\n",
            "reward 0.2057142857142857\n",
            "robot loc [373  71]\n",
            "False\n",
            "reward 0.206\n",
            "robot loc [328  71]\n",
            "False\n",
            "reward 0.312\n",
            "robot loc [283  71]\n",
            "False\n",
            "reward 0.6817142857142857\n",
            "robot loc [238  71]\n",
            "False\n",
            "reward 0.5524285714285714\n",
            "robot loc [193  71]\n",
            "False\n",
            "reward 0.19457142857142856\n",
            "robot loc [148  71]\n",
            "False\n",
            "reward -300\n",
            "robot loc [148  71]\n",
            "True\n",
            "reward -300\n",
            "robot loc [148  71]\n",
            "True\n",
            "reward -300\n",
            "robot loc [148  71]\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO_EJKEoNC6T"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchsummary\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
        "\n",
        "def build_conv_feature_extractor(conv_dims, act):\n",
        "  #Create Conv2D + MaxPool layers\n",
        "  conv_layers = [nn.Conv2d(*conv_dim) if len(conv_dim) == 3 else nn.MaxPool2d(conv_dim) for conv_dim in conv_dims]\n",
        "  total_layers = []\n",
        "\n",
        "  #Add ReLU activations after each conv layer\n",
        "  for layer in conv_layers:\n",
        "    total_layers.append(layer)\n",
        "    if type(layer) == nn.Conv2d:\n",
        "      total_layers.append(act())\n",
        "  return nn.Sequential(*total_layers)\n",
        "  \n",
        "\n",
        "def get_output_shape(model, image_dim):\n",
        "    return model(torch.rand(*(image_dim))).data.shape\n",
        "\n",
        "class RNNActor(nn.Module):\n",
        "  #TODO Determine if the action space allows negative numbers\n",
        "  #Potentially replace tanh with sigmoid\n",
        "  def __init__(self, conv_dims, lstm_hidden, train_length, input_size=(1, 1,84,84), act=nn.ReLU, final_act=nn.Sigmoid):\n",
        "    super(RNNActor, self).__init__()\n",
        "\n",
        "    self.conv_mod = build_conv_feature_extractor(conv_dims, act)\n",
        "    \n",
        "    #Silly way to determine the size going into the RNN\n",
        "    with torch.no_grad():\n",
        "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
        "\n",
        "    print('LSTM Input Size', feature_size)\n",
        "\n",
        "    #Construct LSTM\n",
        "    self.lstm_hidden = lstm_hidden\n",
        "    self.lstm_input = np.prod(list(feature_size)) + 2\n",
        "    self.lstm = nn.LSTM(self.lstm_input, lstm_hidden)\n",
        "    self.linear = nn.Linear(lstm_hidden, 2)\n",
        "    self.train_length = train_length\n",
        "    self.final_act = final_act()\n",
        "\n",
        "  def forward(self, image, positions, lengths, hidden_state=None):\n",
        "    batch_size = image.size()[1]\n",
        "    seq_length = image.size()[0]\n",
        "    conv = self.conv_mod(image.view((seq_length * batch_size, 1, 84, 84)))\n",
        "\n",
        "    flat = conv.view(-1).view(seq_length, batch_size, self.lstm_input - 2)\n",
        "    state = torch.cat((flat, positions), 2)\n",
        "    packed = pack_padded_sequence(state, lengths, enforce_sorted=False)\n",
        "    self.lstm.flatten_parameters()\n",
        "    if hidden_state is not None:\n",
        "      states, final_state = self.lstm(packed, hidden_state)\n",
        "    else:\n",
        "      states, final_state = self.lstm(packed)\n",
        "\n",
        "    unpacked, end_lengths = pad_packed_sequence(states)\n",
        "    final = self.linear(unpacked)\n",
        "    return self.final_act(final), final_state, end_lengths"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgxUtoeMJ8Pa"
      },
      "source": [
        "def build_dense_regression(linear_dims, act, final_act=None):\n",
        "  linear_layers = [nn.Linear(*linear_dim)  for linear_dim in linear_dims]\n",
        "  activations = [act() for layer in range(len(linear_layers) - 1)]\n",
        "  if final_act is not None:\n",
        "    activations.append(final_act())\n",
        "  else:\n",
        "    activations.append(nn.Identity())\n",
        "  return nn.Sequential(*[val for tup in zip(*[linear_layers, activations]) for val in tup]\n",
        ")\n",
        "\n",
        "class CNNCritic(nn.Module):\n",
        "  def __init__(self, conv_dims, fc_dims, input_size=(1, 1,84,84), conv_act=nn.ReLU, fc_act=nn.ReLU):\n",
        "    super(CNNCritic, self).__init__()\n",
        "    self.conv_mod = build_conv_feature_extractor(conv_dims, conv_act)\n",
        "\n",
        "    #Silly way to determine the size going into the RNN\n",
        "    with torch.no_grad():\n",
        "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
        "\n",
        "    #Add 4 for action + position\n",
        "    feature_size = np.prod(list(feature_size)) + 4\n",
        "    first_output = fc_dims[0][0]\n",
        "    fc_dims.insert(0, (feature_size, first_output))\n",
        "\n",
        "    self.fc = build_dense_regression(fc_dims, fc_act)\n",
        "    self.fc_dims = feature_size\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self, map, positions, action):\n",
        "    batch_size = map.size()[1]\n",
        "    seq_length =  map.size()[0]\n",
        "    conv = self.conv_mod(map.view((seq_length * batch_size, 1, 84, 84)))\n",
        "\n",
        "    flat = conv.view(-1).view(seq_length, batch_size, self.fc_dims - 4)\n",
        "    total_feats = torch.cat((flat, positions, action), 2)\n",
        "    return self.fc(total_feats)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjDpPhJi8gvh"
      },
      "source": [
        "class ActorPolicy:\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "\n",
        "  def __call__(self, map, position):\n",
        "    map = map.to(device='cuda').float().unsqueeze(0).unsqueeze(1)\n",
        "    position = position.to(device='cuda').float().unsqueeze(0)\n",
        "\n",
        "    result = self.model(map, position)\n",
        "\n",
        "    return result.cpu().squeeze(0)\n",
        "\n",
        "class CNNCriticNoSeq(nn.Module):\n",
        "  def __init__(self, conv_dims, fc_dims, input_size=(1, 1,84,84), conv_act=nn.ReLU, fc_act=nn.ReLU):\n",
        "    super(CNNCriticNoSeq, self).__init__()\n",
        "    self.conv_mod = build_conv_feature_extractor(conv_dims, conv_act)\n",
        "\n",
        "    #Silly way to determine the size going into the RNN\n",
        "    with torch.no_grad():\n",
        "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
        "\n",
        "    #Add 4 for action + position\n",
        "    feature_size = np.prod(list(feature_size)) + 4\n",
        "    first_output = fc_dims[0][0]\n",
        "    fc_dims.insert(0, (feature_size, first_output))\n",
        "\n",
        "    self.fc = build_dense_regression(fc_dims, fc_act)\n",
        "    self.fc_dims = feature_size\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self, map, positions, action):\n",
        "    conv = self.conv_mod(map)\n",
        "    batch_size = map.size()[0]\n",
        "    flat = conv.view(batch_size, self.fc_dims - 4)\n",
        "    print('flat', flat.size())\n",
        "    print('positions', positions.size())\n",
        "    total_feats = torch.cat((flat, positions, action), 1)\n",
        "    return self.fc(total_feats)\n",
        "\n",
        "\n",
        "\n",
        "class FCActor(nn.Module):\n",
        "  #TODO Determine if the action space allows negative numbers\n",
        "  #Potentially replace tanh with sigmoid\n",
        "  def __init__(self, conv_dims, linear_dims, input_size=(1, 1,84,84), act=nn.ReLU, final_act=nn.Sigmoid):\n",
        "    super(FCActor, self).__init__()\n",
        "    self.conv_mod = build_conv_feature_extractor(conv_dims, act)\n",
        "\n",
        "    #Silly way to determine the size going into the RNN\n",
        "    with torch.no_grad():\n",
        "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
        "\n",
        "    #Add 4 for action + position\n",
        "    feature_size = np.prod(list(feature_size)) + 2\n",
        "    first_output = linear_dims[0][0]\n",
        "    linear_dims.insert(0, (feature_size, first_output))\n",
        "\n",
        "    self.fc = build_dense_regression(linear_dims, act, final_act)\n",
        "    self.fc_dims = feature_size\n",
        "\n",
        "  def forward(self, map, positions):\n",
        "    conv = self.conv_mod(map)\n",
        "\n",
        "    flat = conv.view(map.size()[0], self.fc_dims - 2)\n",
        "    print('flat', flat.size())\n",
        "    print('positions', positions.size())\n",
        "    total_feats = torch.cat((flat, positions), 1)\n",
        "    return self.fc(total_feats)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-eCOZDBC3pg"
      },
      "source": [
        "\"\"\" Learn a policy using DDPG for the reach task\"\"\"\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import MultivariateNormal\n",
        "from torch.nn import MSELoss\n",
        "import random\n",
        "from skimage.transform import resize\n",
        "from io import BytesIO\n",
        "import itertools\n",
        "import lmdb\n",
        "from itertools import zip_longest\n",
        "\n",
        "import gym\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import time\n",
        "\n",
        "# TODO: A function to soft update target networks\n",
        "def weighSync(target_model, source_model, tau=0.001):\n",
        "  for (target, src) in zip(target_model.parameters(), source_model.parameters()):\n",
        "    target.data = (1-tau) * target.data + tau * src.data \n",
        "\n",
        "def grouper(iterable, n, fillvalue=None):\n",
        "  '''Collect data into fixed-length chunks or blocks'''\n",
        "  # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
        "  args = [iter(iterable)] * n\n",
        "  return zip_longest(*args, fillvalue=fillvalue)\n",
        "\n",
        "# TODO: Write the ReplayBuffer\n",
        "class Replay():\n",
        "    def __init__(self, buffer_size, init_sequences, max_episode_length, sequence_length, action_dim, env, test_env, env_width, env_height):\n",
        "        \"\"\"\n",
        "        A function to initialize the replay buffer.\n",
        "\n",
        "        param: init_length : Initial number of transitions to collect\n",
        "        param: state_dim : Size of the state space\n",
        "        param: action_dim : Size of the action space\n",
        "        param: env : gym environment object\n",
        "        \"\"\"\n",
        "        try:\n",
        "          os.remove('db.lmdb')\n",
        "        except OSError:\n",
        "          pass\n",
        "        self.db = lmdb.open('db.lmdb', map_size=30e9)\n",
        "        self.buffer = [{}] * buffer_size\n",
        "        self.noise = MultivariateNormal(torch.zeros(2), torch.diag(torch.tensor([0.2, 0.2])))\n",
        "        self.sequence_length = sequence_length\n",
        "        self.max_episode_length = max_episode_length\n",
        "        self.env = env\n",
        "        self.test_env = test_env\n",
        "        state = self.env.reset(self.env.index_map, False)\n",
        "        self.env_width = env_width\n",
        "        self.env_height = env_height\n",
        "        self.buffer_idx = 0\n",
        "        self.total_steps = 0\n",
        "        last_state = env.reset(self.env.index_map, False)\n",
        "        init_policy = lambda map, pos: torch.from_numpy(np.random.uniform(0, 1, (2,)))\n",
        "        self.full_buffer = False\n",
        "        self.current_pointer = 0\n",
        "\n",
        "        map, position = self.env.reset()\n",
        "        map = resize(map, (84, 84))\n",
        "        map = map / 255\n",
        "        position = position.astype(np.float64)\n",
        "        position[0] = position[0] / 480\n",
        "        position[1] = position[1] / 640\n",
        "        action = {'map':torch.from_numpy(map).float(), 'position':torch.from_numpy(position).float()}\n",
        "        \n",
        "        while self.buffer_idx < init_sequences:\n",
        "          action, terminal = self.generate_step(init_policy, action, False)\n",
        "          print('action', action)\n",
        "          print('terminal', terminal)\n",
        "          if terminal:\n",
        "            map, position = self.env.reset()\n",
        "\n",
        "            map = resize(map, (84, 84))\n",
        "            map = map / 255\n",
        "            position = position.astype(np.float64)\n",
        "            position[0] = position[0] / 480\n",
        "            position[1] = position[1] / 640\n",
        "            action = {'map':torch.from_numpy(map).float(), 'position':torch.from_numpy(position).float()}\n",
        "\n",
        "\n",
        "    def generate_step(self, policy, last_transition, add_noise=True, store=True, test=False):\n",
        "      if test:\n",
        "        env = self.test_env\n",
        "      else:\n",
        "        env = self.env\n",
        "      episode = []\n",
        "      last_map = last_transition['map']\n",
        "      last_position = last_transition['position']\n",
        "\n",
        "      terminal = False\n",
        "\n",
        "      total_reward = 0\n",
        "\n",
        "      action = policy(last_map, last_position)\n",
        "      if add_noise:\n",
        "        sampled = self.noise.sample()\n",
        "        #print('adding noise', sampled)\n",
        "        action = action.cpu() + sampled\n",
        "      else:\n",
        "        action = action.cpu()\n",
        "\n",
        "      action_np = action.detach().numpy().flatten()\n",
        "      if action_np[0] < 0:\n",
        "        action_np[0] = abs(action_np[0])\n",
        "      elif action_np[0] > 1:\n",
        "        action_np[0] = action_np[0] - 1\n",
        "\n",
        "      if action_np[1] < 0:\n",
        "        action_np[1] = abs(action_np[1])\n",
        "      elif action_np[1] > 1:\n",
        "        action_np[1] = action_np[1] - 1\n",
        "\n",
        "    \n",
        "\n",
        "      (map, loc), reward, terminal, complete, new_loc, collision, all_map = env.step(action_np)\n",
        "      map = resize(map, (84, 84))\n",
        "      map = (map / 255)\n",
        "      loc = loc.astype(np.float64)\n",
        "      loc[0] = loc[0] / 480.0\n",
        "      loc[1] = loc[1] / 640.0\n",
        "\n",
        "      map_tensor = torch.from_numpy(map).float()\n",
        "      position_tensor = torch.from_numpy(loc).float()\n",
        "      reward_tensor = torch.tensor(reward).float()\n",
        "      action = {'last_map':last_map, 'last_position':last_position, 'map': map_tensor.detach(), 'position': position_tensor.detach(), 'reward': reward_tensor.unsqueeze(0).detach(), 'action': action.detach()}\n",
        "\n",
        "      total_reward += reward\n",
        "\n",
        "      if store:\n",
        "        self.write_one_transition(action, self.buffer_idx)\n",
        "        self.buffer_idx = (self.buffer_idx + 1) % len(self.buffer)\n",
        "        if self.buffer_idx == 0:\n",
        "          self.full_buffer = True\n",
        "\n",
        "      return action, terminal\n",
        "\n",
        "    def write_one_transition(self, trans, idx):\n",
        "      actions = trans['action']\n",
        "      rewards = trans['reward']\n",
        "      maps = trans['map']\n",
        "      positions = trans['position']\n",
        "\n",
        "      last_map = trans['last_map']\n",
        "      last_position = trans['last_position']\n",
        "\n",
        "      print('actions', actions.size())\n",
        "      print('rewards', rewards.size())\n",
        "      print('maps', maps.size())\n",
        "      print('positions', positions.size())\n",
        "      print('last_map', last_map.size())\n",
        "      print('last_position', last_position.size())\n",
        "\n",
        "      total_tensor = torch.cat((actions, rewards, positions, last_position), 0)\n",
        "      total_maps = torch.cat((maps, last_map), 0)\n",
        "      with self.db.begin(write=True) as txn:\n",
        "        total_bytes = BytesIO()\n",
        "        maps_bytes = BytesIO()\n",
        "\n",
        "        torch.save(total_tensor, total_bytes)\n",
        "        torch.save(total_maps, maps_bytes)\n",
        "        \n",
        "        txn.put('{}_total'.format(idx).encode(), total_bytes.getvalue())\n",
        "        txn.put('{}_maps'.format(idx).encode(), maps_bytes.getvalue())\n",
        "\n",
        "    def sample_transitions(self, N):\n",
        "      \"\"\"\n",
        "      A function to sample N points from the buffer\n",
        "      param: N : Number of samples to obtain from the buffer\n",
        "      \"\"\"\n",
        "      if self.full_buffer:\n",
        "        samples = np.random.permutation(range(self.buffer_length))\n",
        "      else:\n",
        "        samples = np.random.permutation(range(self.buffer_idx))\n",
        "\n",
        "      samples = samples[:N]\n",
        "      return self.read_transitions(samples)\n",
        "\n",
        "    def read_transitions(self, transitions):\n",
        "      maps = []\n",
        "      positions = []\n",
        "      rewards = []\n",
        "      actions = []\n",
        "      last_maps = []\n",
        "      last_positions = []\n",
        "\n",
        "      for seq in transitions:\n",
        "        with self.db.begin() as txn:\n",
        "          total_data = BytesIO(txn.get('{}_total'.format(seq).encode()))\n",
        "          map_data = BytesIO(txn.get('{}_maps'.format(seq).encode()))      \n",
        "\n",
        "          total_tensor = torch.load(total_data)\n",
        "          map_tensor = torch.load(map_data)\n",
        "          print('map tensor', map_tensor.size())\n",
        "          maps.append(map_tensor[:84, :].unsqueeze(0))\n",
        "          last_maps.append(map_tensor[84:, :].unsqueeze(0))\n",
        "          positions.append(total_tensor[3:5].unsqueeze(0))\n",
        "          actions.append(total_tensor[:2].unsqueeze(0))\n",
        "          rewards.append(total_tensor[2].unsqueeze(0))\n",
        "          last_positions.append(total_tensor[5:].unsqueeze(0))\n",
        "\n",
        "      map_pad = torch.cat(maps, 0).to(device='cuda').float()\n",
        "      pos_pad = torch.cat(positions, 0).to(device='cuda').float()\n",
        "      reward_pad = torch.cat(rewards, 0).to(device='cuda').float()\n",
        "      action_pad = torch.cat(actions, 0).to(device='cuda').float()\n",
        "      last_positions = torch.cat(last_positions, 0).to(device='cuda').float()\n",
        "      last_maps = torch.cat(last_maps, 0).to(device='cuda').float()\n",
        "\n",
        "      return map_pad, pos_pad, reward_pad, action_pad, last_positions, last_maps\n",
        "\n",
        "    def generate_episode(self, policy, add_noise=True, store=True, test=False, plot=False, do_print=False):\n",
        "      episode = []\n",
        "      self.env.plot = plot\n",
        "      map, position = self.env.reset()\n",
        "      position = position.astype(np.float64)\n",
        "      map = resize(map, (84, 84))\n",
        "      map = ((map - 127) / 255) * 2\n",
        "\n",
        "      position[0] = position[0]/ 640.0\n",
        "      position[1] = position[1] / 480.0\n",
        "      last_map = torch.from_numpy(map).float()\n",
        "      last_position = torch.from_numpy(position).float()\n",
        "      terminal = False\n",
        "\n",
        "      total_reward = 0\n",
        "      last_state = None\n",
        "      for i in range(self.max_episode_length):\n",
        "        if last_state is None:\n",
        "          action, last_state, lengths = policy(last_map.unsqueeze(0).unsqueeze(0).to(device='cuda'), last_position.unsqueeze(0).unsqueeze(0).to(device='cuda'), [1])\n",
        "        else:\n",
        "          action, last_state, lengths = policy(last_map.unsqueeze(0).unsqueeze(0).to(device='cuda'), last_position.unsqueeze(0).unsqueeze(0).to(device='cuda'), [1], last_state)\n",
        "      \n",
        "        if add_noise:\n",
        "          sampled = self.noise.sample()\n",
        "          #print('adding noise', sampled)\n",
        "          action = action.cpu().squeeze(0).squeeze(1) + sampled\n",
        "        else:\n",
        "          action = action.cpu().squeeze(0).squeeze(1)\n",
        "\n",
        "        action_np = action.detach().numpy().flatten()\n",
        "        if action_np[0] < 0:\n",
        "          action_np[0] = abs(action_np[0])\n",
        "        elif action_np[0] > 1:\n",
        "          action_np[0] = action_np[0] - 1\n",
        "\n",
        "        if action_np[1] < 0:\n",
        "          action_np[1] = abs(action_np[1])\n",
        "        elif action_np[1] > 1:\n",
        "          action_np[1] = action_np[1] - 1\n",
        "\n",
        "\n",
        "        if do_print:\n",
        "          print('action', action_np)\n",
        "\n",
        "    \n",
        "\n",
        "        (map, loc), reward, terminal, complete, new_loc, collision, all_map = self.env.step(action_np)\n",
        "        map = resize(map, (84, 84))\n",
        "        map = ((map - 127) / 255) * 2\n",
        "        loc = loc.astype(np.float64)\n",
        "        loc[0] = loc[0] / 640.0\n",
        "        loc[1] = loc[1] / 480.0\n",
        "\n",
        "        map_tensor = torch.from_numpy(map).float()\n",
        "        position_tensor = torch.from_numpy(loc).float()\n",
        "        reward_tensor = torch.tensor(reward).float()\n",
        "        episode.append({'map': map_tensor.detach(), 'position': position_tensor.detach(), 'reward': reward_tensor.detach(), 'action': action.detach()})\n",
        "        last_map = map_tensor.to(device='cuda')\n",
        "        last_position = position_tensor.to(device='cuda')\n",
        "        total_reward += reward\n",
        "        if terminal:\n",
        "          break\n",
        "\n",
        "      if store:\n",
        "        sequences = self.episode_to_sequences(episode)\n",
        "        for sequence in sequences:\n",
        "          self.write_sequence(sequence, self.buffer_idx)\n",
        "          self.buffer_idx = (self.buffer_idx + 1) % len(self.buffer)\n",
        "          if self.buffer_idx == 0:\n",
        "            self.full_buffer = True\n",
        "\n",
        "      self.env.plot = False\n",
        "      return total_reward\n",
        "\n",
        "    def write_sequence(self, sequence, idx):\n",
        "      actions = sequence['actions']\n",
        "      rewards = sequence['rewards']\n",
        "      maps = sequence['maps']\n",
        "      positions = sequence['positions']\n",
        "\n",
        "      len = sequence['len']\n",
        "      total_tensor = torch.cat((actions, rewards.unsqueeze(1).unsqueeze(1), positions.unsqueeze(1)), 2)\n",
        "      with self.db.begin(write=True) as txn:\n",
        "        total_bytes = BytesIO()\n",
        "        maps_bytes = BytesIO()\n",
        "\n",
        "        torch.save(total_tensor, total_bytes)\n",
        "        torch.save(maps, maps_bytes)\n",
        "        \n",
        "        txn.put('{}_total'.format(idx).encode(), total_bytes.getvalue())\n",
        "        txn.put('{}_maps'.format(idx).encode(), maps_bytes.getvalue())\n",
        "        txn.put('{}_len'.format(idx).encode(), str(len).encode())\n",
        "\n",
        "    def read_sequences(self, sequences):\n",
        "      map_sequences = []\n",
        "      position_sequences = []\n",
        "      reward_sequences = []\n",
        "      action_sequences = []\n",
        "      seq_lens = []\n",
        "\n",
        "      for seq in sequences:\n",
        "        with self.db.begin() as txn:\n",
        "          total_data = BytesIO(txn.get('{}_total'.format(seq).encode()))\n",
        "          map_data = BytesIO(txn.get('{}_maps'.format(seq).encode()))\n",
        "          length = txn.get('{}_len'.format(seq).encode())\n",
        "      \n",
        "\n",
        "          total_tensor = torch.load(total_data)\n",
        "          map_tensor = torch.load(map_data)\n",
        "          map_sequences.append(map_tensor)\n",
        "          position_sequences.append(total_tensor[:, :, 3:])\n",
        "          action_sequences.append(total_tensor[:, :, :2])\n",
        "          reward_sequences.append(total_tensor[:, :, 2])\n",
        "          seq_lens.append(int(length))\n",
        "\n",
        "      map_pad = pad_sequence(map_sequences).to(device='cuda').float()\n",
        "      pos_pad = pad_sequence(position_sequences).to(device='cuda').float()\n",
        "      reward_pad = pad_sequence(reward_sequences).to(device='cuda').float()\n",
        "      action_pad = pad_sequence(action_sequences).to(device='cuda').float()\n",
        "      seqs = seq_lens\n",
        "\n",
        "      return map_pad, pos_pad, reward_pad, action_pad, seqs\n",
        "    \n",
        "    def episode_to_sequences(self, episode):\n",
        "      sequences = []\n",
        "      last_idx = 0\n",
        "      for i in np.arange(self.sequence_length, len(episode), self.sequence_length):\n",
        "        window = episode[last_idx:i]\n",
        "        map_tensor = torch.cat([torch.unsqueeze(data['map'], 0) for data in window], 0)\n",
        "        position_tensor = torch.cat([torch.unsqueeze(data['position'], 0) for data in window], 0)\n",
        "        reward_tensor = torch.cat([torch.unsqueeze(data['reward'], 0) for data in window], 0)\n",
        "        action_tensor = torch.cat([torch.unsqueeze(data['action'], 0) for data in window], 0)\n",
        "        sequences.append({'maps':map_tensor, 'positions': position_tensor, 'rewards': reward_tensor, 'actions':action_tensor, 'len':len(window)})\n",
        "        last_idx = i\n",
        "\n",
        "      window = episode[last_idx:]\n",
        "      map_tensor = torch.cat([torch.unsqueeze(data['map'], 0) for data in window], 0)\n",
        "      position_tensor = torch.cat([torch.unsqueeze(data['position'], 0) for data in window], 0)\n",
        "      reward_tensor = torch.cat([torch.unsqueeze(data['reward'], 0) for data in window], 0)\n",
        "      action_tensor = torch.cat([torch.unsqueeze(data['action'], 0) for data in window], 0)\n",
        "      sequences.append({'maps':map_tensor, 'positions': position_tensor, 'rewards': reward_tensor, 'actions':action_tensor, 'len':len(window)})\n",
        "      return sequences\n",
        "    \n",
        "\n",
        "    #TODO: Complete the function\n",
        "    def buffer_sample(self, N):\n",
        "        \"\"\"\n",
        "        A function to sample N points from the buffer\n",
        "        param: N : Number of samples to obtain from the buffer\n",
        "        \"\"\"\n",
        "        if self.full_buffer:\n",
        "          samples = np.random.permutation(range(self.buffer_length))\n",
        "        else:\n",
        "          samples = np.random.permutation(range(self.buffer_idx))\n",
        "\n",
        "        samples = samples[:N]\n",
        "        return self.read_sequences(samples)\n",
        "\n",
        "    def batchify(self, samples):\n",
        "      \n",
        "      map_sequences = []\n",
        "      position_sequences = []\n",
        "      reward_sequences = []\n",
        "      action_sequences = []\n",
        "      seq_lens = []\n",
        "\n",
        "      for sequence in samples:\n",
        "\n",
        "        map_sequences.append(sequence['maps'])\n",
        "        position_sequences.append(sequence['positions'])\n",
        "        reward_sequences.append(sequence['rewards'])\n",
        "        action_sequences.append(sequence['actions'])\n",
        "        seq_lens.append(sequence['len'])\n",
        "\n",
        "      map_pad = pad_sequence(map_sequences).to(device='cuda').float()\n",
        "      pos_pad = pad_sequence(position_sequences).to(device='cuda').float()\n",
        "      reward_pad = pad_sequence(reward_sequences).to(device='cuda').float()\n",
        "      action_pad = pad_sequence(action_sequences).to(device='cuda').float()\n",
        "      seqs = seq_lens\n",
        "\n",
        "      return map_pad, pos_pad, reward_pad, action_pad, seqs\n",
        "\n",
        "      \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFMjDGz1N958"
      },
      "source": [
        "# TODO: Implement a DDPG class\n",
        "class DDPG():\n",
        "    def __init__(\n",
        "            self,\n",
        "            env,\n",
        "            conv_dims,\n",
        "            state_dim,\n",
        "            linear_dims,\n",
        "            actor_linear_dims,\n",
        "            sequence_length,\n",
        "            replay,\n",
        "            critic_lr=3e-4,\n",
        "            actor_lr=3e-4,\n",
        "            gamma=0.99,\n",
        "            batch_size=100,\n",
        "            seed=1000\n",
        "    ):\n",
        "        \"\"\"\n",
        "        param: env: An gym environment\n",
        "        param: action_dim: Size of action space\n",
        "        param: state_dim: Size of state space\n",
        "        param: critic_lr: Learning rate of the critic\n",
        "        param: actor_lr: Learning rate of the actor\n",
        "        param: gamma: The discount factor\n",
        "        param: batch_size: The batch size for training\n",
        "        \"\"\"\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        action_dim = 2\n",
        "        self.gamma = gamma\n",
        "        self.batch_size = batch_size\n",
        "        self.sequence_length = sequence_length\n",
        "        self.env = env\n",
        "        self.state_dim = state_dim\n",
        "        self.actor = FCActor(conv_dims, actor_linear_dims).float().to(device='cuda')\n",
        "\n",
        "        # TODO: Create a actor and actor_target\n",
        "        self.actor_target = copy.deepcopy(self.actor)\n",
        "\n",
        "        # TODO: Make sure that both networks have the same initial weights\n",
        "\n",
        "        # TODO: Create a critic and critic_target object\n",
        "        self.critic = CNNCriticNoSeq(conv_dims, linear_dims).float().to(device='cuda')\n",
        "        self.critic_target = copy.deepcopy(self.critic)\n",
        "        # TODO: Make sure that both networks have the same initial weights\n",
        "\n",
        "        # TODO: Define the optimizer for the actor\n",
        "        self.optimizer_actor = optim.Adam(self.actor.parameters(), actor_lr)\n",
        "        # TODO: Define the optimizer for the critic\n",
        "        self.optimizer_critic = optim.Adam(self.critic.parameters(), critic_lr)\n",
        "\n",
        "        # TODO: define a replay buffer\n",
        "        #buffer_size, init_episodes, max_episode_length, state_dim, action_dim, env, env_width, env_height\n",
        "        self.replay = replay\n",
        "\n",
        "    # TODO: Complete the function\n",
        "    def update_target_networks(self):\n",
        "        \"\"\"\n",
        "        A function to update the target networks\n",
        "        \"\"\"\n",
        "        weighSync(self.actor_target, self.actor)\n",
        "        weighSync(self.critic_target, self.critic)\n",
        "\n",
        "    # TODO: Complete the function\n",
        "    def update_network(self, y_i, maps, positions, actions, last_maps, last_positions):\n",
        "        \"\"\"\n",
        "        A function to update the function just once\n",
        "        \"\"\"\n",
        "\n",
        "        qs = self.critic(last_maps, last_positions, actions)\n",
        "        #should be (seq_len, batch, 1)\n",
        "        #should be (seq_len, batch, 1)\n",
        "\n",
        "        critic_loss = ((y_i - qs)**2).sum() / (self.sequence_length * self.batch_size)\n",
        "        critic_loss.backward()\n",
        "\n",
        "        self.optimizer_critic.step()\n",
        "\n",
        "        # Freeze Q-network so you don't waste computational effort \n",
        "        # computing gradients for it during the policy learning step.\n",
        "        for p in self.critic.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        new_act = self.actor(last_maps, last_positions)\n",
        "        qs = self.critic(last_maps, last_positions, new_act)\n",
        "        actor_loss = qs.sum() / (self.batch_size)\n",
        "        (-actor_loss).backward()\n",
        "        self.optimizer_actor.step()\n",
        "\n",
        "        # Freeze Q-network so you don't waste computational effort \n",
        "        # computing gradients for it during the policy learning step.\n",
        "        for p in self.critic.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "  \n",
        "    # TODO: Complete the function\n",
        "    def train(self, num_steps):\n",
        "        \"\"\"\n",
        "        Train the policy for the given number of iterations\n",
        "        :param num_steps:The number of steps to train the policy for\n",
        "        \"\"\"\n",
        "        self.critic_criterion = MSELoss()\n",
        "        num_episodes = 0\n",
        "        i = 0\n",
        "        total_reward = 0\n",
        "        total_steps = 0\n",
        "        episode_reward = 0\n",
        "        steps_list = []\n",
        "        rewards = []\n",
        "        start = time.time()\n",
        "        total_target_time = 0\n",
        "        total_backprop_time = 0\n",
        "        total_gen_episode_time = 0\n",
        "        total_test_time = 0\n",
        "        total_dataload_time = 0\n",
        "\n",
        "        \n",
        "        map, position = self.replay.env.reset()\n",
        "        map = resize(map, (84, 84))\n",
        "        map = map / 255\n",
        "        position = position.astype(np.float64)\n",
        "        position[0] = position[0] / 480\n",
        "        position[1] = position[1] / 640\n",
        "        action = {'map':torch.from_numpy(map).float(), 'position':torch.from_numpy(position).float()}\n",
        "        \n",
        "        while i < num_steps:\n",
        "          gen_start = time.time()\n",
        "          action, terminal = self.replay.generate_step(ActorPolicy(self.actor), action)\n",
        "          total_gen_episode_time += time.time() - gen_start\n",
        "          if terminal:\n",
        "            map, position = self.env.reset()\n",
        "            map = resize(map, (84, 84))\n",
        "            map = map / 255\n",
        "            position = position.astype(np.float64)\n",
        "            position[0] = position[0] / 480\n",
        "            position[1] = position[1] / 640\n",
        "            action = {'map':torch.from_numpy(map).float(), 'position':torch.from_numpy(position).float()}\n",
        "\n",
        "\n",
        "          self.optimizer_critic.zero_grad()\n",
        "          self.optimizer_actor.zero_grad()\n",
        "          #maps.size() -> (seq_len, batch_size, 1, 224, 224)\n",
        "          #positons.size() -> (seq_len, batch_size, 2)\n",
        "          #rewards.size() -> (seq_len, batch_size, 1)\n",
        "          # actions -> (seq_len, batch_size, 2)\n",
        "          dataload_time = time.time()\n",
        "          maps, positions, rewards, actions, last_positions, last_maps = self.replay.sample_transitions(self.batch_size)\n",
        "          maps = maps.unsqueeze(1)\n",
        "          last_maps = last_maps.unsqueeze(1)\n",
        "\n",
        "          total_dataload_time += time.time() - dataload_time\n",
        "            \n",
        "          target_start = time.time()\n",
        "          with torch.no_grad():\n",
        "            target_action = self.actor_target(last_maps, last_positions)\n",
        "            #Should be (seq_len, batch_size, 2)\n",
        "            #Should be (seq_len, batch_size, 1)\n",
        "            crit = self.critic_target(maps, positions, target_action)\n",
        "            #print('rewards', rewards.size())\n",
        "            #print('crit', crit.size())\n",
        "            ys = rewards + self.gamma * crit\n",
        "\n",
        "          total_target_time += time.time() - target_start\n",
        "\n",
        "          update_start = time.time()\n",
        "          self.update_network(ys, maps, positions, actions, last_maps, last_positions)\n",
        "\n",
        "          self.update_target_networks()\n",
        "          total_backprop_time += time.time() - update_start\n",
        "          i += 1\n",
        "          if i % 20 == 0:\n",
        "            print('step {}'.format(i))\n",
        "            print('avg iter time {}'.format((time.time() - start) / i))\n",
        "\n",
        "            reward = 0\n",
        "            start_test = time.time()\n",
        "            for j in range(1):\n",
        "              test_map, test_position = self.replay.test_env.reset()\n",
        "              test_map = resize(test_map, (84, 84))\n",
        "              test_map = test_map / 255\n",
        "              test_position = test_position.astype(np.float64)\n",
        "              test_position[0] = test_position[0] / 480\n",
        "              test_position[1] = test_position[1] / 640\n",
        "              test_action = {'map':torch.from_numpy(test_map).float(), 'position':torch.from_numpy(test_position).float()}\n",
        "              x = 0\n",
        "              total_reward = 0\n",
        "              while x < 300:\n",
        "                test_action, test_terminal = self.replay.generate_step(ActorPolicy(self.actor), action, False)\n",
        "                print('action', test_action)\n",
        "                print('terminal', test_terminal)\n",
        "                total_reward += test_action['reward'].item()\n",
        "                if test_terminal:\n",
        "                  test_map, test_position = self.replay.test_env.reset()\n",
        "\n",
        "                  test_map = resize(test_map, (84, 84))\n",
        "                  test_map = test_map / 255\n",
        "                  test_position = test_position.astype(np.float64)\n",
        "                  test_position[0] = test_position[0] / 480\n",
        "                  test_position[1] = test_position[1] / 640\n",
        "                  test_action = {'map':torch.from_numpy(test_map).float(), 'position':torch.from_numpy(test_position).float()}\n",
        "                  break\n",
        "                x += 1\n",
        "\n",
        "            print('test reward', total_reward)\n",
        "            total_test_time = time.time() - start\n",
        "            print('avg test time', total_test_time / 5)\n",
        "            print('avg target time', total_target_time / i)\n",
        "            print('avg backprop time', total_backprop_time / i)\n",
        "            print('avg data load time', total_dataload_time / i)\n",
        "            print('avg gen episode time', total_gen_episode_time / i)\n",
        "            #  test_done = False\n",
        "            #  episode_reward = 0\n",
        "            #  the_steps = 0\n",
        "            #  s = test_env.reset()\n",
        "            #  while not test_done:\n",
        "            #    total_steps += 1\n",
        "            #    the_steps += 1\n",
        "            #    action = self.actor(torch.from_numpy(s).float().to(device='cuda')).detach().squeeze().cpu().numpy()\n",
        "            #    n_state, r, test_done, _ = test_env.step(action)\n",
        "            #    s = n_state\n",
        "            #    episode_reward += r\n",
        "\n",
        "            #  rewards.append(episode_reward)\n",
        "            #  steps_list.append(the_steps)\n",
        "            #  print('Episode reward')\n",
        "            #  print(episode_reward)\n",
        "\n",
        "        return rewards, steps_list"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjFt7JBRQVyT"
      },
      "source": [
        "reward_func = PaperRewardFunction()\n",
        "action_space = PolarActionSpace(30, 60)\n",
        "\n",
        "robot = Robot(0, True, False, 'DRL_robot_exploration/DungeonMaps',action_space,reward_func, False)\n",
        "test_robot = Robot(0, True, False, 'DRL_robot_exploration/DungeonMaps',action_space,reward_func, False)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCg-zeJMGV5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc560de-28c2-4d4a-d5f4-d1959c6b955d"
      },
      "source": [
        "replay = Replay(10000, 10, 300, 4, 2, robot, test_robot, 640, 480)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.6979, 0.3359]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.6396, 0.3984]), 'reward': tensor([0.7909]), 'action': tensor([0.9039, 0.6303], dtype=torch.float64)}\n",
            "terminal False\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.6396, 0.3984]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.7583, 0.3812]), 'reward': tensor([0.5261]), 'action': tensor([0.2810, 0.9327], dtype=torch.float64)}\n",
            "terminal False\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.7583, 0.3812]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.7583, 0.3812]), 'reward': tensor([-300.]), 'action': tensor([0.0179, 0.3206], dtype=torch.float64)}\n",
            "terminal True\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.2313, 0.4859]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.2313, 0.4859]), 'reward': tensor([-300.]), 'action': tensor([0.3512, 0.8492], dtype=torch.float64)}\n",
            "terminal True\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.7312, 0.2609]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.7312, 0.2609]), 'reward': tensor([-300.]), 'action': tensor([0.0043, 0.6481], dtype=torch.float64)}\n",
            "terminal True\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.5312, 0.4109]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.5021, 0.3516]), 'reward': tensor([0.0834]), 'action': tensor([0.5555, 0.3374], dtype=torch.float64)}\n",
            "terminal False\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.5021, 0.3516]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.5396, 0.3984]), 'reward': tensor([0.0957]), 'action': tensor([0.0852, 0.1466], dtype=torch.float64)}\n",
            "terminal False\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.5396, 0.3984]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.4854, 0.3719]), 'reward': tensor([0.1019]), 'action': tensor([0.6578, 0.0458], dtype=torch.float64)}\n",
            "terminal False\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.4854, 0.3719]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.5208, 0.4344]), 'reward': tensor([-0.8000]), 'action': tensor([0.0619, 0.4578], dtype=torch.float64)}\n",
            "terminal False\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.5208, 0.4344]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.5125, 0.3875]), 'reward': tensor([-0.8000]), 'action': tensor([0.5211, 0.0156], dtype=torch.float64)}\n",
            "terminal False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si4Aab04PDRr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "19078837-dbea-4d32-b949-4490015b6196"
      },
      "source": [
        "np.random.seed(1000)\n",
        "map, position, reward, action, last_position, last_map = replay.sample_transitions(1)\n",
        "print(reward)\n",
        "print(action)\n",
        "plt.imshow(resize(map.squeeze(0).cpu().numpy(), (480, 640)), cmap='gray')\n",
        "position = position.cpu().numpy()\n",
        "position[0, 0] = position[0, 0] * 480\n",
        "position[0, 1] = position[0, 1] * 640\n",
        "last_position = last_position.cpu().numpy()\n",
        "last_position[0, 0] = last_position[0, 0] * 480\n",
        "last_position[0, 1] = last_position[0, 1] * 640\n",
        "plt.scatter(position[0, 0], position[0, 1])\n",
        "plt.scatter(last_position[0, 0], last_position[0, 1])\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "map tensor torch.Size([168, 84])\n",
            "tensor([-300.], device='cuda:0')\n",
            "tensor([[0.0179, 0.3206]], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieHIP9WFQ0t5"
      },
      "source": [
        "linear_dims = [(256, 128), (128, 1)]\n",
        "actor_linear_dims = [(512, 1024), (1024, 512), (512, 256), (256, 2)]\n",
        "conv_dims = [(1, 32, 8), (32, 64, 4), (2, 2), (64, 64, 3), (64, 512, 7), (2, 2), (512, 64, 1)]\n",
        "lstm_hidden = 512\n",
        "lstm_out = 2\n",
        "train_length = 4\n",
        "\n",
        "\n",
        "ddpg = DDPG(robot, conv_dims, lstm_hidden, linear_dims, actor_linear_dims, train_length, replay, 1e-3,3e-4,0.99, 4)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbQtpI5A7l2D",
        "outputId": "6154e3dd-1f91-4d22-8edf-25d3b5bbe669"
      },
      "source": [
        "print('init seqs', ddpg.replay.buffer_idx)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init seqs 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsCYdcqISY73",
        "outputId": "936cecdb-d1cc-42d8-cc22-eb7cdf727a10"
      },
      "source": [
        "ddpg.train(30)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "step 20\n",
            "avg iter time 0.34838247299194336\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.5646, 0.1859]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.5646, 0.2328]), 'reward': tensor([0.3739]), 'action': tensor([0., 0.])}\n",
            "terminal False\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.5646, 0.1859]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.5646, 0.2328]), 'reward': tensor([-300.]), 'action': tensor([0., 0.])}\n",
            "terminal True\n",
            "test reward -299.6261428594589\n",
            "avg test time 1.610606575012207\n",
            "avg target time 0.0054124236106872555\n",
            "avg backprop time 0.022090494632720947\n",
            "avg data load time 0.004515421390533447\n",
            "avg gen episode time 0.08325117826461792\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-3.0000e+02, -8.0000e-01,  5.2614e-01,  1.0186e-01], device='cuda:0'),\n",
              " [])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KSbEc30VzFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13ba1e76-edee-4844-a6a5-187505c6bfef"
      },
      "source": [
        "ddpg.replay.buffer_idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "576"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kG55trJz-Cnw",
        "outputId": "56205657-135f-4057-93e8-0a8f3a6bb70e"
      },
      "source": [
        "init_policy = lambda map, pos, lengths: (torch.from_numpy(np.random.uniform(0, 1, (2,))).unsqueeze(0).unsqueeze(1), None, [1])\n",
        "ddpg.action_space = action_space\n",
        "ddpg.replay.generate_episode(init_policy, False, False, True, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-300.48157142857144"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzIsZcLC-NcR",
        "outputId": "1b98d250-0824-4631-8a98-27e497ebc1f0"
      },
      "source": [
        "np.sum(ddpg.replay.env.global_map == 255)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57088"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSsm56JjCda8",
        "outputId": "b1773da3-e2a4-4b83-90e8-f396782c133a"
      },
      "source": [
        "640 * 480"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "307200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUD6ZRLZC2GK",
        "outputId": "91d9437a-6e86-42b7-c748-44b952b1dbbd"
      },
      "source": [
        "test = nn.Linear(512, 2)\n",
        "\n",
        "vec = torch.randn(1, 1, 512)\n",
        "\n",
        "test(vec).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2z4lsEooyg9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}