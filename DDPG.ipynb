{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "DDPG.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OttoJursch/DRL_robot_exploration/blob/master/DDPG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJBqQwnOM5hX",
        "outputId": "04a8bdc7-b07d-4e56-a125-f9a8f6b09140"
      },
      "source": [
        "#Install pybind11\n",
        "!git clone https://github.com/pybind/pybind11.git\n",
        "!cd pybind11 && mkdir build && cd build && cmake .. && make install"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pybind11'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 13942 (delta 1), reused 0 (delta 0), pack-reused 13933\u001b[K\n",
            "Receiving objects: 100% (13942/13942), 5.40 MiB | 24.81 MiB/s, done.\n",
            "Resolving deltas: 100% (9486/9486), done.\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- pybind11 v2.6.2 dev1\n",
            "-- CMake 3.12.0\n",
            "-- Found PythonInterp: /usr/bin/python3.6 (found version \"3.6.9\") \n",
            "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so\n",
            "-- PYTHON 3.6.9\n",
            "-- Performing Test HAS_FLTO\n",
            "-- Performing Test HAS_FLTO - Success\n",
            "-- pybind11::lto enabled\n",
            "-- pybind11::thin_lto enabled\n",
            "-- Setting tests build type to MinSizeRel as none was specified\n",
            "-- Building tests WITHOUT Eigen, use -DDOWNLOAD_EIGEN on CMake 3.11+ to download\n",
            "-- Boost version: 1.65.1\n",
            "-- Found pytest 3.6.4\n",
            "-- Catch not detected. Interpreter tests will be skipped. Install Catch headers manually or use `cmake -DDOWNLOAD_CATCH=ON` to fetch them automatically.\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/pybind11/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target pybind11_cross_module_tests\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_cross_module_tests.dir/pybind11_cross_module_tests.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32m\u001b[1mLinking CXX shared module pybind11_cross_module_tests.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[  4%] Built target pybind11_cross_module_tests\n",
            "\u001b[35m\u001b[1mScanning dependencies of target pybind11_tests\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/pybind11_tests.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_async.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_buffers.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_builtin_casters.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_call_policies.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_callbacks.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_chrono.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_class.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_constants_and_functions.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_copy_move.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_custom_type_casters.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_docstring_options.cpp.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_enum.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_eval.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_exceptions.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_factory_constructors.cpp.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_gil_scoped.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_iostream.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_kwargs_and_defaults.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_local_bindings.cpp.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_methods_and_attributes.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_modules.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_multiple_inheritance.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_array.cpp.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_dtypes.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_vectorize.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_opaque_types.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_operator_overloading.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_pickling.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_pytypes.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_sequences_and_iterators.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_smart_ptr.cpp.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_stl.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_stl_binders.cpp.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_tagbased_polymorphic.cpp.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_union.cpp.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_virtual_functions.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX shared module pybind11_tests.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "------ pybind11_tests.cpython-36m-x86_64-linux-gnu.so file size: 2032248\n",
            "[ 95%] Built target pybind11_tests\n",
            "\u001b[35m\u001b[1mScanning dependencies of target cross_module_gil_utils\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object tests/CMakeFiles/cross_module_gil_utils.dir/cross_module_gil_utils.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared module cross_module_gil_utils.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[100%] Built target cross_module_gil_utils\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"MinSizeRel\"\n",
            "-- Installing: /usr/local/include/pybind11\n",
            "-- Installing: /usr/local/include/pybind11/operators.h\n",
            "-- Installing: /usr/local/include/pybind11/stl_bind.h\n",
            "-- Installing: /usr/local/include/pybind11/numpy.h\n",
            "-- Installing: /usr/local/include/pybind11/cast.h\n",
            "-- Installing: /usr/local/include/pybind11/options.h\n",
            "-- Installing: /usr/local/include/pybind11/functional.h\n",
            "-- Installing: /usr/local/include/pybind11/iostream.h\n",
            "-- Installing: /usr/local/include/pybind11/eval.h\n",
            "-- Installing: /usr/local/include/pybind11/stl.h\n",
            "-- Installing: /usr/local/include/pybind11/detail\n",
            "-- Installing: /usr/local/include/pybind11/detail/class.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/typeid.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/common.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/descr.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/internals.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/init.h\n",
            "-- Installing: /usr/local/include/pybind11/common.h\n",
            "-- Installing: /usr/local/include/pybind11/attr.h\n",
            "-- Installing: /usr/local/include/pybind11/complex.h\n",
            "-- Installing: /usr/local/include/pybind11/pybind11.h\n",
            "-- Installing: /usr/local/include/pybind11/buffer_info.h\n",
            "-- Installing: /usr/local/include/pybind11/pytypes.h\n",
            "-- Installing: /usr/local/include/pybind11/embed.h\n",
            "-- Installing: /usr/local/include/pybind11/eigen.h\n",
            "-- Installing: /usr/local/include/pybind11/chrono.h\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Config.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11ConfigVersion.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/FindPythonLibsNew.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Common.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Tools.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11NewTools.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Targets.cmake\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwAQeZFoM8IL",
        "outputId": "b2ecb398-e690-48f3-ee54-e62cbcf169c6"
      },
      "source": [
        "#Install Eigen\n",
        "!apt install libeigen3-dev\n",
        "!ln -sf /usr/include/eigen3/Eigen /usr/include/Eigen"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libeigen3-doc libmrpt-dev\n",
            "The following NEW packages will be installed:\n",
            "  libeigen3-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 810 kB of archives.\n",
            "After this operation, 7,128 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libeigen3-dev all 3.3.4-4 [810 kB]\n",
            "Fetched 810 kB in 1s (1,499 kB/s)\n",
            "Selecting previously unselected package libeigen3-dev.\n",
            "(Reading database ... 144865 files and directories currently installed.)\n",
            "Preparing to unpack .../libeigen3-dev_3.3.4-4_all.deb ...\n",
            "Unpacking libeigen3-dev (3.3.4-4) ...\n",
            "Setting up libeigen3-dev (3.3.4-4) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wohYNJjVNAs3",
        "outputId": "eb130439-c614-4c65-bf31-dc917cb58362"
      },
      "source": [
        "# Install dependencies on colab\n",
        "!git clone https://github.com/OttoJursch/DRL_robot_exploration.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DRL_robot_exploration'...\n",
            "remote: Enumerating objects: 209, done.\u001b[K\n",
            "remote: Counting objects: 100% (209/209), done.\u001b[K\n",
            "remote: Compressing objects: 100% (172/172), done.\u001b[K\n",
            "remote: Total 11258 (delta 126), reused 74 (delta 36), pack-reused 11049\u001b[K\n",
            "Receiving objects: 100% (11258/11258), 287.58 MiB | 35.60 MiB/s, done.\n",
            "Resolving deltas: 100% (219/219), done.\n",
            "Checking out files: 100% (10922/10922), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdbx9dj_zRQ_",
        "outputId": "d76681c9-491d-4c12-fa39-8860479993a6"
      },
      "source": [
        "!#Build the C++/pybind stuff\n",
        "!rm -rf DRL_robot_exploration/build\n",
        "!cd DRL_robot_exploration && mkdir build && cd build && cmake .. && make"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found PythonInterp: /usr/bin/python3 (found version \"3.6.9\") \n",
            "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so\n",
            "-- Performing Test HAS_FLTO\n",
            "-- Performing Test HAS_FLTO - Success\n",
            "-- Found pybind11: /usr/local/include (found version \"2.6.2\" dev1)\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/DRL_robot_exploration/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target astar\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/astar.dir/src/astar.cpp.o\u001b[0m\n",
            "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/astar.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* pybind11_init()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/astar.cpp:140:32:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kpybind11::module_::module_(const char*, const char*)\u001b[m\u001b[K’ is deprecated: Use PYBIND11_MODULE or module_::create_extension_module instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   py::module m(\"astar\", \"astar\"\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/include/pybind11/numpy.h:12:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/include/pybind11/eigen.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/DRL_robot_exploration/src/astar.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/include/pybind11/pybind11.h:897:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "     explicit \u001b[01;36m\u001b[Kmodule_\u001b[m\u001b[K(const char *name, const char *doc = nullptr) {\n",
            "              \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module astar.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[ 50%] Built target astar\n",
            "\u001b[35m\u001b[1mScanning dependencies of target inverse_sensor_model\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/inverse_sensor_model.dir/src/inverse_sensor_model.cpp.o\u001b[0m\n",
            "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/inverse_sensor_model.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* pybind11_init()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/inverse_sensor_model.cpp:64:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kpybind11::module_::module_(const char*, const char*)\u001b[m\u001b[K’ is deprecated: Use PYBIND11_MODULE or module_::create_extension_module instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   py::module m(\"inverse_sensor_model\", \"inverse_sensor_model\"\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/include/pybind11/numpy.h:12:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/include/pybind11/eigen.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/DRL_robot_exploration/src/inverse_sensor_model.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/include/pybind11/pybind11.h:897:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "     explicit \u001b[01;36m\u001b[Kmodule_\u001b[m\u001b[K(const char *name, const char *doc = nullptr) {\n",
            "              \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared module inverse_sensor_model.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[100%] Built target inverse_sensor_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH4Hccvf4Pdh",
        "outputId": "89b1e254-9904-4bf7-8984-99c3b809a8f7"
      },
      "source": [
        "!cd DRL_robot_exploration && git pull"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5BsFx_f9ONI"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "class PaperRewardFunction:\n",
        "    '''\n",
        "    Reward function from the paper\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def get_reward(self, robot_position, old_op_map, op_map, coll_index):\n",
        "        '''\n",
        "        Takes in map before step and map after step. Measures effect of sensor\n",
        "        input from last step\n",
        "        '''\n",
        "        if not coll_index:\n",
        "            reward = float(\n",
        "                np.size(np.where(op_map == 255)) - np.size(np.where(old_op_map == 255))) / 14000\n",
        "            if reward > 1:\n",
        "                reward = 1\n",
        "        else:\n",
        "            reward = -300\n",
        "        return reward\n",
        "\n",
        "\n",
        "class FrontierRewardFunction:\n",
        "    def __init__(self, reward_scale):\n",
        "        self.reward_scale = reward_scale\n",
        "        self.paper_reward = PaperRewardFunction()\n",
        "\n",
        "    def frontiers(self, op_map, map_size, points):\n",
        "        y_len = map_size[0]\n",
        "        x_len = map_size[1]\n",
        "        mapping = op_map.copy()\n",
        "        # 0-1 unknown area map\n",
        "        mapping = (mapping == 127) * 1\n",
        "        mapping = np.lib.pad(mapping, ((1, 1), (1, 1)),\n",
        "                             'constant',\n",
        "                             constant_values=0)\n",
        "        fro_map = mapping[2:][:, 1:x_len + 1] + mapping[:y_len][:, 1:x_len + 1] + mapping[1:y_len + 1][:, 2:] + \\\n",
        "                  mapping[1:y_len + 1][:, :x_len] + mapping[:y_len][:, 2:] + mapping[2:][:, :x_len] + mapping[2:][:,\n",
        "                                                                                                      2:] + \\\n",
        "                  mapping[:y_len][:, :x_len]\n",
        "\n",
        "        ind_free = np.where(op_map.ravel(order='F') == 255)[0]\n",
        "        ind_fron_1 = np.where(1 < fro_map.ravel(order='F'))[0]\n",
        "        ind_fron_2 = np.where(fro_map.ravel(order='F') < 8)[0]\n",
        "        ind_fron = np.intersect1d(ind_fron_1, ind_fron_2)\n",
        "        ind_to = np.intersect1d(ind_free, ind_fron)\n",
        "        f = points[ind_to]\n",
        "        f = f.astype(int)\n",
        "        return f\n",
        "\n",
        "    def map_points(self, map_glo):\n",
        "        map_x = map_glo.shape[1]\n",
        "        map_y = map_glo.shape[0]\n",
        "        x = np.linspace(0, map_x - 1, map_x)\n",
        "        y = np.linspace(0, map_y - 1, map_y)\n",
        "        t1, t2 = np.meshgrid(x, y)\n",
        "        points = np.vstack([t1.T.ravel(), t2.T.ravel()]).T\n",
        "        return points\n",
        "\n",
        "    def get_reward(self, robot_pos, old_op_map, op_map, coll_index):\n",
        "        paper_reward = self.paper_reward.get_reward(robot_pos, old_op_map,\n",
        "                                                    op_map, coll_index)\n",
        "\n",
        "        #If there was a collision return the collision reward\n",
        "        if coll_index:\n",
        "            return paper_reward\n",
        "\n",
        "        frontiers = np.array(\n",
        "            self.frontiers(op_map, op_map.shape, self.map_points(op_map)))\n",
        "\n",
        "        min_frontier_dist = -np.min(np.linalg.norm(robot_pos - frontiers, axis=1))\n",
        "        return self.reward_scale * min_frontier_dist + paper_reward\n",
        "\n",
        "sqrt2 = 2**0.5 +0.1\n",
        "class PolarActionSpace:\n",
        "    '''\n",
        "    Action space is polar representation of vector robot should take from its\n",
        "    current position\n",
        "\n",
        "    This class will take that and add it to the current robot position to get \n",
        "    '''\n",
        "    def __init__(self, min_travel, max_travel):\n",
        "        self.max_distance = max_travel\n",
        "        self.min_travel = min_travel\n",
        "\n",
        "    def get_action(self, action_polar_coords, robot_position):\n",
        "        angle = action_polar_coords[0] * (2 * np.pi)\n",
        "        dist = action_polar_coords[1] * (self.max_distance - self.min_travel) + self.min_travel\n",
        "        dx = dist * np.sin(angle)\n",
        "        dy = dist * np.cos(angle)\n",
        "\n",
        "        return np.array([dx, dy])\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l08KzoEf_xt3"
      },
      "source": [
        "from scipy import spatial\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import numpy.ma as ma\n",
        "import time\n",
        "import sys\n",
        "from scipy import ndimage\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sys.path.append('DRL_robot_exploration')\n",
        "from DRL_robot_exploration.build.inverse_sensor_model import *\n",
        "from DRL_robot_exploration.build.astar import *\n",
        "from random import shuffle\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "class Robot:\n",
        "    def __init__(self,\n",
        "                 index_map,\n",
        "                 train,\n",
        "                 plot,\n",
        "                 root_dir,\n",
        "                 action_space,\n",
        "                 reward_function,\n",
        "                 do_rescue,\n",
        "                 shuffle=True):\n",
        "        self.mode = train\n",
        "        self.action_space = action_space\n",
        "        self.plot = plot\n",
        "        self.root_dir = root_dir\n",
        "        self.index_map = index_map\n",
        "        self.do_rescue = do_rescue\n",
        "        self.reward_function = reward_function\n",
        "        self.reset(index_map, shuffle)\n",
        "\n",
        "    def reset(self, index_map=None, do_shuffle=True):\n",
        "        if self.mode:\n",
        "            self.map_dir = os.path.join(self.root_dir, 'train')\n",
        "        else:\n",
        "            self.map_dir = os.path.join(self.root_dir, 'test')\n",
        "        self.map_list = os.listdir(self.map_dir)\n",
        "        self.map_number = np.size(self.map_list)\n",
        "        if self.mode and do_shuffle:\n",
        "            shuffle(self.map_list)\n",
        "        if index_map is None:\n",
        "            index_map = random.choice(range(len(self.map_list)))\n",
        "        self.li_map = index_map\n",
        "        self.global_map, self.robot_position = self.map_setup(\n",
        "            self.map_dir + '/' + self.map_list[self.li_map])\n",
        "        self.op_map = np.ones(self.global_map.shape) * 127\n",
        "        self.map_size = np.shape(self.global_map)\n",
        "        self.finish_percent = 0.985\n",
        "        self.resolution = 1\n",
        "        self.sensor_range = 80\n",
        "        self.old_position = np.zeros([2])\n",
        "        self.old_op_map = np.empty([0])\n",
        "        #current_dir = os.path.dirname(os.path.realpath(__file__))\n",
        "        self.t = self.map_points(self.global_map)\n",
        "        self.free_tree = spatial.KDTree(\n",
        "            self.free_points(self.global_map).tolist())\n",
        "        self.robot_size = 6\n",
        "        self.local_size = 40\n",
        "        if self.plot:\n",
        "            self.xPoint = np.array([self.robot_position[0]])\n",
        "            self.yPoint = np.array([self.robot_position[1]])\n",
        "            self.x2frontier = np.empty([0])\n",
        "            self.y2frontier = np.empty([0])\n",
        "\n",
        "\n",
        "        return self.begin(), self.robot_position\n",
        "\n",
        "    def begin(self):\n",
        "        self.op_map = self.inverse_sensor(self.robot_position,\n",
        "                                          self.sensor_range, self.op_map,\n",
        "                                          self.global_map)\n",
        "        step_map = self.robot_model(self.robot_position, self.robot_size,\n",
        "                                    self.t, self.op_map)\n",
        "        map_local = self.local_map(self.robot_position, step_map,\n",
        "                                   self.map_size,\n",
        "                                   self.sensor_range + self.local_size)\n",
        "        if self.plot:\n",
        "            self.plot_env()\n",
        "        return self.op_map\n",
        "\n",
        "    def step(self, action_index):\n",
        "        terminal = False\n",
        "        complete = False\n",
        "        new_location = False\n",
        "        all_map = False\n",
        "        self.old_position = self.robot_position.copy()\n",
        "        self.old_op_map = self.op_map.copy()\n",
        "\n",
        "        # take action\n",
        "        self.take_action(action_index, self.robot_position)\n",
        "\n",
        "        # collision check\n",
        "        collision_points, collision_index = self.collision_check(\n",
        "            self.old_position, self.robot_position, self.map_size,\n",
        "            self.global_map)\n",
        "\n",
        "        if collision_index:\n",
        "            self.robot_position = self.nearest_free(self.free_tree,\n",
        "                                                    collision_points)\n",
        "            self.op_map = self.inverse_sensor(self.robot_position,\n",
        "                                              self.sensor_range, self.op_map,\n",
        "                                              self.global_map)\n",
        "            step_map = self.robot_model(self.robot_position, self.robot_size,\n",
        "                                        self.t, self.op_map)\n",
        "        else:\n",
        "            self.op_map = self.inverse_sensor(self.robot_position,\n",
        "                                              self.sensor_range, self.op_map,\n",
        "                                              self.global_map)\n",
        "            step_map = self.robot_model(self.robot_position, self.robot_size,\n",
        "                                        self.t, self.op_map)\n",
        "\n",
        "        map_local = self.local_map(self.robot_position, step_map,\n",
        "                                   self.map_size,\n",
        "                                   self.sensor_range + self.local_size)\n",
        "        reward = self.reward_function.get_reward(self.robot_position,\n",
        "                                                 self.old_op_map, self.op_map,\n",
        "                                                 collision_index)\n",
        "\n",
        "        if reward <= 0.02 and not collision_index:\n",
        "            reward = -0.8\n",
        "            new_location = True\n",
        "            #terminal = True\n",
        "\n",
        "        # during training, the robot is relocated if it has a collision\n",
        "        # during testing, the robot will use collision check to avoid the collision\n",
        "        if collision_index:\n",
        "            if not self.mode:\n",
        "                new_location = False\n",
        "                terminal = False\n",
        "            else:\n",
        "                new_location = True\n",
        "                terminal = True\n",
        "            if self.plot and self.mode:\n",
        "                self.xPoint = ma.append(self.xPoint, self.robot_position[0])\n",
        "                self.yPoint = ma.append(self.yPoint, self.robot_position[1])\n",
        "                self.plot_env()\n",
        "            self.robot_position = self.old_position.copy()\n",
        "            self.op_map = self.old_op_map.copy()\n",
        "            if self.plot and self.mode:\n",
        "                self.xPoint[self.xPoint.size - 1] = ma.masked\n",
        "                self.yPoint[self.yPoint.size - 1] = ma.masked\n",
        "        else:\n",
        "            if self.plot:\n",
        "                self.xPoint = ma.append(self.xPoint, self.robot_position[0])\n",
        "                self.yPoint = ma.append(self.yPoint, self.robot_position[1])\n",
        "                self.plot_env()\n",
        "\n",
        "        # check if exploration is finished\n",
        "        if np.size(np.where(self.op_map == 255)) / np.size(\n",
        "                np.where(self.global_map == 255)) > self.finish_percent:\n",
        "            self.li_map += 1\n",
        "            if self.li_map == self.map_number:\n",
        "                self.li_map = 0\n",
        "                all_map = True\n",
        "            #self.__init__(self.li_map, self.mode, self.plot)\n",
        "            complete = True\n",
        "            new_location = False\n",
        "            terminal = True\n",
        "\n",
        "        return (\n",
        "            self.op_map, self.robot_position\n",
        "        ), reward, terminal, complete, new_location, collision_index, all_map\n",
        "\n",
        "    def rescuer(self):\n",
        "        complete = False\n",
        "        all_map = False\n",
        "        pre_position = self.robot_position.copy()\n",
        "        self.robot_position = self.frontier(self.op_map, self.map_size, self.t)\n",
        "        self.op_map = self.inverse_sensor(self.robot_position,\n",
        "                                          self.sensor_range, self.op_map,\n",
        "                                          self.global_map)\n",
        "        step_map = self.robot_model(self.robot_position, self.robot_size,\n",
        "                                    self.t, self.op_map)\n",
        "        map_local = self.local_map(self.robot_position, step_map,\n",
        "                                   self.map_size,\n",
        "                                   self.sensor_range + self.local_size)\n",
        "\n",
        "        if self.plot:\n",
        "            path = self.astar_path(self.op_map, pre_position.tolist(),\n",
        "                                   self.robot_position.tolist())\n",
        "            self.x2frontier = ma.append(self.x2frontier, ma.masked)\n",
        "            self.y2frontier = ma.append(self.y2frontier, ma.masked)\n",
        "            self.x2frontier = ma.append(self.x2frontier, path[1, :])\n",
        "            self.y2frontier = ma.append(self.y2frontier, path[0, :])\n",
        "            self.xPoint = ma.append(self.xPoint, ma.masked)\n",
        "            self.yPoint = ma.append(self.yPoint, ma.masked)\n",
        "            self.xPoint = ma.append(self.xPoint, self.robot_position[0])\n",
        "            self.yPoint = ma.append(self.yPoint, self.robot_position[1])\n",
        "            self.plot_env()\n",
        "\n",
        "        if np.size(np.where(self.op_map == 255)) / np.size(\n",
        "                np.where(self.global_map == 255)) > self.finish_percent:\n",
        "            self.li_map += 1\n",
        "            if self.li_map == self.map_number:\n",
        "                self.li_map = 0\n",
        "                all_map = True\n",
        "            #self.__init__(self.li_map, self.mode, self.plot)\n",
        "            complete = True\n",
        "            new_location = False\n",
        "            terminal = True\n",
        "        return map_local, complete, all_map\n",
        "\n",
        "    def take_action(self, action_index, robot_position):\n",
        "        move_action = self.action_space.get_action(action_index,\n",
        "                                                   robot_position)\n",
        "\n",
        "        robot_position[0] = np.round(robot_position[0] + move_action[0])\n",
        "        robot_position[1] = np.round(robot_position[1] + move_action[1])\n",
        "\n",
        "    def map_setup(self, location):\n",
        "        global_map = (io.imread(location, 1) * 255).astype(int)\n",
        "        robot_location = np.nonzero(global_map == 208)\n",
        "        robot_location = np.array([\n",
        "            np.array(robot_location)[1, 127],\n",
        "            np.array(robot_location)[0, 127]\n",
        "        ])\n",
        "        global_map = (global_map > 150)\n",
        "        global_map = global_map * 254 + 1\n",
        "        return global_map, robot_location\n",
        "\n",
        "    def map_points(self, map_glo):\n",
        "        map_x = map_glo.shape[1]\n",
        "        map_y = map_glo.shape[0]\n",
        "        x = np.linspace(0, map_x - 1, map_x)\n",
        "        y = np.linspace(0, map_y - 1, map_y)\n",
        "        t1, t2 = np.meshgrid(x, y)\n",
        "        points = np.vstack([t1.T.ravel(), t2.T.ravel()]).T\n",
        "        return points\n",
        "\n",
        "    def local_map(self, robot_location, map_glo, map_size, local_size):\n",
        "        minX = robot_location[0] - local_size\n",
        "        maxX = robot_location[0] + local_size\n",
        "        minY = robot_location[1] - local_size\n",
        "        maxY = robot_location[1] + local_size\n",
        "\n",
        "        if minX < 0:\n",
        "            maxX = abs(minX) + maxX\n",
        "            minX = 0\n",
        "        if maxX > map_size[1]:\n",
        "            minX = minX - (maxX - map_size[1])\n",
        "            maxX = map_size[1]\n",
        "        if minY < 0:\n",
        "            maxY = abs(minY) + maxY\n",
        "            minY = 0\n",
        "        if maxY > map_size[0]:\n",
        "            minY = minY - (maxY - map_size[0])\n",
        "            maxY = map_size[0]\n",
        "\n",
        "        map_loc = map_glo[minY:maxY][:, minX:maxX]\n",
        "        return map_loc\n",
        "\n",
        "    def free_points(self, op_map):\n",
        "        index = np.where(op_map == 255)\n",
        "        free = np.asarray([index[1], index[0]]).T\n",
        "        return free\n",
        "\n",
        "    def nearest_free(self, tree, point):\n",
        "        pts = np.atleast_2d(point)\n",
        "        index = tuple(tree.query(pts)[1])\n",
        "        nearest = tree.data[index]\n",
        "        return nearest\n",
        "\n",
        "    def robot_model(self, position, robot_size, points, map_glo):\n",
        "        map_copy = map_glo.copy()\n",
        "        robot_points = self.range_search(position, robot_size, points)\n",
        "        for i in range(0, robot_points.shape[0]):\n",
        "            rob_loc = np.int32(robot_points[i, :])\n",
        "            rob_loc = np.flipud(rob_loc)\n",
        "            map_copy[tuple(rob_loc)] = 76\n",
        "        map_with_robot = map_copy\n",
        "        return map_with_robot\n",
        "\n",
        "    def range_search(self, position, r, points):\n",
        "        nvar = position.shape[0]\n",
        "        r2 = r**2\n",
        "        s = 0\n",
        "        for d in range(0, nvar):\n",
        "            s += (points[:, d] - position[d])**2\n",
        "        idx = np.nonzero(s <= r2)\n",
        "        idx = np.asarray(idx).ravel()\n",
        "        inrange_points = points[idx, :]\n",
        "        return inrange_points\n",
        "\n",
        "    def collision_check(self, start_point, end_point, map_size, map_glo):\n",
        "        x0, y0 = start_point.round()\n",
        "        x1, y1 = end_point.round()\n",
        "        dx, dy = abs(x1 - x0), abs(y1 - y0)\n",
        "        x, y = x0, y0\n",
        "        error = dx - dy\n",
        "        x_inc = 1 if x1 > x0 else -1\n",
        "        y_inc = 1 if y1 > y0 else -1\n",
        "        dx *= 2\n",
        "        dy *= 2\n",
        "\n",
        "        coll_points = np.ones((1, 2), np.uint8) * -1\n",
        "\n",
        "        while 0 <= x < map_size[1] and 0 <= y < map_size[0]:\n",
        "            k = map_glo.item(y, x)\n",
        "            if k == 1:\n",
        "                coll_points.itemset((0, 0), x)\n",
        "                coll_points.itemset((0, 1), y)\n",
        "                break\n",
        "\n",
        "            if x == end_point[0] and y == end_point[1]:\n",
        "                break\n",
        "\n",
        "            if error > 0:\n",
        "                x += x_inc\n",
        "                error -= dy\n",
        "            else:\n",
        "                y += y_inc\n",
        "                error += dx\n",
        "        if np.sum(coll_points) == -2:\n",
        "            coll_index = False\n",
        "        else:\n",
        "            coll_index = True\n",
        "\n",
        "        return coll_points, coll_index\n",
        "\n",
        "    def inverse_sensor(self, robot_position, sensor_range, op_map, map_glo):\n",
        "        op_map = inverse_sensor_model(robot_position[0], robot_position[1],\n",
        "                                      sensor_range, op_map, map_glo)\n",
        "        return op_map\n",
        "\n",
        "    def frontier(self, op_map, map_size, points):\n",
        "        y_len = map_size[0]\n",
        "        x_len = map_size[1]\n",
        "        mapping = op_map.copy()\n",
        "        # 0-1 unknown area map\n",
        "        mapping = (mapping == 127) * 1\n",
        "        mapping = np.lib.pad(mapping, ((1, 1), (1, 1)),\n",
        "                             'constant',\n",
        "                             constant_values=0)\n",
        "        fro_map = mapping[2:][:, 1:x_len + 1] + mapping[:y_len][:, 1:x_len + 1] + mapping[1:y_len + 1][:, 2:] + \\\n",
        "                  mapping[1:y_len + 1][:, :x_len] + mapping[:y_len][:, 2:] + mapping[2:][:, :x_len] + mapping[2:][:,\n",
        "                                                                                                      2:] + \\\n",
        "                  mapping[:y_len][:, :x_len]\n",
        "        ind_free = np.where(op_map.ravel(order='F') == 255)[0]\n",
        "        ind_fron_1 = np.where(1 < fro_map.ravel(order='F'))[0]\n",
        "        ind_fron_2 = np.where(fro_map.ravel(order='F') < 8)[0]\n",
        "        ind_fron = np.intersect1d(ind_fron_1, ind_fron_2)\n",
        "        ind_to = np.intersect1d(ind_free, ind_fron)\n",
        "        f = points[ind_to]\n",
        "        f = f.astype(int)\n",
        "        return f[0]\n",
        "\n",
        "    def unique_rows(self, a):\n",
        "        a = np.ascontiguousarray(a)\n",
        "        unique_a = np.unique(a.view([('', a.dtype)] * a.shape[1]))\n",
        "        result = unique_a.view(a.dtype).reshape(\n",
        "            (unique_a.shape[0], a.shape[1]))\n",
        "        result = result[~np.isnan(result).any(axis=1)]\n",
        "        return result\n",
        "\n",
        "    def astar_path(self, weights, start, goal, allow_diagonal=True):\n",
        "        temp_start = [start[1], start[0]]\n",
        "        temp_goal = [goal[1], goal[0]]\n",
        "        temp_weight = (weights < 150) * 254 + 1\n",
        "        # For the heuristic to be valid, each move must cost at least 1.\n",
        "        if temp_weight.min(axis=None) < 1.:\n",
        "            raise ValueError(\"Minimum cost to move must be 1, but got %f\" %\n",
        "                             (temp_weight.min(axis=None)))\n",
        "        # Ensure start is within bounds.\n",
        "        if (temp_start[0] < 0 or temp_start[0] >= temp_weight.shape[0]\n",
        "                or temp_start[1] < 0 or temp_start[1] >= temp_weight.shape[1]):\n",
        "            raise ValueError(\"Start lies outside grid.\")\n",
        "        # Ensure goal is within bounds.\n",
        "        if (temp_goal[0] < 0 or temp_goal[0] >= temp_weight.shape[0]\n",
        "                or temp_goal[1] < 0 or temp_goal[1] >= temp_weight.shape[1]):\n",
        "            raise ValueError(\"Goal of lies outside grid.\")\n",
        "\n",
        "        height, width = temp_weight.shape\n",
        "        start_idx = np.ravel_multi_index(temp_start, (height, width))\n",
        "        goal_idx = np.ravel_multi_index(temp_goal, (height, width))\n",
        "\n",
        "        path = astar(\n",
        "            temp_weight.flatten(),\n",
        "            height,\n",
        "            width,\n",
        "            start_idx,\n",
        "            goal_idx,\n",
        "            allow_diagonal,\n",
        "        )\n",
        "        return path\n",
        "\n",
        "    def plot_env(self):\n",
        "        plt.cla()\n",
        "        plt.imshow(self.op_map, cmap='gray')\n",
        "        plt.axis((0, self.map_size[1], self.map_size[0], 0))\n",
        "        plt.plot(self.xPoint, self.yPoint, 'b', linewidth=2)\n",
        "        plt.plot(self.x2frontier, self.y2frontier, 'r', linewidth=2)\n",
        "        plt.plot(self.robot_position[0],\n",
        "                 self.robot_position[1],\n",
        "                 'mo',\n",
        "                 markersize=8)\n",
        "        plt.plot(self.xPoint[0], self.yPoint[0], 'co', markersize=8)\n",
        "        plt.pause(0.05)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edUqbZxCxIKW",
        "outputId": "10f07d76-0d02-45c3-e56f-66d20b1edeb1"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "np.random.seed(1000)\n",
        "random.seed(10)\n",
        "\n",
        "reward_func = PaperRewardFunction()\n",
        "action_space = PolarActionSpace(30, 60)\n",
        "\n",
        "robot = Robot(0, True, False, 'DRL_robot_exploration/DungeonMaps',action_space,reward_func, False)\n",
        "\n",
        "test_action = np.array([0.75, 0.5])\n",
        "print('start')\n",
        "print(robot.robot_position)\n",
        "\n",
        "for i in range(10):\n",
        "  (map, loc), reward, terminal, complete, new_loc, collision, all_map = robot.step(test_action)\n",
        "  print('reward', reward)\n",
        "  print('robot loc', loc)\n",
        "  print(collision)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start\n",
            "[463  71]\n",
            "reward 0.2057142857142857\n",
            "robot loc [418  71]\n",
            "False\n",
            "reward 0.2057142857142857\n",
            "robot loc [373  71]\n",
            "False\n",
            "reward 0.206\n",
            "robot loc [328  71]\n",
            "False\n",
            "reward 0.312\n",
            "robot loc [283  71]\n",
            "False\n",
            "reward 0.6817142857142857\n",
            "robot loc [238  71]\n",
            "False\n",
            "reward 0.5524285714285714\n",
            "robot loc [193  71]\n",
            "False\n",
            "reward 0.19457142857142856\n",
            "robot loc [148  71]\n",
            "False\n",
            "reward -300\n",
            "robot loc [148  71]\n",
            "True\n",
            "reward -300\n",
            "robot loc [148  71]\n",
            "True\n",
            "reward -300\n",
            "robot loc [148  71]\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO_EJKEoNC6T"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchsummary\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
        "\n",
        "def build_conv_feature_extractor(conv_dims, act):\n",
        "  #Create Conv2D + MaxPool layers\n",
        "  conv_layers = [nn.Conv2d(*conv_dim) if len(conv_dim) == 3 else nn.MaxPool2d(conv_dim) for conv_dim in conv_dims]\n",
        "  total_layers = []\n",
        "\n",
        "  #Add ReLU activations after each conv layer\n",
        "  for layer in conv_layers:\n",
        "    total_layers.append(layer)\n",
        "    if type(layer) == nn.Conv2d:\n",
        "      total_layers.append(act())\n",
        "  return nn.Sequential(*total_layers)\n",
        "  \n",
        "\n",
        "def get_output_shape(model, image_dim):\n",
        "    return model(torch.rand(*(image_dim))).data.shape\n",
        "\n",
        "class RNNActor(nn.Module):\n",
        "  #TODO Determine if the action space allows negative numbers\n",
        "  #Potentially replace tanh with sigmoid\n",
        "  def __init__(self, conv_dims, lstm_hidden, train_length, input_size=(1, 1,84,84), act=nn.ReLU, final_act=nn.Sigmoid):\n",
        "    super(RNNActor, self).__init__()\n",
        "\n",
        "    self.conv_mod = build_conv_feature_extractor(conv_dims, act)\n",
        "    \n",
        "    #Silly way to determine the size going into the RNN\n",
        "    with torch.no_grad():\n",
        "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
        "\n",
        "    print('LSTM Input Size', feature_size)\n",
        "\n",
        "    #Construct LSTM\n",
        "    self.lstm_hidden = lstm_hidden\n",
        "    self.lstm_input = np.prod(list(feature_size)) + 2\n",
        "    self.lstm = nn.LSTM(self.lstm_input, lstm_hidden)\n",
        "    self.linear = nn.Linear(lstm_hidden, 2)\n",
        "    self.train_length = train_length\n",
        "    self.final_act = final_act()\n",
        "\n",
        "  def forward(self, image, positions, lengths, hidden_state=None):\n",
        "    batch_size = image.size()[1]\n",
        "    seq_length = image.size()[0]\n",
        "    conv = self.conv_mod(image.view((seq_length * batch_size, 1, 84, 84)))\n",
        "\n",
        "    flat = conv.view(-1).view(seq_length, batch_size, self.lstm_input - 2)\n",
        "    state = torch.cat((flat, positions), 2)\n",
        "    packed = pack_padded_sequence(state, lengths, enforce_sorted=False)\n",
        "    self.lstm.flatten_parameters()\n",
        "    if hidden_state is not None:\n",
        "      states, final_state = self.lstm(packed, hidden_state)\n",
        "    else:\n",
        "      states, final_state = self.lstm(packed)\n",
        "\n",
        "    unpacked, end_lengths = pad_packed_sequence(states)\n",
        "    final = self.linear(unpacked)\n",
        "    return self.final_act(final), final_state, end_lengths"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgxUtoeMJ8Pa"
      },
      "source": [
        "def build_dense_regression(linear_dims, act, final_act=None):\n",
        "  linear_layers = [nn.Linear(*linear_dim)  for linear_dim in linear_dims]\n",
        "  activations = [act() for layer in range(len(linear_layers) - 1)]\n",
        "  if final_act is not None:\n",
        "    activations.append(final_act())\n",
        "  else:\n",
        "    activations.append(nn.Identity())\n",
        "  return nn.Sequential(*[val for tup in zip(*[linear_layers, activations]) for val in tup]\n",
        ")\n",
        "\n",
        "class CNNCritic(nn.Module):\n",
        "  def __init__(self, conv_dims, fc_dims, input_size=(1, 1,84,84), conv_act=nn.ReLU, fc_act=nn.ReLU):\n",
        "    super(CNNCritic, self).__init__()\n",
        "    self.conv_mod = build_conv_feature_extractor(conv_dims, conv_act)\n",
        "\n",
        "    #Silly way to determine the size going into the RNN\n",
        "    with torch.no_grad():\n",
        "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
        "\n",
        "    #Add 4 for action + position\n",
        "    feature_size = np.prod(list(feature_size)) + 4\n",
        "    first_output = fc_dims[0][0]\n",
        "    fc_dims.insert(0, (feature_size, first_output))\n",
        "\n",
        "    self.fc = build_dense_regression(fc_dims, fc_act)\n",
        "    self.fc_dims = feature_size\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self, map, positions, action):\n",
        "    batch_size = map.size()[1]\n",
        "    seq_length =  map.size()[0]\n",
        "    conv = self.conv_mod(map.view((seq_length * batch_size, 1, 84, 84)))\n",
        "\n",
        "    flat = conv.view(-1).view(seq_length, batch_size, self.fc_dims - 4)\n",
        "    total_feats = torch.cat((flat, positions, action), 2)\n",
        "    return self.fc(total_feats)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjDpPhJi8gvh"
      },
      "source": [
        "class ActorPolicy:\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "\n",
        "  def __call__(self, map, position):\n",
        "    map = map.to(device='cuda').float().unsqueeze(0).unsqueeze(1)\n",
        "    position = position.to(device='cuda').float().unsqueeze(0)\n",
        "\n",
        "    result = self.model(map, position)\n",
        "\n",
        "    return result.cpu().squeeze(0)\n",
        "\n",
        "class CNNCriticNoSeq(nn.Module):\n",
        "  def __init__(self, conv_dims, fc_dims, input_size=(1, 1,84,84), conv_act=nn.ReLU, fc_act=nn.ReLU):\n",
        "    super(CNNCriticNoSeq, self).__init__()\n",
        "    self.conv_mod = build_conv_feature_extractor(conv_dims, conv_act)\n",
        "\n",
        "    #Silly way to determine the size going into the RNN\n",
        "    with torch.no_grad():\n",
        "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
        "\n",
        "    #Add 4 for action + position\n",
        "    feature_size = np.prod(list(feature_size)) + 4\n",
        "    first_output = fc_dims[0][0]\n",
        "    fc_dims.insert(0, (feature_size, first_output))\n",
        "\n",
        "    self.fc = build_dense_regression(fc_dims, fc_act)\n",
        "    self.fc_dims = feature_size\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self, map, positions, action):\n",
        "    conv = self.conv_mod(map)\n",
        "    batch_size = map.size()[0]\n",
        "    flat = conv.view(batch_size, self.fc_dims - 4)\n",
        "    print('flat', flat.size())\n",
        "    print('positions', positions.size())\n",
        "    total_feats = torch.cat((flat, positions, action), 1)\n",
        "    return self.fc(total_feats)\n",
        "\n",
        "\n",
        "\n",
        "class FCActor(nn.Module):\n",
        "  #TODO Determine if the action space allows negative numbers\n",
        "  #Potentially replace tanh with sigmoid\n",
        "  def __init__(self, conv_dims, linear_dims, input_size=(1, 1,84,84), act=nn.ReLU, final_act=nn.Sigmoid):\n",
        "    super(FCActor, self).__init__()\n",
        "    self.conv_mod = build_conv_feature_extractor(conv_dims, act)\n",
        "\n",
        "    #Silly way to determine the size going into the RNN\n",
        "    with torch.no_grad():\n",
        "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
        "\n",
        "    #Add 4 for action + position\n",
        "    feature_size = np.prod(list(feature_size)) + 2\n",
        "    first_output = linear_dims[0][0]\n",
        "    linear_dims.insert(0, (feature_size, first_output))\n",
        "\n",
        "    self.fc = build_dense_regression(linear_dims, act, final_act)\n",
        "    self.fc_dims = feature_size\n",
        "\n",
        "  def forward(self, map, positions):\n",
        "    conv = self.conv_mod(map)\n",
        "\n",
        "    flat = conv.view(map.size()[0], self.fc_dims - 2)\n",
        "    print('flat', flat.size())\n",
        "    print('positions', positions.size())\n",
        "    total_feats = torch.cat((flat, positions), 1)\n",
        "    return self.fc(total_feats)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-eCOZDBC3pg"
      },
      "source": [
        "\"\"\" Learn a policy using DDPG for the reach task\"\"\"\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import MultivariateNormal\n",
        "from torch.nn import MSELoss\n",
        "import random\n",
        "from skimage.transform import resize\n",
        "from io import BytesIO\n",
        "import itertools\n",
        "import lmdb\n",
        "from itertools import zip_longest\n",
        "\n",
        "import gym\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import time\n",
        "\n",
        "# TODO: A function to soft update target networks\n",
        "def weighSync(target_model, source_model, tau=0.001):\n",
        "  for (target, src) in zip(target_model.parameters(), source_model.parameters()):\n",
        "    target.data = (1-tau) * target.data + tau * src.data \n",
        "\n",
        "def grouper(iterable, n, fillvalue=None):\n",
        "  '''Collect data into fixed-length chunks or blocks'''\n",
        "  # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
        "  args = [iter(iterable)] * n\n",
        "  return zip_longest(*args, fillvalue=fillvalue)\n",
        "\n",
        "# TODO: Write the ReplayBuffer\n",
        "class Replay():\n",
        "    def __init__(self, buffer_size, init_sequences, max_episode_length, sequence_length, action_dim, env, test_env, env_width, env_height):\n",
        "        \"\"\"\n",
        "        A function to initialize the replay buffer.\n",
        "\n",
        "        param: init_length : Initial number of transitions to collect\n",
        "        param: state_dim : Size of the state space\n",
        "        param: action_dim : Size of the action space\n",
        "        param: env : gym environment object\n",
        "        \"\"\"\n",
        "        try:\n",
        "          os.remove('db.lmdb')\n",
        "        except OSError:\n",
        "          pass\n",
        "        self.db = lmdb.open('db.lmdb', map_size=30e9)\n",
        "        self.buffer = [{}] * buffer_size\n",
        "        self.noise = MultivariateNormal(torch.zeros(2), torch.diag(torch.tensor([0.2, 0.2])))\n",
        "        self.sequence_length = sequence_length\n",
        "        self.max_episode_length = max_episode_length\n",
        "        self.env = env\n",
        "        self.test_env = test_env\n",
        "        state = self.env.reset(self.env.index_map, False)\n",
        "        self.env_width = env_width\n",
        "        self.env_height = env_height\n",
        "        self.buffer_idx = 0\n",
        "        self.total_steps = 0\n",
        "        last_state = env.reset(self.env.index_map, False)\n",
        "        init_policy = lambda map, pos: torch.from_numpy(np.random.uniform(0, 1, (2,)))\n",
        "        self.full_buffer = False\n",
        "        self.current_pointer = 0\n",
        "\n",
        "        map, position = self.env.reset()\n",
        "        map = resize(map, (84, 84))\n",
        "        map = map / 255\n",
        "        position = position.astype(np.float64)\n",
        "        position[0] = position[0] / 480\n",
        "        position[1] = position[1] / 640\n",
        "        action = {'map':torch.from_numpy(map).float(), 'position':torch.from_numpy(position).float()}\n",
        "        \n",
        "        while self.buffer_idx < init_sequences:\n",
        "          action, terminal = self.generate_step(init_policy, action, False)\n",
        "          print('action', action)\n",
        "          print('terminal', terminal)\n",
        "          if terminal:\n",
        "            map, position = self.env.reset()\n",
        "\n",
        "            map = resize(map, (84, 84))\n",
        "            map = map / 255\n",
        "            position = position.astype(np.float64)\n",
        "            position[0] = position[0] / 480\n",
        "            position[1] = position[1] / 640\n",
        "            action = {'map':torch.from_numpy(map).float(), 'position':torch.from_numpy(position).float()}\n",
        "\n",
        "\n",
        "    def generate_step(self, policy, last_transition, add_noise=True, store=True):\n",
        "      episode = []\n",
        "      last_map = last_transition['map']\n",
        "      last_position = last_transition['position']\n",
        "\n",
        "      terminal = False\n",
        "\n",
        "      total_reward = 0\n",
        "\n",
        "      action = policy(last_map, last_position)\n",
        "      if add_noise:\n",
        "        sampled = self.noise.sample()\n",
        "        #print('adding noise', sampled)\n",
        "        action = action.cpu() + sampled\n",
        "      else:\n",
        "        action = action.cpu()\n",
        "\n",
        "      action_np = action.detach().numpy().flatten()\n",
        "      if action_np[0] < 0:\n",
        "        action_np[0] = abs(action_np[0])\n",
        "      elif action_np[0] > 1:\n",
        "        action_np[0] = action_np[0] - 1\n",
        "\n",
        "      if action_np[1] < 0:\n",
        "        action_np[1] = abs(action_np[1])\n",
        "      elif action_np[1] > 1:\n",
        "        action_np[1] = action_np[1] - 1\n",
        "\n",
        "    \n",
        "\n",
        "      (map, loc), reward, terminal, complete, new_loc, collision, all_map = self.env.step(action_np)\n",
        "      map = resize(map, (84, 84))\n",
        "      map = (map / 255)\n",
        "      loc = loc.astype(np.float64)\n",
        "      loc[0] = loc[0] / 480.0\n",
        "      loc[1] = loc[1] / 640.0\n",
        "\n",
        "      map_tensor = torch.from_numpy(map).float()\n",
        "      position_tensor = torch.from_numpy(loc).float()\n",
        "      reward_tensor = torch.tensor(reward).float()\n",
        "      action = {'last_map':last_map, 'last_position':last_position, 'map': map_tensor.detach(), 'position': position_tensor.detach(), 'reward': reward_tensor.unsqueeze(0).detach(), 'action': action.detach()}\n",
        "\n",
        "      total_reward += reward\n",
        "\n",
        "      if store:\n",
        "        self.write_one_transition(action, self.buffer_idx)\n",
        "        self.buffer_idx = (self.buffer_idx + 1) % len(self.buffer)\n",
        "        if self.buffer_idx == 0:\n",
        "          self.full_buffer = True\n",
        "\n",
        "      return action, terminal\n",
        "\n",
        "    def write_one_transition(self, trans, idx):\n",
        "      actions = trans['action']\n",
        "      rewards = trans['reward']\n",
        "      maps = trans['map']\n",
        "      positions = trans['position']\n",
        "\n",
        "      last_map = trans['last_map']\n",
        "      last_position = trans['last_position']\n",
        "\n",
        "      print('actions', actions.size())\n",
        "      print('rewards', rewards.size())\n",
        "      print('maps', maps.size())\n",
        "      print('positions', positions.size())\n",
        "      print('last_map', last_map.size())\n",
        "      print('last_position', last_position.size())\n",
        "\n",
        "      total_tensor = torch.cat((actions, rewards, positions, last_position), 0)\n",
        "      total_maps = torch.cat((maps, last_map), 0)\n",
        "      with self.db.begin(write=True) as txn:\n",
        "        total_bytes = BytesIO()\n",
        "        maps_bytes = BytesIO()\n",
        "\n",
        "        torch.save(total_tensor, total_bytes)\n",
        "        torch.save(total_maps, maps_bytes)\n",
        "        \n",
        "        txn.put('{}_total'.format(idx).encode(), total_bytes.getvalue())\n",
        "        txn.put('{}_maps'.format(idx).encode(), maps_bytes.getvalue())\n",
        "\n",
        "    def sample_transitions(self, N):\n",
        "      \"\"\"\n",
        "      A function to sample N points from the buffer\n",
        "      param: N : Number of samples to obtain from the buffer\n",
        "      \"\"\"\n",
        "      if self.full_buffer:\n",
        "        samples = np.random.permutation(range(self.buffer_length))\n",
        "      else:\n",
        "        samples = np.random.permutation(range(self.buffer_idx))\n",
        "\n",
        "      samples = samples[:N]\n",
        "      return self.read_transitions(samples)\n",
        "\n",
        "    def read_transitions(self, transitions):\n",
        "      maps = []\n",
        "      positions = []\n",
        "      rewards = []\n",
        "      actions = []\n",
        "      last_maps = []\n",
        "      last_positions = []\n",
        "\n",
        "      for seq in transitions:\n",
        "        with self.db.begin() as txn:\n",
        "          total_data = BytesIO(txn.get('{}_total'.format(seq).encode()))\n",
        "          map_data = BytesIO(txn.get('{}_maps'.format(seq).encode()))      \n",
        "\n",
        "          total_tensor = torch.load(total_data)\n",
        "          map_tensor = torch.load(map_data)\n",
        "          print('map tensor', map_tensor.size())\n",
        "          maps.append(map_tensor[:84, :].unsqueeze(0))\n",
        "          last_maps.append(map_tensor[84:, :].unsqueeze(0))\n",
        "          positions.append(total_tensor[3:5].unsqueeze(0))\n",
        "          actions.append(total_tensor[:2].unsqueeze(0))\n",
        "          rewards.append(total_tensor[2].unsqueeze(0))\n",
        "          last_positions.append(total_tensor[5:].unsqueeze(0))\n",
        "\n",
        "      map_pad = torch.cat(maps, 0).to(device='cuda').float()\n",
        "      pos_pad = torch.cat(positions, 0).to(device='cuda').float()\n",
        "      reward_pad = torch.cat(rewards, 0).to(device='cuda').float()\n",
        "      action_pad = torch.cat(actions, 0).to(device='cuda').float()\n",
        "      last_positions = torch.cat(last_positions, 0).to(device='cuda').float()\n",
        "      last_maps = torch.cat(last_maps, 0).to(device='cuda').float()\n",
        "\n",
        "      return map_pad, pos_pad, reward_pad, action_pad, last_positions, last_maps\n",
        "\n",
        "    def generate_episode(self, policy, add_noise=True, store=True, test=False, plot=False, do_print=False):\n",
        "      episode = []\n",
        "      self.env.plot = plot\n",
        "      map, position = self.env.reset()\n",
        "      position = position.astype(np.float64)\n",
        "      map = resize(map, (84, 84))\n",
        "      map = ((map - 127) / 255) * 2\n",
        "\n",
        "      position[0] = position[0]/ 640.0\n",
        "      position[1] = position[1] / 480.0\n",
        "      last_map = torch.from_numpy(map).float()\n",
        "      last_position = torch.from_numpy(position).float()\n",
        "      terminal = False\n",
        "\n",
        "      total_reward = 0\n",
        "      last_state = None\n",
        "      for i in range(self.max_episode_length):\n",
        "        if last_state is None:\n",
        "          action, last_state, lengths = policy(last_map.unsqueeze(0).unsqueeze(0).to(device='cuda'), last_position.unsqueeze(0).unsqueeze(0).to(device='cuda'), [1])\n",
        "        else:\n",
        "          action, last_state, lengths = policy(last_map.unsqueeze(0).unsqueeze(0).to(device='cuda'), last_position.unsqueeze(0).unsqueeze(0).to(device='cuda'), [1], last_state)\n",
        "      \n",
        "        if add_noise:\n",
        "          sampled = self.noise.sample()\n",
        "          #print('adding noise', sampled)\n",
        "          action = action.cpu().squeeze(0).squeeze(1) + sampled\n",
        "        else:\n",
        "          action = action.cpu().squeeze(0).squeeze(1)\n",
        "\n",
        "        action_np = action.detach().numpy().flatten()\n",
        "        if action_np[0] < 0:\n",
        "          action_np[0] = abs(action_np[0])\n",
        "        elif action_np[0] > 1:\n",
        "          action_np[0] = action_np[0] - 1\n",
        "\n",
        "        if action_np[1] < 0:\n",
        "          action_np[1] = abs(action_np[1])\n",
        "        elif action_np[1] > 1:\n",
        "          action_np[1] = action_np[1] - 1\n",
        "\n",
        "\n",
        "        if do_print:\n",
        "          print('action', action_np)\n",
        "\n",
        "    \n",
        "\n",
        "        (map, loc), reward, terminal, complete, new_loc, collision, all_map = self.env.step(action_np)\n",
        "        map = resize(map, (84, 84))\n",
        "        map = ((map - 127) / 255) * 2\n",
        "        loc = loc.astype(np.float64)\n",
        "        loc[0] = loc[0] / 640.0\n",
        "        loc[1] = loc[1] / 480.0\n",
        "\n",
        "        map_tensor = torch.from_numpy(map).float()\n",
        "        position_tensor = torch.from_numpy(loc).float()\n",
        "        reward_tensor = torch.tensor(reward).float()\n",
        "        episode.append({'map': map_tensor.detach(), 'position': position_tensor.detach(), 'reward': reward_tensor.detach(), 'action': action.detach()})\n",
        "        last_map = map_tensor.to(device='cuda')\n",
        "        last_position = position_tensor.to(device='cuda')\n",
        "        total_reward += reward\n",
        "        if terminal:\n",
        "          break\n",
        "\n",
        "      if store:\n",
        "        sequences = self.episode_to_sequences(episode)\n",
        "        for sequence in sequences:\n",
        "          self.write_sequence(sequence, self.buffer_idx)\n",
        "          self.buffer_idx = (self.buffer_idx + 1) % len(self.buffer)\n",
        "          if self.buffer_idx == 0:\n",
        "            self.full_buffer = True\n",
        "\n",
        "      self.env.plot = False\n",
        "      return total_reward\n",
        "\n",
        "    def write_sequence(self, sequence, idx):\n",
        "      actions = sequence['actions']\n",
        "      rewards = sequence['rewards']\n",
        "      maps = sequence['maps']\n",
        "      positions = sequence['positions']\n",
        "\n",
        "      len = sequence['len']\n",
        "      total_tensor = torch.cat((actions, rewards.unsqueeze(1).unsqueeze(1), positions.unsqueeze(1)), 2)\n",
        "      with self.db.begin(write=True) as txn:\n",
        "        total_bytes = BytesIO()\n",
        "        maps_bytes = BytesIO()\n",
        "\n",
        "        torch.save(total_tensor, total_bytes)\n",
        "        torch.save(maps, maps_bytes)\n",
        "        \n",
        "        txn.put('{}_total'.format(idx).encode(), total_bytes.getvalue())\n",
        "        txn.put('{}_maps'.format(idx).encode(), maps_bytes.getvalue())\n",
        "        txn.put('{}_len'.format(idx).encode(), str(len).encode())\n",
        "\n",
        "    def read_sequences(self, sequences):\n",
        "      map_sequences = []\n",
        "      position_sequences = []\n",
        "      reward_sequences = []\n",
        "      action_sequences = []\n",
        "      seq_lens = []\n",
        "\n",
        "      for seq in sequences:\n",
        "        with self.db.begin() as txn:\n",
        "          total_data = BytesIO(txn.get('{}_total'.format(seq).encode()))\n",
        "          map_data = BytesIO(txn.get('{}_maps'.format(seq).encode()))\n",
        "          length = txn.get('{}_len'.format(seq).encode())\n",
        "      \n",
        "\n",
        "          total_tensor = torch.load(total_data)\n",
        "          map_tensor = torch.load(map_data)\n",
        "          map_sequences.append(map_tensor)\n",
        "          position_sequences.append(total_tensor[:, :, 3:])\n",
        "          action_sequences.append(total_tensor[:, :, :2])\n",
        "          reward_sequences.append(total_tensor[:, :, 2])\n",
        "          seq_lens.append(int(length))\n",
        "\n",
        "      map_pad = pad_sequence(map_sequences).to(device='cuda').float()\n",
        "      pos_pad = pad_sequence(position_sequences).to(device='cuda').float()\n",
        "      reward_pad = pad_sequence(reward_sequences).to(device='cuda').float()\n",
        "      action_pad = pad_sequence(action_sequences).to(device='cuda').float()\n",
        "      seqs = seq_lens\n",
        "\n",
        "      return map_pad, pos_pad, reward_pad, action_pad, seqs\n",
        "    \n",
        "    def episode_to_sequences(self, episode):\n",
        "      sequences = []\n",
        "      last_idx = 0\n",
        "      for i in np.arange(self.sequence_length, len(episode), self.sequence_length):\n",
        "        window = episode[last_idx:i]\n",
        "        map_tensor = torch.cat([torch.unsqueeze(data['map'], 0) for data in window], 0)\n",
        "        position_tensor = torch.cat([torch.unsqueeze(data['position'], 0) for data in window], 0)\n",
        "        reward_tensor = torch.cat([torch.unsqueeze(data['reward'], 0) for data in window], 0)\n",
        "        action_tensor = torch.cat([torch.unsqueeze(data['action'], 0) for data in window], 0)\n",
        "        sequences.append({'maps':map_tensor, 'positions': position_tensor, 'rewards': reward_tensor, 'actions':action_tensor, 'len':len(window)})\n",
        "        last_idx = i\n",
        "\n",
        "      window = episode[last_idx:]\n",
        "      map_tensor = torch.cat([torch.unsqueeze(data['map'], 0) for data in window], 0)\n",
        "      position_tensor = torch.cat([torch.unsqueeze(data['position'], 0) for data in window], 0)\n",
        "      reward_tensor = torch.cat([torch.unsqueeze(data['reward'], 0) for data in window], 0)\n",
        "      action_tensor = torch.cat([torch.unsqueeze(data['action'], 0) for data in window], 0)\n",
        "      sequences.append({'maps':map_tensor, 'positions': position_tensor, 'rewards': reward_tensor, 'actions':action_tensor, 'len':len(window)})\n",
        "      return sequences\n",
        "    \n",
        "\n",
        "    #TODO: Complete the function\n",
        "    def buffer_sample(self, N):\n",
        "        \"\"\"\n",
        "        A function to sample N points from the buffer\n",
        "        param: N : Number of samples to obtain from the buffer\n",
        "        \"\"\"\n",
        "        if self.full_buffer:\n",
        "          samples = np.random.permutation(range(self.buffer_length))\n",
        "        else:\n",
        "          samples = np.random.permutation(range(self.buffer_idx))\n",
        "\n",
        "        samples = samples[:N]\n",
        "        return self.read_sequences(samples)\n",
        "\n",
        "    def batchify(self, samples):\n",
        "      \n",
        "      map_sequences = []\n",
        "      position_sequences = []\n",
        "      reward_sequences = []\n",
        "      action_sequences = []\n",
        "      seq_lens = []\n",
        "\n",
        "      for sequence in samples:\n",
        "\n",
        "        map_sequences.append(sequence['maps'])\n",
        "        position_sequences.append(sequence['positions'])\n",
        "        reward_sequences.append(sequence['rewards'])\n",
        "        action_sequences.append(sequence['actions'])\n",
        "        seq_lens.append(sequence['len'])\n",
        "\n",
        "      map_pad = pad_sequence(map_sequences).to(device='cuda').float()\n",
        "      pos_pad = pad_sequence(position_sequences).to(device='cuda').float()\n",
        "      reward_pad = pad_sequence(reward_sequences).to(device='cuda').float()\n",
        "      action_pad = pad_sequence(action_sequences).to(device='cuda').float()\n",
        "      seqs = seq_lens\n",
        "\n",
        "      return map_pad, pos_pad, reward_pad, action_pad, seqs\n",
        "\n",
        "      \n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFMjDGz1N958"
      },
      "source": [
        "# TODO: Implement a DDPG class\n",
        "class DDPG():\n",
        "    def __init__(\n",
        "            self,\n",
        "            env,\n",
        "            conv_dims,\n",
        "            state_dim,\n",
        "            linear_dims,\n",
        "            actor_linear_dims,\n",
        "            sequence_length,\n",
        "            replay,\n",
        "            critic_lr=3e-4,\n",
        "            actor_lr=3e-4,\n",
        "            gamma=0.99,\n",
        "            batch_size=100,\n",
        "            seed=1000\n",
        "    ):\n",
        "        \"\"\"\n",
        "        param: env: An gym environment\n",
        "        param: action_dim: Size of action space\n",
        "        param: state_dim: Size of state space\n",
        "        param: critic_lr: Learning rate of the critic\n",
        "        param: actor_lr: Learning rate of the actor\n",
        "        param: gamma: The discount factor\n",
        "        param: batch_size: The batch size for training\n",
        "        \"\"\"\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        action_dim = 2\n",
        "        self.gamma = gamma\n",
        "        self.batch_size = batch_size\n",
        "        self.sequence_length = sequence_length\n",
        "        self.env = env\n",
        "        self.state_dim = state_dim\n",
        "        self.actor = FCActor(conv_dims, actor_linear_dims).float().to(device='cuda')\n",
        "\n",
        "        # TODO: Create a actor and actor_target\n",
        "        self.actor_target = copy.deepcopy(self.actor)\n",
        "\n",
        "        # TODO: Make sure that both networks have the same initial weights\n",
        "\n",
        "        # TODO: Create a critic and critic_target object\n",
        "        self.critic = CNNCriticNoSeq(conv_dims, linear_dims).float().to(device='cuda')\n",
        "        self.critic_target = copy.deepcopy(self.critic)\n",
        "        # TODO: Make sure that both networks have the same initial weights\n",
        "\n",
        "        # TODO: Define the optimizer for the actor\n",
        "        self.optimizer_actor = optim.Adam(self.actor.parameters(), actor_lr)\n",
        "        # TODO: Define the optimizer for the critic\n",
        "        self.optimizer_critic = optim.Adam(self.critic.parameters(), critic_lr)\n",
        "\n",
        "        # TODO: define a replay buffer\n",
        "        #buffer_size, init_episodes, max_episode_length, state_dim, action_dim, env, env_width, env_height\n",
        "        self.replay = replay\n",
        "\n",
        "    # TODO: Complete the function\n",
        "    def update_target_networks(self):\n",
        "        \"\"\"\n",
        "        A function to update the target networks\n",
        "        \"\"\"\n",
        "        weighSync(self.actor_target, self.actor)\n",
        "        weighSync(self.critic_target, self.critic)\n",
        "\n",
        "    # TODO: Complete the function\n",
        "    def update_network(self, y_i, maps, positions, actions, last_maps, last_positions):\n",
        "        \"\"\"\n",
        "        A function to update the function just once\n",
        "        \"\"\"\n",
        "\n",
        "        qs = self.critic(last_maps, last_positions, actions)\n",
        "        #should be (seq_len, batch, 1)\n",
        "        #should be (seq_len, batch, 1)\n",
        "\n",
        "        critic_loss = ((y_i - qs)**2).sum() / (self.sequence_length * self.batch_size)\n",
        "        critic_loss.backward()\n",
        "\n",
        "        self.optimizer_critic.step()\n",
        "\n",
        "        # Freeze Q-network so you don't waste computational effort \n",
        "        # computing gradients for it during the policy learning step.\n",
        "        for p in self.critic.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        new_act = self.actor(last_maps, last_positions)\n",
        "        qs = self.critic(last_maps, last_positions, new_act)\n",
        "        actor_loss = qs.sum() / (self.batch_size)\n",
        "        (-actor_loss).backward()\n",
        "        self.optimizer_actor.step()\n",
        "\n",
        "        # Freeze Q-network so you don't waste computational effort \n",
        "        # computing gradients for it during the policy learning step.\n",
        "        for p in self.critic.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "  \n",
        "    # TODO: Complete the function\n",
        "    def train(self, num_steps):\n",
        "        \"\"\"\n",
        "        Train the policy for the given number of iterations\n",
        "        :param num_steps:The number of steps to train the policy for\n",
        "        \"\"\"\n",
        "        self.critic_criterion = MSELoss()\n",
        "        num_episodes = 0\n",
        "        i = 0\n",
        "        total_reward = 0\n",
        "        total_steps = 0\n",
        "        episode_reward = 0\n",
        "        steps_list = []\n",
        "        rewards = []\n",
        "        start = time.time()\n",
        "        total_target_time = 0\n",
        "        total_backprop_time = 0\n",
        "        total_gen_episode_time = 0\n",
        "        total_test_time = 0\n",
        "        total_dataload_time = 0\n",
        "\n",
        "        \n",
        "        map, position = self.replay.env.reset()\n",
        "        map = resize(map, (84, 84))\n",
        "        map = map / 255\n",
        "        position = position.astype(np.float64)\n",
        "        position[0] = position[0] / 480\n",
        "        position[1] = position[1] / 640\n",
        "        action = {'map':torch.from_numpy(map).float(), 'position':torch.from_numpy(position).float()}\n",
        "        \n",
        "        while i < num_steps:\n",
        "          gen_start = time.time()\n",
        "          action, terminal = self.replay.generate_step(ActorPolicy(self.actor), action)\n",
        "          total_gen_episode_time += time.time() - gen_start\n",
        "          if terminal:\n",
        "            map, position = self.env.reset()\n",
        "            map = resize(map, (84, 84))\n",
        "            map = map / 255\n",
        "            position = position.astype(np.float64)\n",
        "            position[0] = position[0] / 480\n",
        "            position[1] = position[1] / 640\n",
        "            action = {'map':torch.from_numpy(map).float(), 'position':torch.from_numpy(position).float()}\n",
        "\n",
        "\n",
        "          self.optimizer_critic.zero_grad()\n",
        "          self.optimizer_actor.zero_grad()\n",
        "          #maps.size() -> (seq_len, batch_size, 1, 224, 224)\n",
        "          #positons.size() -> (seq_len, batch_size, 2)\n",
        "          #rewards.size() -> (seq_len, batch_size, 1)\n",
        "          # actions -> (seq_len, batch_size, 2)\n",
        "          dataload_time = time.time()\n",
        "          maps, positions, rewards, actions, last_positions, last_maps = self.replay.sample_transitions(self.batch_size)\n",
        "          maps = maps.unsqueeze(1)\n",
        "          last_maps = last_maps.unsqueeze(1)\n",
        "\n",
        "          total_dataload_time += time.time() - dataload_time\n",
        "            \n",
        "          target_start = time.time()\n",
        "          with torch.no_grad():\n",
        "            target_action = self.actor_target(last_maps, last_positions)\n",
        "            #Should be (seq_len, batch_size, 2)\n",
        "            #Should be (seq_len, batch_size, 1)\n",
        "            crit = self.critic_target(maps, positions, target_action)\n",
        "            #print('rewards', rewards.size())\n",
        "            #print('crit', crit.size())\n",
        "            ys = rewards + self.gamma * crit\n",
        "\n",
        "          total_target_time += time.time() - target_start\n",
        "\n",
        "          update_start = time.time()\n",
        "          self.update_network(ys, maps, positions, actions, last_maps, last_positions)\n",
        "\n",
        "          self.update_target_networks()\n",
        "          total_backprop_time += time.time() - update_start\n",
        "          i += 1\n",
        "          if i % 20 == 0:\n",
        "            print('step {}'.format(i))\n",
        "            print('avg iter time {}'.format((time.time() - start) / i))\n",
        "\n",
        "            reward = 0\n",
        "            start_test = time.time()\n",
        "            for j in range(1):\n",
        "              reward += self.replay.generate_episode(self.actor, False, False, True, True, True)\n",
        "            print('test reward', reward / 5)\n",
        "            total_test_time = time.time() - start\n",
        "            print('avg test time', total_test_time / 5)\n",
        "            print('avg target time', total_target_time / i)\n",
        "            print('avg backprop time', total_backprop_time / i)\n",
        "            print('avg data load time', total_dataload_time / i)\n",
        "            print('avg gen episode time', total_gen_episode_time / i)\n",
        "            #  test_done = False\n",
        "            #  episode_reward = 0\n",
        "            #  the_steps = 0\n",
        "            #  s = test_env.reset()\n",
        "            #  while not test_done:\n",
        "            #    total_steps += 1\n",
        "            #    the_steps += 1\n",
        "            #    action = self.actor(torch.from_numpy(s).float().to(device='cuda')).detach().squeeze().cpu().numpy()\n",
        "            #    n_state, r, test_done, _ = test_env.step(action)\n",
        "            #    s = n_state\n",
        "            #    episode_reward += r\n",
        "\n",
        "            #  rewards.append(episode_reward)\n",
        "            #  steps_list.append(the_steps)\n",
        "            #  print('Episode reward')\n",
        "            #  print(episode_reward)\n",
        "\n",
        "        return rewards, steps_list"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjFt7JBRQVyT"
      },
      "source": [
        "reward_func = PaperRewardFunction()\n",
        "action_space = PolarActionSpace(30, 60)\n",
        "\n",
        "robot = Robot(0, True, False, 'DRL_robot_exploration/DungeonMaps',action_space,reward_func, False)\n",
        "test_robot = Robot(0, True, False, 'DRL_robot_exploration/DungeonMaps',action_space,reward_func, False)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCg-zeJMGV5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9a7cc8-da91-471a-da19-0033122a5a10"
      },
      "source": [
        "replay = Replay(10000, 10, 300, 4, 2, robot, test_robot, 640, 480)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.1646, 0.5609]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.1708, 0.6234]), 'reward': tensor([0.0339]), 'action': tensor([0.0136, 0.3442], dtype=torch.float64)}\n",
            "terminal False\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.1708, 0.6234]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.1708, 0.6234]), 'reward': tensor([-300.]), 'action': tensor([0.1760, 0.8517], dtype=torch.float64)}\n",
            "terminal True\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.6979, 0.1609]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.6979, 0.1609]), 'reward': tensor([-300.]), 'action': tensor([0.5743, 0.7725], dtype=torch.float64)}\n",
            "terminal True\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([1.1313, 0.2609]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([1.1313, 0.2609]), 'reward': tensor([-300.]), 'action': tensor([0.9067, 0.0603], dtype=torch.float64)}\n",
            "terminal True\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.9646, 0.5859]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.9646, 0.5859]), 'reward': tensor([-300.]), 'action': tensor([0.0212, 0.9050], dtype=torch.float64)}\n",
            "terminal True\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([1.0646, 0.3609]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([1.0021, 0.3812]), 'reward': tensor([0.2559]), 'action': tensor([0.8173, 0.0859], dtype=torch.float64)}\n",
            "terminal False\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([1.0021, 0.3812]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([1.0021, 0.3812]), 'reward': tensor([-300.]), 'action': tensor([0.8554, 0.2445], dtype=torch.float64)}\n",
            "terminal True\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.3979, 0.1859]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.3208, 0.1484]), 'reward': tensor([-0.8000]), 'action': tensor([0.6586, 0.4766], dtype=torch.float64)}\n",
            "terminal False\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.3208, 0.1484]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.3208, 0.1484]), 'reward': tensor([-300.]), 'action': tensor([0.8163, 0.2407], dtype=torch.float64)}\n",
            "terminal True\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([0.2979, 0.2609]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([0.2979, 0.2609]), 'reward': tensor([-300.]), 'action': tensor([0.5705, 0.8296], dtype=torch.float64)}\n",
            "terminal True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si4Aab04PDRr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "0486c2db-2e08-4f13-b5c6-c5c36300729b"
      },
      "source": [
        "np.random.seed(1000)\n",
        "map, position, reward, action, last_position, last_map = replay.sample_transitions(1)\n",
        "print(reward)\n",
        "print(action)\n",
        "plt.imshow(resize(map.squeeze(0).cpu().numpy(), (480, 640)), cmap='gray')\n",
        "position = position.cpu().numpy()\n",
        "position[0, 0] = position[0, 0] * 480\n",
        "position[0, 1] = position[0, 1] * 640\n",
        "last_position = last_position.cpu().numpy()\n",
        "last_position[0, 0] = last_position[0, 0] * 480\n",
        "last_position[0, 1] = last_position[0, 1] * 640\n",
        "plt.scatter(position[0, 0], position[0, 1])\n",
        "plt.scatter(last_position[0, 0], last_position[0, 1])\n",
        "plt.show()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "map tensor torch.Size([168, 84])\n",
            "tensor([-300.], device='cuda:0')\n",
            "tensor([[0.5743, 0.7725]], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAD8CAYAAAARze3ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAa3UlEQVR4nO3dbYxc133f8e9/53lml7s0yYgCyZYyIiRwg0YSGFuGgyCwqtZWDckvnEBGYLOBAhmNCzi10URuiwAB+sJujCgOWjhWI7dykcZynbQiBBeuK8koCjSyaFmyLamSaFcuSVOkZHJn5/nx9MXcc3N2ONRdaufhjvj7AIO999zLmbPE8Mdzzzn3XHPOISIiV7ay6AqIiKSdglJEJIGCUkQkgYJSRCSBglJEJIGCUkQkwUyC0szeZ2YvmtkpM7tvFp8hIjIvNu15lGaWAV4CbgfOAE8BH3bOPT/VDxIRmZNZtCjfCZxyzv3IOdcFvgLcNYPPERGZi+wM3vMQcDrYPwO8643+QKlUcuvr6zOoiojIzpw/f/5159yBScdmEZQ7Ymb3AvcCrK2t8ZGPfGRRVRER4XOf+9yPr3RsFpfeZ4Ejwf7hqGwb59wDzrljzrlj5XJ5BtUQEZmOWQTlU8CNZnaDmeWBu4ETM/gcEZG5mPqlt3Oub2b/BPgGkAG+5Jx7btqfIyIyLzPpo3TOfR34+izeW0Rk3nRnjohIAgWliEgCBaWISAIFpYhIAgWliEgCBaWISAIFpYhIAgWliEgCBaWISAIFpYhIAgWliEgCBaWISAIFpYhIAgWliEiChT0KQq49ZnZZ2bSfAioyCwpKmYtJIenLZxWW4+97pTqIJFFQykyZGSsrK/HLl/mAHAwGDIdDhsNhHGyTgnM4HF5WFp4//pp0PsDKykr8+eHL12vS+Um/n7z1KShlplZWVsjlcvErk8nEoTkcDmm323Q6Hbrd7sSQu1IYDgaD+NzhcBjvDwYD+v1+HMBh6GYyGTKZDNlsNq5DWB8zI5PJbAtQ/+eTAnFSoCpE3zoUlDIzvjWZy+UolUqUSiWy2SzZbJZMJkO/3yebzeKco9/vx6EXtjDD4PRlPhj9ywdjv9+n1+tte4XCwPahHdbHv3xo+vDz+/53mtQCHQ6HE8vDPyvLS0EpUxcGRjabpVwus2fPHvbs2UOhUIiDqtvtcunSJQD6/T6dTodms0mj0aDb7caBOB6Q4y3HMDDHXyEfiuErDEi/71uW44E53toMQ9Mf938uk8mQy+Xizwm7HWT5KChlJnzI5HI5KpUKe/fuZd++fZTLZQqFAoVCgXa7TTabZTAY0G632draYmtri9dff51arRaH3XhL05f5gAwvv8cvxcNL7/HL7fCyOww5H2xhYIYBGva7jr+v/08gn89TLpcplUrbzpPlpKCUqfPBkc1mKRQKVCoVNjY22L9/P5VKhUKhQLFYpN1uMxgM6PV6dLtdGo0G1Wo1bnWF/ZFhS9K3LscHfcIWYCaTmTjqPaklGF7imxn9fj8OxFAmk2EwGJDJZOJzw7r6z5gUxr6LQZaTglKmygdFPp+PW1Wrq6usra2xZ88eSqUS+Xw+7iPct28fKysrlEol1tbW2L9/PwcPHqTZbG5rMYbhON5nuZPR7nFXGv329Z+0/UaX3mGrNGyR+lfYNTAYDGb29y+zoaCUqctkMuTzeUqlEpVKhdXV1TgsC4VC3G+Xy+VYWVmhXC6zd+9eDhw4wNbWFtVqlU6nsy0cw9ZYuL3TYEwSXhaHLcnxAZpJx8J9//Ij+q1WK/7Z6XQumwoly0FBKVPjQyK85F5bW6NcLsd9k/l8/rIpOX5UvFwus76+zv79++n3+5cFZNqFwd7tduPQB+IWpfopl5OCUqYibHFlMhlKpVLciqxUKuTz+W2jyv78cJAkk8lQLBZZW1uLW4rLEJS+juE0pVarxWAwiEfyw0txWT4KSpkaHwS5XI5isRgHpW9Nhn13/nwfkAD5fB5IfziOX/r7lmSv16PT6cSDVOG0IFluCkrZtbBvzk+RKRaLVCoVKpUKxWKRXC6X2KJ6o1sJ0yK8U2g4HNLpdOJR+1arRb1ep9FoUK/XqVarVKtVtra2aLVadLtdDeQsKQWlTEU4tzCXy8V9lH46UDabTXUA7lR426QPRx+MtVqNarXK5uYmtVqNVqsVD+aEk+PT3mKWyykoZSp8UPrR7EKhQKlUolgsxgM4yxqU45Pdu90u3W6XTqdDrVaLQ9IP3lSr1W0T5v0EeUh/t4JMpqCUXQsvu31Q+nmUYd/ksvGj7uG94/7y2gekb002Go24Bekvs/3IvUJy+SkoZSrCBSbCoPT3Oy/T4hDhNB8/cu3nQtZqNS5evMilS5eoVqs0Gg2azSatVoter3fZJHn/frLcFJSya+Ftez4gfWCGU4LSLAxHv0CHv7z2YdhoNOJL7K2tLer1Op1OJ36N3ykkbx0KSpkK3z/pA9LfdROuwpNW4cpE/X6fdrtNvV5na2trWzj6S+x2ux2voxmuXqQW5FuXglJ2LRzICS+3fVimcaJ1uLp6uDBHt9ul2WzGo9d+YMb3Sfo5kuP3bCsc39oUlDIV4WBOuCzZpNV6Fim8i8b3LfopPu12m2azGV9m1+t1ms1m3IJst9v0ej0N0FyDEoPSzL4EfAC44Jz7hajsbcDDwFHgFeDXnXOXbPSv4fPAHUAT+EfOuadnU3VJi/AOG9+SDC+50xKSnh/JrtVqbG5uxvMe/avZbMZ9lH6SeDhAo0vsa89OWpT/Afg3wJeDsvuAx5xznzGz+6L93wPeD9wYvd4FfCH6KW9R47cjjt/PnaaQDCeLt9ttLl68yNmzZ/nJT34SB2S9Xo9XRh9fa1LBeO1KDErn3P80s6NjxXcBvxptPwR8i1FQ3gV82Y2+UX9tZhtmdr1z7ty0KizpNL5SeBoGcZ468UWOPP2H/Ix7jQt2gNM3f4qb7vgtBoMBzWaT8+fP8/LLL3Pq1CmazWbc77iyshIvLlwoFBZWf0mPN9tHeV0Qfq8C10Xbh4DTwXlnojIF5Vvc+Mre4w/hmndgPnXii/zCd/4lJeuCwUFeY/3p3+fp4ZC/c/vxuEV5+vRpXnrpJTqdTvw7FItF9uzZEy8Z5xftkGvXrm+XiFqPV31NYmb3mtlJMzvZbDZ3Ww1JkTRcch95+g9HIRkoWZe/9ez9APFqP91uNx6o8fMme71efFcN6JJb3nxQnjez6wGinxei8rPAkeC8w1HZZZxzDzjnjjnnjpXL5TdZDZHJfsa9NrH8Ovf6tv1w/uT483gUkOK92aA8ARyPto8DjwTlH7WRW4Gq+ievLePPsFmUC3ZgYvl52w9wWR3DFdfH+1cX3TqWxUsMSjP7C+B/Az9nZmfM7B7gM8DtZvYy8PeifYCvAz8CTgH/DvjtmdRaUiccUR5/JswiQvP0Lf+MlstvK2u5PD/+xX8KbF9DM1werlQqxc8eX8aFPGQ2djLq/eErHLptwrkO+PhuKyXLZzwow+dqL6JF9kt3foynIBr1fp0Ltp//d8unuOkf/GY8/Qe2P1rXLw8XrniksBTQnTmyS76lGPb1jS8vtii/dOfH4M6PAXAQOBDdquiFo/PhPeoKSRmnoJSp8HevjK/kvchWZZJwSpNzbtudRcu6hqbMhoJSds2HoV9cYnxdRjNLXViG/ZM+KP3qR37CfJrqK4uloJRd85fZ/jEJ449ASMO8yknCgRxg4i2YIqCglCnxQekncfd6vbjfMo2XsGGLMpsd/TMIb79UWEoofd9gWTrjC9/6O1v8T38JnjZhizJcGi6tqx7J4qhFKVMRhmS4CG6v19vWD5im8AlD0u+nYTEPSR+1KGXXwsGc8PLb3zsdPq41LcYvvX1AqjUpkygoZSrCy+9er0en04lXEPeL36bt3ulw1Ht8aTgFpYQUlDIVk4LSP2bBtyrTEJTh/dthSIYBqZCUceqjlF0LA9AHZbvdptFoxIvflstlhsNhqvr/fCj6oFSLUq5EQSlT4/sqfVDWajXy+TylUolKpRLfB56GsBxvUYbzPX3d0jitSRZD3wSZinCR28FgED8bu1ar0Wg0ts2tHF9daBHCgRx/y6LuxpErUYtSpiZ8FGy73WZlZYV8Pk+j0Ygf+wrEi0/MO5TCVmQ2m6VcLrO+vs6+ffviuolMoqCUqRsMBnQ6HYbDIZlMhrW1Ner1Oo1GIz7H9wfOU9gnWSgUWF1dZd++ffHTF/10psFgEJ8vAgpKmTI/+u0vs1utFo1Gg1qtRqVSAUYB5J/9Pe8w8uGcy+WoVCpsbGzQarXI5/PUajU9BkImUlDK1IWTyzudDo1Gg2q1Si6Xiwdz/OK485ySEw7SZLNZSqUS6+vrdLujh5D5LoNwzUoFpoCCUmbEt8x6vR7NZpPNzc24j7BQKFCpVMjn83NvVfrP8kG5trYW31HUbrfZ2tpiZWUlFQNOkh4KSpm6MGD6/T6tVit+NnYul6NYLFIul8lkMttWFZ9XYPp+ynw+T7lcptfrUalUKBaL5PN52u02ZpbKu4lkMRSUMjO+v7Lb7VKv1xkMBhQKBUqlEqVSiZWVFcrlchxc825Z+tAeDAbUajUKhQL5fJ5cLkev10vF4ywkHRSUMlPhwE4YlMViMV75PFwTcl79lf4zC4UCw+EwrpN/AqMPSV9HubYpKGXmwlZZs9nk0qVLmFm8XqVffi2fz29byWeWfCs2m82Sz+e3tXRbrRbwN0vHiSgoZaZ8a8z397VarTgkw7mW2WyW4XBIoVCY2/xK36r0n+v7TtvtdtxloBalgIJS5iB8pG2n0wGI16j0rcfhcMja2lp8T3g+n79sYd1pCief53K5+J50H5T+fnV/nsLy2qaglLnyYen7/1ZWVuIpRBsbG2xsbDAYDCiXy/HAyqz6LcN5lT4o19bW4jt0ms3mtmXZFJbXLgWlzI0fIPEDO74PsNVqUa/Xabfb8cPI/ADL+FMcJwXmGx3bqXC6kK9P+IAxheS1TUEpczU+x7LT6cQrDplZ3OLcs2cPq6urrK6uxlOJ4PIw9NN8/Gsn60mGt1n6x1bU6/VtiwyHE84VlKKglIUInwXuF/v1y7NtbW2xtrbG+vo6GxsbrK6uApPXh8xkMpTL5fg+cn+pfqU1L/193P5OnGazSbPZpNFo0Gg0aLVacR9lOFrv30uBeW1SUMrC+MDyd8H4FmYYWq1Wi0qlErfqwnUvnXPkcjk2NjbYu3cvMBpdz2azZLPZy4I1vPRvt9tUq1U2NzfZ3NyMA9KvzN5sNuN7vv1nKSSvXQpKWbhwVLzb7cZh1u/3aTab5PP5bX2aftuPjh88eJBDhw7hnGN1dZV8Ph/PyQz5S+p+v0+tVuPcuXOcO3eOCxcu0Gq14kvxfr+/7RXWUa5NCkpJBd/a8/2VfnpOtVoFiOddhmHW6/UoFAo0m02AOFCLxSKlUol8Pr/tM/r9frzS+qVLl3j11Vd55ZVXOH36NO12O/5sP7/Sv0BrU17rFJSSGuHlrR8Z9+V+0GW8tWdm1Ot1Ll68SLFYpF6vx5PHw1XUwwDu9Xpsbm7y2muvsbW1FfdJ+rD2czv9vt9WWF67FJSSWuHlrp/r6O+k8a3PTCaDc45qtcpwOKRYLG5rDYZBGQ4e+Yef9Xq9+H19UIdPZkzDg9Bk8RSUshQm3f/tW3vD4ZBarRYv5xaG3Pj5k+Zx+kUwxikgxVNQytIYDy6/xmU4L7Lf719xLqVvMfppP+NzJUWuREEpSy8MPz/V6ErBF04vEtkpBaW8JSgAZZYSl2UxsyNm9oSZPW9mz5nZJ6Lyt5nZN83s5ejn3qjczOxPzOyUmX3PzG6Z9S8hIjJLO1m/qg98yjn3DuBW4ONm9g7gPuAx59yNwGPRPsD7gRuj173AF6ZeaxGROUoMSufcOefc09F2DXgBOATcBTwUnfYQ8MFo+y7gy27kr4ENM7t+6jUXEZmTq1oR1cyOAjcDTwLXOefORYdeBa6Ltg8Bp4M/diYqG3+ve83spJmd9HdWiIik0Y6D0sxWgb8Efsc5txUec6Me9KvqRXfOPeCcO+acO1Yul6/mj4qIzNWOgtLMcoxC8s+dc38VFZ/3l9TRzwtR+VngSPDHD0dlIiJLaSej3gY8CLzgnPuj4NAJ4Hi0fRx4JCj/aDT6fStQDS7RRUSWzk7mUb4H+AjwfTN7Jir758BngK+a2T3Aj4Ffj459HbgDOAU0gd+cao1FROYsMSidc/8LuNL9XbdNON8BH99lvUREUmM+D1AWEVliCkoRkQQKShGRBApKEZEECkoRkQQKShGRBApKEZEECkoRkQQKShGRBApKEZEECkoRkQQKShGRBApKEZEECkoRkQQKShGRBApKEZEECkoRkQQKShGRBApKEZEECkoRkQQKShGRBApKEZEECkoRkQQKShGRBApKEZEECkoRkQQKShGRBApKEZEECkoRkQQKShGRBApKEZEECkoRkQQKShGRBApKEZEECkoRkQQKShGRBIlBaWZFM/u2mT1rZs+Z2R9E5TeY2ZNmdsrMHjazfFReiPZPRcePzvZXEBGZrZ20KDvAe51zvwjcBLzPzG4FPgvc75z7WeAScE90/j3Apaj8/ug8EZGllRiUbqQe7eailwPeC3wtKn8I+GC0fVe0T3T8NjOzqdVYRGTOdtRHaWYZM3sGuAB8E/ghsOmc60ennAEORduHgNMA0fEqsG/Ce95rZifN7GSz2dzdbyEiMkM7Ckrn3MA5dxNwGHgn8PO7/WDn3APOuWPOuWPlcnm3byciMjNXNertnNsEngDeDWyYWTY6dBg4G22fBY4ARMfXgZ9OpbYiIguwk1HvA2a2EW2XgNuBFxgF5oei044Dj0TbJ6J9ouOPO+fcNCstIjJP2eRTuB54yMwyjIL1q865R83seeArZvavgO8CD0bnPwj8RzM7BVwE7p5BvUVE5iYxKJ1z3wNunlD+I0b9lePlbeDXplI7EZEU0J05IiIJFJQiIgkUlCIiCRSUIiIJFJQiIgkUlCIiCRSUIiIJFJQiIgkUlCIiCRSUIiIJFJQiIgkUlCIiCRSUIiIJFJQiIgkUlCIiCRSUIiIJFJQiIgkUlCIiCRSUIiIJFJQiIgkUlCIiCRSUIiIJFJQiIgkUlCIiCRSUIiIJFJQiIgkUlCIiCRSUIiIJFJQiIgkUlCIiCRSUIiIJFJQiIgkUlCIiCRSUIiIJFJQiIgkUlCIiCXYclGaWMbPvmtmj0f4NZvakmZ0ys4fNLB+VF6L9U9Hxo7OpuojIfFxNi/ITwAvB/meB+51zPwtcAu6Jyu8BLkXl90fniYgsrR0FpZkdBv4h8GfRvgHvBb4WnfIQ8MFo+65on+j4bdH5IiJLaactyj8GfhcYRvv7gE3nXD/aPwMcirYPAacBouPV6HwRkaWUGJRm9gHggnPuO9P8YDO718xOmtnJZrM5zbcWEZmq7A7OeQ9wp5ndARSBPcDngQ0zy0atxsPA2ej8s8AR4IyZZYF14Kfjb+qcewB4AODgwYNut7+IiMisJLYonXOfds4dds4dBe4GHnfO/QbwBPCh6LTjwCPR9olon+j44845BaGILK3dzKP8PeCTZnaKUR/kg1H5g8C+qPyTwH27q6KIyGLt5NI75pz7FvCtaPtHwDsnnNMGfm0KdRMRSQXdmSMikkBBKSKSQEEpIpJAQSkikkBBKSKSQEEpIpJAQSkikkBBKSKSQEEpIpJAQSkikkBBKSKSQEEpIpJAQSkikkBBKSKSQEEpIpJAQSkikkBBKSKSQEEpIpJAQSkikkBBKSKSQEEpIpJAQSkikkBBKSKSQEEpIpJAQSkikkBBKSKSQEEpIpJAQSkikkBBKSKSQEEpIpJAQSkiksCcc4uuA2ZWA15cdD3ehP3A64uuxFVSnednGet9Ldf5bzvnDkw6kJ3Cm0/Di865Y4uuxNUys5PLVm/VeX6Wsd6q82S69BYRSaCgFBFJkJagfGDRFXiTlrHeqvP8LGO9VecJUjGYIyKSZmlpUYqIpNbCg9LM3mdmL5rZKTO7b9H18czsS2Z2wcx+EJS9zcy+aWYvRz/3RuVmZn8S/Q7fM7NbFlTnI2b2hJk9b2bPmdknlqTeRTP7tpk9G9X7D6LyG8zsyah+D5tZPiovRPunouNHF1HvqC4ZM/uumT26DHU2s1fM7Ptm9oyZnYzK0v792DCzr5nZ/zGzF8zs3XOvs3NuYS8gA/wQeDuQB54F3rHIOgV1+xXgFuAHQdm/Bu6Ltu8DPhtt3wH8N8CAW4EnF1Tn64Fbou014CXgHUtQbwNWo+0c8GRUn68Cd0flfwr842j7t4E/jbbvBh5e4Pfkk8B/Ah6N9lNdZ+AVYP9YWdq/Hw8BvxVt54GNedd5IV+u4C/g3cA3gv1PA59eZJ3G6nd0LChfBK6Ptq9nNP8T4IvAhyedt+D6PwLcvkz1BsrA08C7GE0izo5/V4BvAO+OtrPRebaAuh4GHgPeCzwa/eNMe50nBWVqvx/AOvB/x/+u5l3nRV96HwJOB/tnorK0us45dy7afhW4LtpO3e8RXdrdzKh1lvp6R5ewzwAXgG8yutLYdM71J9Qtrnd0vArsm2+NAfhj4HeBYbS/j/TX2QH/3cy+Y2b3RmVp/n7cALwG/Puoi+PPzKzCnOu86KBcWm7031UqpwyY2Srwl8DvOOe2wmNprbdzbuCcu4lRK+2dwM8vuEpvyMw+AFxwzn1n0XW5Sr/snLsFeD/wcTP7lfBgCr8fWUZdYF9wzt0MNBhdasfmUedFB+VZ4EiwfzgqS6vzZnY9QPTzQlSemt/DzHKMQvLPnXN/FRWnvt6ec24TeILRZeuGmfnbbMO6xfWOjq8DP51zVd8D3GlmrwBfYXT5/XnSXWecc2ejnxeA/8LoP6U0fz/OAGecc09G+19jFJxzrfOig/Ip4MZopDDPqJP7xILr9EZOAMej7eOM+gB9+UejEbdbgWpwWTA3ZmbAg8ALzrk/Cg6lvd4HzGwj2i4x6ld9gVFgfig6bbze/vf5EPB41KqYG+fcp51zh51zRxl9bx93zv0GKa6zmVXMbM1vA38f+AEp/n44514FTpvZz0VFtwHPz73O8+5MntBZewej0dkfAv9i0fUJ6vUXwDmgx+h/tXsY9Sk9BrwM/A/gbdG5Bvzb6Hf4PnBsQXX+ZUaXIN8DnoledyxBvf8u8N2o3j8Afj8qfzvwbeAU8J+BQlRejPZPRcffvuDvyq/yN6Peqa1zVLdno9dz/t/bEnw/bgJORt+P/wrsnXeddWeOiEiCRV96i4iknoJSRCSBglJEJIGCUkQkgYJSRCSBglJEJIGCUkQkgYJSRCTB/wf+JUKKxwLNDAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieHIP9WFQ0t5"
      },
      "source": [
        "linear_dims = [(256, 128), (128, 1)]\n",
        "actor_linear_dims = [(512, 1024), (1024, 512), (512, 256), (256, 2)]\n",
        "conv_dims = [(1, 32, 8), (32, 64, 4), (2, 2), (64, 64, 3), (64, 512, 7), (2, 2), (512, 64, 1)]\n",
        "lstm_hidden = 512\n",
        "lstm_out = 2\n",
        "train_length = 4\n",
        "\n",
        "\n",
        "ddpg = DDPG(robot, conv_dims, lstm_hidden, linear_dims, actor_linear_dims, train_length, replay, 1e-3,3e-4,0.99, 4)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbQtpI5A7l2D",
        "outputId": "210d1c03-d291-4f3a-bf28-43410d23be7a"
      },
      "source": [
        "print('init seqs', ddpg.replay.buffer_idx)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init seqs 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsCYdcqISY73",
        "outputId": "86c4730e-d64f-475a-903c-b836173b8ac9"
      },
      "source": [
        "ddpg.train(10)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([1, 12544])\n",
            "positions torch.Size([1, 2])\n",
            "actions torch.Size([2])\n",
            "rewards torch.Size([1])\n",
            "maps torch.Size([84, 84])\n",
            "positions torch.Size([2])\n",
            "last_map torch.Size([84, 84])\n",
            "last_position torch.Size([2])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "map tensor torch.Size([168, 84])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n",
            "flat torch.Size([4, 12544])\n",
            "positions torch.Size([4, 2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  -0.8000, -300.0000,    0.8183, -300.0000], device='cuda:0'), [])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KSbEc30VzFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13ba1e76-edee-4844-a6a5-187505c6bfef"
      },
      "source": [
        "ddpg.replay.buffer_idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "576"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kG55trJz-Cnw",
        "outputId": "56205657-135f-4057-93e8-0a8f3a6bb70e"
      },
      "source": [
        "init_policy = lambda map, pos, lengths: (torch.from_numpy(np.random.uniform(0, 1, (2,))).unsqueeze(0).unsqueeze(1), None, [1])\n",
        "ddpg.action_space = action_space\n",
        "ddpg.replay.generate_episode(init_policy, False, False, True, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-300.48157142857144"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzIsZcLC-NcR",
        "outputId": "1b98d250-0824-4631-8a98-27e497ebc1f0"
      },
      "source": [
        "np.sum(ddpg.replay.env.global_map == 255)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57088"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSsm56JjCda8",
        "outputId": "b1773da3-e2a4-4b83-90e8-f396782c133a"
      },
      "source": [
        "640 * 480"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "307200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUD6ZRLZC2GK",
        "outputId": "91d9437a-6e86-42b7-c748-44b952b1dbbd"
      },
      "source": [
        "test = nn.Linear(512, 2)\n",
        "\n",
        "vec = torch.randn(1, 1, 512)\n",
        "\n",
        "test(vec).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2z4lsEooyg9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}