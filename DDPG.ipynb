{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "DDPG.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJBqQwnOM5hX",
        "outputId": "0cf068c5-17f2-418c-937c-3a79a94a9300"
      },
      "source": [
        "#Install pybind11\n",
        "!git clone https://github.com/pybind/pybind11.git\n",
        "!cd pybind11 && mkdir build && cd build && cmake .. && make install"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pybind11'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 13925 (delta 6), reused 11 (delta 1), pack-reused 13897\u001b[K\n",
            "Receiving objects: 100% (13925/13925), 5.44 MiB | 23.82 MiB/s, done.\n",
            "Resolving deltas: 100% (9467/9467), done.\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- pybind11 v2.6.2 dev1\n",
            "-- CMake 3.12.0\n",
            "-- Found PythonInterp: /usr/bin/python3.6 (found version \"3.6.9\") \n",
            "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so\n",
            "-- PYTHON 3.6.9\n",
            "-- Performing Test HAS_FLTO\n",
            "-- Performing Test HAS_FLTO - Success\n",
            "-- pybind11::lto enabled\n",
            "-- pybind11::thin_lto enabled\n",
            "-- Setting tests build type to MinSizeRel as none was specified\n",
            "-- Building tests WITHOUT Eigen, use -DDOWNLOAD_EIGEN on CMake 3.11+ to download\n",
            "-- Boost version: 1.65.1\n",
            "-- Found pytest 3.6.4\n",
            "-- Catch not detected. Interpreter tests will be skipped. Install Catch headers manually or use `cmake -DDOWNLOAD_CATCH=ON` to fetch them automatically.\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/pybind11/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target pybind11_cross_module_tests\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_cross_module_tests.dir/pybind11_cross_module_tests.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32m\u001b[1mLinking CXX shared module pybind11_cross_module_tests.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[  4%] Built target pybind11_cross_module_tests\n",
            "\u001b[35m\u001b[1mScanning dependencies of target pybind11_tests\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/pybind11_tests.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_async.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_buffers.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_builtin_casters.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_call_policies.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_callbacks.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_chrono.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_class.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_constants_and_functions.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_copy_move.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_custom_type_casters.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_docstring_options.cpp.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_enum.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_eval.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_exceptions.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_factory_constructors.cpp.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_gil_scoped.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_iostream.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_kwargs_and_defaults.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_local_bindings.cpp.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_methods_and_attributes.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_modules.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_multiple_inheritance.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_array.cpp.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_dtypes.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_vectorize.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_opaque_types.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_operator_overloading.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_pickling.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_pytypes.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_sequences_and_iterators.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_smart_ptr.cpp.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_stl.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_stl_binders.cpp.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_tagbased_polymorphic.cpp.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_union.cpp.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_virtual_functions.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX shared module pybind11_tests.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "------ pybind11_tests.cpython-36m-x86_64-linux-gnu.so file size: 2032248\n",
            "[ 95%] Built target pybind11_tests\n",
            "\u001b[35m\u001b[1mScanning dependencies of target cross_module_gil_utils\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object tests/CMakeFiles/cross_module_gil_utils.dir/cross_module_gil_utils.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared module cross_module_gil_utils.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[100%] Built target cross_module_gil_utils\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"MinSizeRel\"\n",
            "-- Installing: /usr/local/include/pybind11\n",
            "-- Installing: /usr/local/include/pybind11/eigen.h\n",
            "-- Installing: /usr/local/include/pybind11/cast.h\n",
            "-- Installing: /usr/local/include/pybind11/stl.h\n",
            "-- Installing: /usr/local/include/pybind11/iostream.h\n",
            "-- Installing: /usr/local/include/pybind11/common.h\n",
            "-- Installing: /usr/local/include/pybind11/options.h\n",
            "-- Installing: /usr/local/include/pybind11/stl_bind.h\n",
            "-- Installing: /usr/local/include/pybind11/functional.h\n",
            "-- Installing: /usr/local/include/pybind11/numpy.h\n",
            "-- Installing: /usr/local/include/pybind11/operators.h\n",
            "-- Installing: /usr/local/include/pybind11/attr.h\n",
            "-- Installing: /usr/local/include/pybind11/buffer_info.h\n",
            "-- Installing: /usr/local/include/pybind11/pytypes.h\n",
            "-- Installing: /usr/local/include/pybind11/pybind11.h\n",
            "-- Installing: /usr/local/include/pybind11/complex.h\n",
            "-- Installing: /usr/local/include/pybind11/embed.h\n",
            "-- Installing: /usr/local/include/pybind11/detail\n",
            "-- Installing: /usr/local/include/pybind11/detail/class.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/common.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/init.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/descr.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/typeid.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/internals.h\n",
            "-- Installing: /usr/local/include/pybind11/chrono.h\n",
            "-- Installing: /usr/local/include/pybind11/eval.h\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Config.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11ConfigVersion.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/FindPythonLibsNew.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Common.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Tools.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11NewTools.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Targets.cmake\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwAQeZFoM8IL",
        "outputId": "e27d5ce4-ebb3-4ea3-ed0c-6f568c465fd8"
      },
      "source": [
        "#Install Eigen\n",
        "!apt install libeigen3-dev\n",
        "!ln -sf /usr/include/eigen3/Eigen /usr/include/Eigen"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libeigen3-doc libmrpt-dev\n",
            "The following NEW packages will be installed:\n",
            "  libeigen3-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 810 kB of archives.\n",
            "After this operation, 7,128 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libeigen3-dev all 3.3.4-4 [810 kB]\n",
            "Fetched 810 kB in 1s (1,162 kB/s)\n",
            "Selecting previously unselected package libeigen3-dev.\n",
            "(Reading database ... 144793 files and directories currently installed.)\n",
            "Preparing to unpack .../libeigen3-dev_3.3.4-4_all.deb ...\n",
            "Unpacking libeigen3-dev (3.3.4-4) ...\n",
            "Setting up libeigen3-dev (3.3.4-4) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wohYNJjVNAs3",
        "outputId": "c6b4c6c7-f30f-427a-879d-2fa11cdc7804"
      },
      "source": [
        "# Install dependencies on colab\n",
        "!git clone https://github.com/OttoJursch/DRL_robot_exploration.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DRL_robot_exploration'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 11108 (delta 31), reused 31 (delta 12), pack-reused 11049\u001b[K\n",
            "Receiving objects: 100% (11108/11108), 284.76 MiB | 32.75 MiB/s, done.\n",
            "Resolving deltas: 100% (124/124), done.\n",
            "Checking out files: 100% (10919/10919), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqK51GzA9nOa"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "class SizeEstimator(object):\n",
        "\n",
        "    def __init__(self, model, input_size=(1,1,32,32), bits=32):\n",
        "        '''\n",
        "        Estimates the size of PyTorch models in memory\n",
        "        for a given input size\n",
        "        '''\n",
        "        self.model = model\n",
        "        self.input_size = input_size\n",
        "        self.bits = bits\n",
        "        return\n",
        "\n",
        "    def get_parameter_sizes(self):\n",
        "        '''Get sizes of all parameters in `model`'''\n",
        "        mods = list(self.model.modules())\n",
        "        sizes = []\n",
        "        \n",
        "        for i in range(1,len(mods)):\n",
        "            m = mods[i]\n",
        "            p = list(m.parameters())\n",
        "            for j in range(len(p)):\n",
        "                sizes.append(np.array(p[j].size()))\n",
        "\n",
        "        self.param_sizes = sizes\n",
        "        return\n",
        "\n",
        "    def get_output_sizes(self):\n",
        "        '''Run sample input through each layer to get output sizes'''\n",
        "        input_ = Variable(torch.FloatTensor(*self.input_size), volatile=True)\n",
        "        mods = list(self.model.modules())\n",
        "        out_sizes = []\n",
        "        for i in range(1, len(mods)):\n",
        "            m = mods[i]\n",
        "            out = m(input_)\n",
        "            out_sizes.append(np.array(out.size()))\n",
        "            input_ = out\n",
        "\n",
        "        self.out_sizes = out_sizes\n",
        "        return\n",
        "\n",
        "    def calc_param_bits(self):\n",
        "        '''Calculate total number of bits to store `model` parameters'''\n",
        "        total_bits = 0\n",
        "        for i in range(len(self.param_sizes)):\n",
        "            s = self.param_sizes[i]\n",
        "            bits = np.prod(np.array(s))*self.bits\n",
        "            total_bits += bits\n",
        "        self.param_bits = total_bits\n",
        "        return\n",
        "\n",
        "    def calc_forward_backward_bits(self):\n",
        "        '''Calculate bits to store forward and backward pass'''\n",
        "        total_bits = 0\n",
        "        for i in range(len(self.out_sizes)):\n",
        "            s = self.out_sizes[i]\n",
        "            bits = np.prod(np.array(s))*self.bits\n",
        "            total_bits += bits\n",
        "        # multiply by 2 for both forward AND backward\n",
        "        self.forward_backward_bits = (total_bits*2)\n",
        "        return\n",
        "\n",
        "    def calc_input_bits(self):\n",
        "        '''Calculate bits to store input'''\n",
        "        self.input_bits = np.prod(np.array(self.input_size))*self.bits\n",
        "        return\n",
        "\n",
        "    def estimate_size(self):\n",
        "        '''Estimate model size in memory in megabytes and bits'''\n",
        "        self.get_parameter_sizes()\n",
        "        self.get_output_sizes()\n",
        "        self.calc_param_bits()\n",
        "        self.calc_forward_backward_bits()\n",
        "        self.calc_input_bits()\n",
        "        total = self.param_bits + self.forward_backward_bits + self.input_bits\n",
        "\n",
        "        total_megabytes = (total/8)/(1024**2)\n",
        "        return total_megabytes, total"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO_EJKEoNC6T"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchsummary\n",
        "import numpy as np\n",
        "\n",
        "def build_conv_feature_extractor(conv_dims, act):\n",
        "  #Create Conv2D + MaxPool layers\n",
        "  conv_layers = [nn.Conv2d(*conv_dim) if len(conv_dim) == 3 else nn.MaxPool2d(conv_dim) for conv_dim in conv_dims]\n",
        "  total_layers = []\n",
        "\n",
        "  #Add ReLU activations after each conv layer\n",
        "  for layer in conv_layers:\n",
        "    total_layers.append(layer)\n",
        "    if type(layer) == nn.Conv2d:\n",
        "      total_layers.append(act())\n",
        "  return nn.Sequential(*total_layers)\n",
        "  \n",
        "\n",
        "def get_output_shape(model, image_dim):\n",
        "    return model(torch.rand(*(image_dim))).data.shape\n",
        "\n",
        "class RNNActor(nn.Module):\n",
        "  #TODO Determine if the action space allows negative numbers\n",
        "  #Potentially replace tanh with sigmoid\n",
        "  def __init__(self, conv_dims, lstm_hidden, lstm_out, train_length, input_size=(1, 1,224,224), act=nn.ReLU, final_act=nn.Tanh):\n",
        "    super(RNNActor, self).__init__()\n",
        "\n",
        "    self.conv_mod = build_conv_feature_extractor(conv_dims, act)\n",
        "    \n",
        "    #Silly way to determine the size going into the RNN\n",
        "    with torch.no_grad():\n",
        "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
        "\n",
        "    print('LSTM Input Size', feature_size)\n",
        "\n",
        "    #Construct LSTM\n",
        "    self.lstm_hidden = lstm_hidden\n",
        "    self.lstm = nn.LSTM(np.prod(list(feature_size)), lstm_hidden, lstm_out)\n",
        "    self.train_length = train_length\n",
        "    self.final_act = final_act\n",
        "\n",
        "  def forward(self, image, positions, state):\n",
        "    batch_size = x.size()[0]\n",
        "    conv = self.conv_mod(x)\n",
        "    flat = torch.reshape(conv.flatten(), (batch_size, self.train_length, self.lstm_hidden))\n",
        "    state = torch.hstack((flat, positions))\n",
        "    action, hidden = self.lstm(state, state)\n",
        "\n",
        "    #Scale by the max/min bounds of the action space later\n",
        "    return self.final_act(action), hidden"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMUxifkjVCJE",
        "outputId": "8c46df4b-489d-4d7c-e893-7f0760325f4a"
      },
      "source": [
        "conv_dims = [(1, 32, 8), (32, 64, 4), (2, 2), (64, 64, 3), (64, 512, 7), (2, 2), (512, 64, 1)]\n",
        "\n",
        "lstm_hidden = 512\n",
        "lstm_out = 2\n",
        "train_length = 50\n",
        "\n",
        "rnn = RNNActor(conv_dims, lstm_hidden, lstm_out, train_length)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM Input Size torch.Size([1, 64, 49, 49])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgxUtoeMJ8Pa"
      },
      "source": [
        "def build_dense_regression(linear_dims, act, final_act=None):\n",
        "  print(linear_dims)\n",
        "  linear_layers = [nn.Linear(*linear_dim)  for linear_dim in linear_dims]\n",
        "  print(linear_layers)\n",
        "  activations = [act() for layer in range(len(linear_layers) - 1)]\n",
        "  if final_act is not None:\n",
        "    activations.append(final_act)\n",
        "  return nn.Sequential(*[val for tup in zip(*[linear_layers, activations]) for val in tup]\n",
        ")\n",
        "\n",
        "class CNNCritic(nn.Module):\n",
        "  def __init__(self, conv_dims, fc_dims, input_size=(1, 1,224,224), conv_act=nn.ReLU, fc_act=nn.ReLU):\n",
        "    super(CNNCritic, self).__init__()\n",
        "    self.conv_mod = build_conv_feature_extractor(conv_dims, conv_act)\n",
        "\n",
        "    #Silly way to determine the size going into the RNN\n",
        "    with torch.no_grad():\n",
        "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
        "\n",
        "    #Add 4 for action + position\n",
        "    feature_size = np.prod(list(feature_size)) + 4\n",
        "    first_output = fc_dims[0][0]\n",
        "    fc_dims.insert(0, (feature_size, first_output))\n",
        "\n",
        "    self.fc = build_dense_regression(fc_dims, fc_act)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self, map, pos, action):\n",
        "    batch_size = x.size()[0]\n",
        "    map_feats = self.conv_mod(map)\n",
        "    all_feats = torch.hstack([map_feats, pos, action])\n",
        "    return self.fc(total_feats)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4Q7eTJfcJ7a",
        "outputId": "207750fd-1169-4afa-940a-a9420b39d3de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "linear_dims = [(256, 128), (128, 1)]\n",
        "conv_dims = [(1, 32, 8), (32, 64, 4), (2, 2), (64, 64, 3), (64, 512, 7), (2, 2), (512, 64, 1)]\n",
        "\n",
        "critic = CNNCritic(conv_dims, linear_dims)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(153664, 256), (256, 128), (128, 1)]\n",
            "[Linear(in_features=153664, out_features=256, bias=True), Linear(in_features=256, out_features=128, bias=True), Linear(in_features=128, out_features=1, bias=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFMjDGz1N958"
      },
      "source": [
        "\"\"\" Learn a policy using DDPG for the reach task\"\"\"\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import MultivariateNormal\n",
        "from torch.nn import MSELoss\n",
        "import random\n",
        "\n",
        "import gym\n",
        "import pybullet\n",
        "import pybulletgym.envs\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "np.random.seed(1000)\n",
        "\n",
        "\n",
        "# TODO: A function to soft update target networks\n",
        "def weighSync(target_model, source_model, tau=0.001):\n",
        "  for (target, src) in zip(target_model.parameters(), source_model.parameters()):\n",
        "    target.data = (1-tau) * target.data + tau * src.data \n",
        "\n",
        "# TODO: Write the ReplayBuffer\n",
        "class Replay():\n",
        "    def __init__(self, buffer_size, init_length, state_dim, action_dim, env):\n",
        "        \"\"\"\n",
        "        A function to initialize the replay buffer.\n",
        "\n",
        "        param: init_length : Initial number of transitions to collect\n",
        "        param: state_dim : Size of the state space\n",
        "        param: action_dim : Size of the action space\n",
        "        param: env : gym environment object\n",
        "        \"\"\"\n",
        "        self.buffer = np.zeros((buffer_size, 2 * state_dim + action_dim + 1))\n",
        "        state = env.reset()\n",
        "        self.buffer_idx = 0\n",
        "        self.total_steps = 0\n",
        "        last_state = env.reset()\n",
        "        for i in range(init_length):\n",
        "          action = np.random.uniform(-1, 1, (2,))\n",
        "          state, reward, _, _ = env.step(action)\n",
        "          self.buffer[self.buffer_idx, :] = np.hstack([state, last_state, action, reward])\n",
        "          self.total_steps = min(self.total_steps + 1, len(self.buffer))\n",
        "          self.buffer_idx = (self.buffer_idx + 1) % len(self.buffer)\n",
        "          last_state = state\n",
        "\n",
        "\n",
        "\n",
        "    # TODO: Complete the function\n",
        "    def buffer_add(self, exp):\n",
        "        \"\"\"\n",
        "        A function to add a dictionary to the buffer\n",
        "        param: exp : A dictionary consisting of state, action, reward , next state and done flag\n",
        "        \"\"\"\n",
        "        self.buffer[self.buffer_idx, :] = np.hstack([exp['state'], exp['last_state'], exp['action'].cpu().detach().numpy(), np.array([exp['reward']])])\n",
        "        self.buffer_idx = (self.buffer_idx + 1) % len(self.buffer)\n",
        "        self.total_steps = min(self.total_steps + 1, len(self.buffer))\n",
        "\n",
        "    #TODO: Complete the function\n",
        "    def buffer_sample(self, N):\n",
        "        \"\"\"\n",
        "        A function to sample N points from the buffer\n",
        "        param: N : Number of samples to obtain from the buffer\n",
        "        \"\"\"\n",
        "        if N > self.total_steps:\n",
        "          return torch.from_numpy(self.buffer[:self.total_steps, :]).float().to(device='cuda')\n",
        "\n",
        "        perm = np.random.permutation(min(self.buffer.shape[0], self.total_steps))\n",
        "        idx = perm[:N]\n",
        "        samples = self.buffer[idx,:]\n",
        "        self.total_steps += 1\n",
        "        return torch.from_numpy(samples).float().to(device='cuda')\n",
        "\n",
        "\n",
        "# TODO: Implement a DDPG class\n",
        "class DDPG():\n",
        "    def __init__(\n",
        "            self,\n",
        "            env,\n",
        "            action_dim,\n",
        "            state_dim,\n",
        "            critic_lr=3e-4,\n",
        "            actor_lr=3e-4,\n",
        "            gamma=0.99,\n",
        "            batch_size=100,\n",
        "            seed=1000\n",
        "    ):\n",
        "        \"\"\"\n",
        "        param: env: An gym environment\n",
        "        param: action_dim: Size of action space\n",
        "        param: state_dim: Size of state space\n",
        "        param: critic_lr: Learning rate of the critic\n",
        "        param: actor_lr: Learning rate of the actor\n",
        "        param: gamma: The discount factor\n",
        "        param: batch_size: The batch size for training\n",
        "        \"\"\"\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        self.gamma = gamma\n",
        "        self.batch_size = batch_size\n",
        "        self.env = env\n",
        "        self.state_dim = state_dim\n",
        "\n",
        "        # TODO: Create a actor and actor_target\n",
        "        self.actor = Actor(state_dim, action_dim).to(device='cuda')\n",
        "        self.actor_target = copy.deepcopy(self.actor)\n",
        "\n",
        "        # TODO: Make sure that both networks have the same initial weights\n",
        "\n",
        "        # TODO: Create a critic and critic_target object\n",
        "        self.critic = Critic(state_dim, action_dim).to(device='cuda')\n",
        "        self.critic_target = copy.deepcopy(self.critic)\n",
        "        # TODO: Make sure that both networks have the same initial weights\n",
        "\n",
        "        # TODO: Define the optimizer for the actor\n",
        "        self.optimizer_actor = optim.Adam(self.actor.parameters(), actor_lr)\n",
        "        # TODO: Define the optimizer for the critic\n",
        "        self.optimizer_critic = optim.Adam(self.critic.parameters(), critic_lr)\n",
        "\n",
        "        # TODO: define a replay buffer\n",
        "        self.ReplayBuffer = Replay(10000, 1000, state_dim, action_dim, env)\n",
        "\n",
        "    # TODO: Complete the function\n",
        "    def update_target_networks(self):\n",
        "        \"\"\"\n",
        "        A function to update the target networks\n",
        "        \"\"\"\n",
        "        weighSync(self.actor_target, self.actor)\n",
        "        weighSync(self.critic_target, self.critic)\n",
        "\n",
        "    # TODO: Complete the function\n",
        "    def update_network(self, y_i, obs, actions):\n",
        "        \"\"\"\n",
        "        A function to update the function just once\n",
        "        \"\"\"\n",
        "        qs = self.critic(obs, actions).squeeze(-1)\n",
        "        critic_loss = self.critic_criterion(y_i, qs)\n",
        "        critic_loss.backward()\n",
        "\n",
        "        self.optimizer_critic.step()\n",
        "\n",
        "        act = self.actor(obs)\n",
        "        qs = self.critic(obs, act)\n",
        "        #print(actions.size())\n",
        "        (-qs).mean().backward()\n",
        "        self.optimizer_actor.step()\n",
        "\n",
        "  \n",
        "    # TODO: Complete the function\n",
        "    def train(self, num_steps):\n",
        "        \"\"\"\n",
        "        Train the policy for the given number of iterations\n",
        "        :param num_steps:The number of steps to train the policy for\n",
        "        \"\"\"\n",
        "        self.critic_criterion = MSELoss()\n",
        "        noise = MultivariateNormal(torch.zeros(2), torch.diag(torch.tensor([0.1, 0.1])))\n",
        "        num_episodes = 0\n",
        "        i = 0\n",
        "        total_reward = 0\n",
        "        total_steps = 0\n",
        "        episode_reward = 0\n",
        "        test_env = gym.make('modified_gym_env:ReacherPyBulletEnv-v1')\n",
        "        steps_list = []\n",
        "        rewards = []\n",
        "        while i < num_steps:\n",
        "          done = False\n",
        "          last_state = self.env.reset()\n",
        "          num_episodes += 1\n",
        "          while not done:\n",
        "            i += 1\n",
        "            self.optimizer_critic.zero_grad()\n",
        "            self.optimizer_actor.zero_grad()\n",
        "\n",
        "            action = self.actor(torch.from_numpy(last_state).float().to(device='cuda')) + noise.sample().to(device='cuda')\n",
        "            state, reward, done, _ = self.env.step(action.cpu().detach().numpy())\n",
        "            self.ReplayBuffer.buffer_add({'state':state, 'last_state':last_state, 'reward':reward, 'action':action})\n",
        "            batch = self.ReplayBuffer.buffer_sample(self.batch_size)\n",
        "            #print(batch.size())\n",
        "            r_i = batch[:, -1]\n",
        "            actions = batch[:,2*self.state_dim:2*self.state_dim+2]\n",
        "            states = batch[:,self.state_dim:2*self.state_dim]\n",
        "            next_states = batch[:, :self.state_dim]\n",
        "            with torch.no_grad():\n",
        "              crit = self.critic_target(next_states, self.actor_target(next_states)).squeeze(-1)\n",
        "              y_i = r_i + self.gamma * crit\n",
        "\n",
        "            self.update_network(y_i, states, actions)\n",
        "\n",
        "            self.update_target_networks()\n",
        "\n",
        "            if i % 100 == 0:\n",
        "              test_done = False\n",
        "              episode_reward = 0\n",
        "              the_steps = 0\n",
        "              s = test_env.reset()\n",
        "              while not test_done:\n",
        "                total_steps += 1\n",
        "                the_steps += 1\n",
        "                action = self.actor(torch.from_numpy(s).float().to(device='cuda')).detach().squeeze().cpu().numpy()\n",
        "                n_state, r, test_done, _ = test_env.step(action)\n",
        "                s = n_state\n",
        "                episode_reward += r\n",
        "\n",
        "              rewards.append(episode_reward)\n",
        "              steps_list.append(the_steps)\n",
        "              print('Episode reward')\n",
        "              print(episode_reward)\n",
        "\n",
        "            last_state = state\n",
        "\n",
        "          state = self.env.reset()\n",
        "\n",
        "        return rewards, steps_list"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}