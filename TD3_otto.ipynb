{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DDPG.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OttoJursch/DRL_robot_exploration/blob/master/TD3_otto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJBqQwnOM5hX",
        "outputId": "82147d09-f5bd-4c82-bdcf-55fb9d81ae33"
      },
      "source": [
        "#Install pybind11\n",
        "!git clone https://github.com/pybind/pybind11.git\n",
        "!cd pybind11 && mkdir build && cd build && cmake .. && make install"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pybind11'...\n",
            "remote: Enumerating objects: 13942, done.\u001b[K\n",
            "remote: Total 13942 (delta 0), reused 0 (delta 0), pack-reused 13942\u001b[K\n",
            "Receiving objects: 100% (13942/13942), 5.40 MiB | 25.71 MiB/s, done.\n",
            "Resolving deltas: 100% (9492/9492), done.\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- pybind11 v2.6.2 dev1\n",
            "-- CMake 3.12.0\n",
            "-- Found PythonInterp: /usr/bin/python3.6 (found version \"3.6.9\") \n",
            "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so\n",
            "-- PYTHON 3.6.9\n",
            "-- Performing Test HAS_FLTO\n",
            "-- Performing Test HAS_FLTO - Success\n",
            "-- pybind11::lto enabled\n",
            "-- pybind11::thin_lto enabled\n",
            "-- Setting tests build type to MinSizeRel as none was specified\n",
            "-- Building tests WITHOUT Eigen, use -DDOWNLOAD_EIGEN on CMake 3.11+ to download\n",
            "-- Boost version: 1.65.1\n",
            "-- Found pytest 3.6.4\n",
            "-- Catch not detected. Interpreter tests will be skipped. Install Catch headers manually or use `cmake -DDOWNLOAD_CATCH=ON` to fetch them automatically.\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/pybind11/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target pybind11_cross_module_tests\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_cross_module_tests.dir/pybind11_cross_module_tests.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32m\u001b[1mLinking CXX shared module pybind11_cross_module_tests.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[  4%] Built target pybind11_cross_module_tests\n",
            "\u001b[35m\u001b[1mScanning dependencies of target pybind11_tests\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/pybind11_tests.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_async.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_buffers.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_builtin_casters.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_call_policies.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_callbacks.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_chrono.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_class.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_constants_and_functions.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_copy_move.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_custom_type_casters.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_docstring_options.cpp.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_enum.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_eval.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_exceptions.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_factory_constructors.cpp.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_gil_scoped.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_iostream.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_kwargs_and_defaults.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_local_bindings.cpp.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_methods_and_attributes.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_modules.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_multiple_inheritance.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_array.cpp.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_dtypes.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_vectorize.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_opaque_types.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_operator_overloading.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_pickling.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_pytypes.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_sequences_and_iterators.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_smart_ptr.cpp.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_stl.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_stl_binders.cpp.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_tagbased_polymorphic.cpp.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_union.cpp.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_virtual_functions.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX shared module pybind11_tests.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "------ pybind11_tests.cpython-36m-x86_64-linux-gnu.so file size: 2032248\n",
            "[ 95%] Built target pybind11_tests\n",
            "\u001b[35m\u001b[1mScanning dependencies of target cross_module_gil_utils\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object tests/CMakeFiles/cross_module_gil_utils.dir/cross_module_gil_utils.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared module cross_module_gil_utils.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[100%] Built target cross_module_gil_utils\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"MinSizeRel\"\n",
            "-- Installing: /usr/local/include/pybind11\n",
            "-- Installing: /usr/local/include/pybind11/attr.h\n",
            "-- Installing: /usr/local/include/pybind11/numpy.h\n",
            "-- Installing: /usr/local/include/pybind11/eigen.h\n",
            "-- Installing: /usr/local/include/pybind11/pytypes.h\n",
            "-- Installing: /usr/local/include/pybind11/buffer_info.h\n",
            "-- Installing: /usr/local/include/pybind11/iostream.h\n",
            "-- Installing: /usr/local/include/pybind11/stl_bind.h\n",
            "-- Installing: /usr/local/include/pybind11/eval.h\n",
            "-- Installing: /usr/local/include/pybind11/common.h\n",
            "-- Installing: /usr/local/include/pybind11/chrono.h\n",
            "-- Installing: /usr/local/include/pybind11/operators.h\n",
            "-- Installing: /usr/local/include/pybind11/cast.h\n",
            "-- Installing: /usr/local/include/pybind11/pybind11.h\n",
            "-- Installing: /usr/local/include/pybind11/complex.h\n",
            "-- Installing: /usr/local/include/pybind11/detail\n",
            "-- Installing: /usr/local/include/pybind11/detail/init.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/common.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/class.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/typeid.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/internals.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/descr.h\n",
            "-- Installing: /usr/local/include/pybind11/functional.h\n",
            "-- Installing: /usr/local/include/pybind11/stl.h\n",
            "-- Installing: /usr/local/include/pybind11/embed.h\n",
            "-- Installing: /usr/local/include/pybind11/options.h\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Config.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11ConfigVersion.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/FindPythonLibsNew.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Common.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Tools.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11NewTools.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Targets.cmake\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwAQeZFoM8IL",
        "outputId": "a12f654d-aee4-4a46-eaa4-8bbbbb70959a"
      },
      "source": [
        "#Install Eigen\n",
        "!apt install libeigen3-dev\n",
        "!ln -sf /usr/include/eigen3/Eigen /usr/include/Eigen"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libeigen3-doc libmrpt-dev\n",
            "The following NEW packages will be installed:\n",
            "  libeigen3-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 810 kB of archives.\n",
            "After this operation, 7,128 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libeigen3-dev all 3.3.4-4 [810 kB]\n",
            "Fetched 810 kB in 1s (1,150 kB/s)\n",
            "Selecting previously unselected package libeigen3-dev.\n",
            "(Reading database ... 144865 files and directories currently installed.)\n",
            "Preparing to unpack .../libeigen3-dev_3.3.4-4_all.deb ...\n",
            "Unpacking libeigen3-dev (3.3.4-4) ...\n",
            "Setting up libeigen3-dev (3.3.4-4) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wohYNJjVNAs3",
        "outputId": "2516d774-580a-406b-a071-cc335d3f16f6"
      },
      "source": [
        "# Install dependencies on colab\n",
        "!git clone https://github.com/OttoJursch/DRL_robot_exploration.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DRL_robot_exploration'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 11338 (delta 3), reused 0 (delta 0), pack-reused 11326\u001b[K\n",
            "Receiving objects: 100% (11338/11338), 323.28 MiB | 34.60 MiB/s, done.\n",
            "Resolving deltas: 100% (259/259), done.\n",
            "Checking out files: 100% (10924/10924), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdbx9dj_zRQ_",
        "outputId": "7b179172-7f48-4490-ccd4-31c2684f8d1d"
      },
      "source": [
        "!#Build the C++/pybind stuff\n",
        "!rm -rf DRL_robot_exploration/build\n",
        "!cd DRL_robot_exploration && mkdir build && cd build && cmake .. && make"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found PythonInterp: /usr/bin/python3 (found version \"3.6.9\") \n",
            "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so\n",
            "-- Performing Test HAS_FLTO\n",
            "-- Performing Test HAS_FLTO - Success\n",
            "-- Found pybind11: /usr/local/include (found version \"2.6.2\" dev1)\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/DRL_robot_exploration/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target astar\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/astar.dir/src/astar.cpp.o\u001b[0m\n",
            "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/astar.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* pybind11_init()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/astar.cpp:140:32:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kpybind11::module_::module_(const char*, const char*)\u001b[m\u001b[K’ is deprecated: Use PYBIND11_MODULE or module_::create_extension_module instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   py::module m(\"astar\", \"astar\"\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/include/pybind11/numpy.h:12:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/include/pybind11/eigen.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/DRL_robot_exploration/src/astar.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/include/pybind11/pybind11.h:897:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "     explicit \u001b[01;36m\u001b[Kmodule_\u001b[m\u001b[K(const char *name, const char *doc = nullptr) {\n",
            "              \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module astar.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[ 50%] Built target astar\n",
            "\u001b[35m\u001b[1mScanning dependencies of target inverse_sensor_model\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/inverse_sensor_model.dir/src/inverse_sensor_model.cpp.o\u001b[0m\n",
            "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/inverse_sensor_model.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* pybind11_init()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/inverse_sensor_model.cpp:64:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kpybind11::module_::module_(const char*, const char*)\u001b[m\u001b[K’ is deprecated: Use PYBIND11_MODULE or module_::create_extension_module instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   py::module m(\"inverse_sensor_model\", \"inverse_sensor_model\"\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/include/pybind11/numpy.h:12:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/include/pybind11/eigen.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/DRL_robot_exploration/src/inverse_sensor_model.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/include/pybind11/pybind11.h:897:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "     explicit \u001b[01;36m\u001b[Kmodule_\u001b[m\u001b[K(const char *name, const char *doc = nullptr) {\n",
            "              \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared module inverse_sensor_model.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[100%] Built target inverse_sensor_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH4Hccvf4Pdh",
        "outputId": "132075a5-8566-4ef1-c5ec-18cd760907f0"
      },
      "source": [
        "!cd DRL_robot_exploration && git pull"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0Y_Sk2aubxH"
      },
      "source": [
        "#laptop=True\n",
        "laptop=False"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5BsFx_f9ONI"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "class PaperRewardFunction:\n",
        "    '''\n",
        "    Reward function from the paper\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def get_reward(self, robot_position, old_op_map, op_map, coll_index):\n",
        "        '''\n",
        "        Takes in map before step and map after step. Measures effect of sensor\n",
        "        input from last step\n",
        "        '''\n",
        "        if not coll_index:\n",
        "            reward = float(\n",
        "                np.size(np.where(op_map == 255)) - np.size(np.where(old_op_map == 255))) / 14000\n",
        "            if reward > 1:\n",
        "                reward = 1\n",
        "        else:\n",
        "            reward = -1\n",
        "        return reward\n",
        "\n",
        "\n",
        "class FrontierRewardFunction:\n",
        "    def __init__(self, reward_scale):\n",
        "        self.reward_scale = reward_scale\n",
        "        self.paper_reward = PaperRewardFunction()\n",
        "\n",
        "    def frontiers(self, op_map, map_size, points):\n",
        "        y_len = map_size[0]\n",
        "        x_len = map_size[1]\n",
        "        mapping = op_map.copy()\n",
        "        # 0-1 unknown area map\n",
        "        mapping = (mapping == 127) * 1\n",
        "        mapping = np.lib.pad(mapping, ((1, 1), (1, 1)),\n",
        "                             'constant',\n",
        "                             constant_values=0)\n",
        "        fro_map = mapping[2:][:, 1:x_len + 1] + mapping[:y_len][:, 1:x_len + 1] + mapping[1:y_len + 1][:, 2:] + \\\n",
        "                  mapping[1:y_len + 1][:, :x_len] + mapping[:y_len][:, 2:] + mapping[2:][:, :x_len] + mapping[2:][:,\n",
        "                                                                                                      2:] + \\\n",
        "                  mapping[:y_len][:, :x_len]\n",
        "\n",
        "        ind_free = np.where(op_map.ravel(order='F') == 255)[0]\n",
        "        ind_fron_1 = np.where(1 < fro_map.ravel(order='F'))[0]\n",
        "        ind_fron_2 = np.where(fro_map.ravel(order='F') < 8)[0]\n",
        "        ind_fron = np.intersect1d(ind_fron_1, ind_fron_2)\n",
        "        ind_to = np.intersect1d(ind_free, ind_fron)\n",
        "        f = points[ind_to]\n",
        "        f = f.astype(int)\n",
        "        return f\n",
        "\n",
        "    def map_points(self, map_glo):\n",
        "        map_x = map_glo.shape[1]\n",
        "        map_y = map_glo.shape[0]\n",
        "        x = np.linspace(0, map_x - 1, map_x)\n",
        "        y = np.linspace(0, map_y - 1, map_y)\n",
        "        t1, t2 = np.meshgrid(x, y)\n",
        "        points = np.vstack([t1.T.ravel(), t2.T.ravel()]).T\n",
        "        return points\n",
        "\n",
        "    def get_reward(self, robot_pos, old_op_map, op_map, coll_index):\n",
        "        paper_reward = self.paper_reward.get_reward(robot_pos, old_op_map,\n",
        "                                                    op_map, coll_index)\n",
        "\n",
        "        #If there was a collision return the collision reward\n",
        "        if coll_index:\n",
        "            return paper_reward\n",
        "\n",
        "        frontiers = np.array(\n",
        "            self.frontiers(op_map, op_map.shape, self.map_points(op_map)))\n",
        "\n",
        "        min_frontier_dist = -np.min(np.linalg.norm(robot_pos - frontiers, axis=1))\n",
        "        return self.reward_scale * min_frontier_dist + paper_reward\n",
        "\n",
        "sqrt2 = 2**0.5 +0.1\n",
        "class PolarActionSpace:\n",
        "    '''\n",
        "    Action space is polar representation of vector robot should take from its\n",
        "    current position\n",
        "\n",
        "    This class will take that and add it to the current robot position to get \n",
        "    '''\n",
        "    def __init__(self, min_travel, max_travel):\n",
        "        self.max_distance = max_travel\n",
        "        self.min_travel = min_travel\n",
        "\n",
        "    def get_action(self, action_polar_coords, robot_position):\n",
        "        angle = action_polar_coords[0] * (2 * np.pi)\n",
        "        dist = action_polar_coords[1] * (self.max_distance - self.min_travel) + self.min_travel\n",
        "        dx = dist * np.sin(angle)\n",
        "        dy = dist * np.cos(angle)\n",
        "\n",
        "        return np.array([dx, dy])\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l08KzoEf_xt3"
      },
      "source": [
        "from scipy import spatial\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import numpy.ma as ma\n",
        "import time\n",
        "import sys\n",
        "from scipy import ndimage\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sys.path.append('DRL_robot_exploration')\n",
        "if laptop:\n",
        "    from build.inverse_sensor_model import *\n",
        "    from build.astar import *\n",
        "else:\n",
        "    from DRL_robot_exploration.build.inverse_sensor_model import *\n",
        "    from DRL_robot_exploration.build.astar import *\n",
        "from random import shuffle\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "class Robot:\n",
        "    def __init__(self,\n",
        "                 index_map,\n",
        "                 train,\n",
        "                 plot,\n",
        "                 root_dir,\n",
        "                 action_space,\n",
        "                 reward_function,\n",
        "                 do_rescue,\n",
        "                 shuffle=True):\n",
        "        self.mode = train\n",
        "        self.action_space = action_space\n",
        "        self.plot = plot\n",
        "        self.root_dir = root_dir\n",
        "        self.index_map = index_map\n",
        "        self.do_rescue = do_rescue\n",
        "        self.reward_function = reward_function\n",
        "        self.reset(index_map, shuffle)\n",
        "\n",
        "    def reset(self, index_map=None, do_shuffle=True):\n",
        "        if self.mode:\n",
        "            self.map_dir = os.path.join(self.root_dir, 'train')\n",
        "        else:\n",
        "            self.map_dir = os.path.join(self.root_dir, 'test')\n",
        "        self.map_list = os.listdir(self.map_dir)\n",
        "        self.map_number = np.size(self.map_list)\n",
        "        if self.mode and do_shuffle:\n",
        "            shuffle(self.map_list)\n",
        "        if index_map is None:\n",
        "            index_map = random.choice(range(len(self.map_list)))\n",
        "        self.li_map = index_map\n",
        "        self.global_map, self.robot_position = self.map_setup(\n",
        "            self.map_dir + '/' + self.map_list[self.li_map])\n",
        "        self.op_map = np.ones(self.global_map.shape) * 127\n",
        "        self.map_size = np.shape(self.global_map)\n",
        "        self.finish_percent = 0.985\n",
        "        self.resolution = 1\n",
        "        self.sensor_range = 80\n",
        "        self.old_position = np.zeros([2])\n",
        "        self.old_op_map = np.empty([0])\n",
        "        #current_dir = os.path.dirname(os.path.realpath(__file__))\n",
        "        self.t = self.map_points(self.global_map)\n",
        "        self.free_tree = spatial.KDTree(\n",
        "            self.free_points(self.global_map).tolist())\n",
        "        self.robot_size = 6\n",
        "        self.local_size = 40\n",
        "        if self.plot:\n",
        "            self.xPoint = np.array([self.robot_position[0]])\n",
        "            self.yPoint = np.array([self.robot_position[1]])\n",
        "            self.x2frontier = np.empty([0])\n",
        "            self.y2frontier = np.empty([0])\n",
        "\n",
        "\n",
        "        return self.begin(), self.robot_position\n",
        "\n",
        "    def begin(self):\n",
        "        self.op_map = self.inverse_sensor(self.robot_position,\n",
        "                                          self.sensor_range, self.op_map,\n",
        "                                          self.global_map)\n",
        "        step_map = self.robot_model(self.robot_position, self.robot_size,\n",
        "                                    self.t, self.op_map)\n",
        "        map_local = self.local_map(self.robot_position, step_map,\n",
        "                                   self.map_size,\n",
        "                                   self.sensor_range + self.local_size)\n",
        "        if self.plot:\n",
        "            self.plot_env()\n",
        "        return self.op_map\n",
        "\n",
        "    def step(self, action_index):\n",
        "        terminal = False\n",
        "        complete = False\n",
        "        new_location = False\n",
        "        all_map = False\n",
        "        self.old_position = self.robot_position.copy()\n",
        "        self.old_op_map = self.op_map.copy()\n",
        "\n",
        "        # take action\n",
        "        self.take_action(action_index, self.robot_position)\n",
        "\n",
        "        # collision check\n",
        "        collision_points, collision_index = self.collision_check(\n",
        "            self.old_position, self.robot_position, self.map_size,\n",
        "            self.global_map)\n",
        "\n",
        "        if collision_index:\n",
        "            self.robot_position = self.nearest_free(self.free_tree,\n",
        "                                                    collision_points)\n",
        "            self.op_map = self.inverse_sensor(self.robot_position,\n",
        "                                              self.sensor_range, self.op_map,\n",
        "                                              self.global_map)\n",
        "            step_map = self.robot_model(self.robot_position, self.robot_size,\n",
        "                                        self.t, self.op_map)\n",
        "        else:\n",
        "            self.op_map = self.inverse_sensor(self.robot_position,\n",
        "                                              self.sensor_range, self.op_map,\n",
        "                                              self.global_map)\n",
        "            step_map = self.robot_model(self.robot_position, self.robot_size,\n",
        "                                        self.t, self.op_map)\n",
        "\n",
        "        map_local = self.local_map(self.robot_position, step_map,\n",
        "                                   self.map_size,\n",
        "                                   self.sensor_range + self.local_size)\n",
        "        reward = self.reward_function.get_reward(self.robot_position,\n",
        "                                                 self.old_op_map, self.op_map,\n",
        "                                                 collision_index)\n",
        "\n",
        "        if reward <= 0.02 and not collision_index:\n",
        "            reward = -0.8\n",
        "            new_location = True\n",
        "            #terminal = True\n",
        "\n",
        "        # during training, the robot is relocated if it has a collision\n",
        "        # during testing, the robot will use collision check to avoid the collision\n",
        "        if collision_index:\n",
        "            if not self.mode:\n",
        "                new_location = False\n",
        "                terminal = False\n",
        "            else:\n",
        "                new_location = True\n",
        "                terminal = True\n",
        "            if self.plot and self.mode:\n",
        "                self.xPoint = ma.append(self.xPoint, self.robot_position[0])\n",
        "                self.yPoint = ma.append(self.yPoint, self.robot_position[1])\n",
        "                self.plot_env()\n",
        "            self.robot_position = self.old_position.copy()\n",
        "            self.op_map = self.old_op_map.copy()\n",
        "            if self.plot and self.mode:\n",
        "                self.xPoint[self.xPoint.size - 1] = ma.masked\n",
        "                self.yPoint[self.yPoint.size - 1] = ma.masked\n",
        "        else:\n",
        "            if self.plot:\n",
        "                self.xPoint = ma.append(self.xPoint, self.robot_position[0])\n",
        "                self.yPoint = ma.append(self.yPoint, self.robot_position[1])\n",
        "                self.plot_env()\n",
        "\n",
        "        # check if exploration is finished\n",
        "        if np.size(np.where(self.op_map == 255)) / np.size(\n",
        "                np.where(self.global_map == 255)) > self.finish_percent:\n",
        "            self.li_map += 1\n",
        "            if self.li_map == self.map_number:\n",
        "                self.li_map = 0\n",
        "                all_map = True\n",
        "            #self.__init__(self.li_map, self.mode, self.plot)\n",
        "            complete = True\n",
        "            new_location = False\n",
        "            terminal = True\n",
        "\n",
        "        return (\n",
        "            self.op_map, self.robot_position\n",
        "        ), reward, terminal, complete, new_location, collision_index, all_map\n",
        "\n",
        "    def rescuer(self):\n",
        "        complete = False\n",
        "        all_map = False\n",
        "        pre_position = self.robot_position.copy()\n",
        "        robot_position = self.frontier(self.op_map, self.map_size, self.t).astype(np.int16)\n",
        "        op_map = self.inverse_sensor(robot_position,\n",
        "                                          self.sensor_range, self.op_map,\n",
        "                                          self.global_map)\n",
        "\n",
        "        path = self.astar_path(self.op_map, pre_position.tolist(),\n",
        "                                   robot_position.tolist())\n",
        "        #if self.plot:\n",
        "        #  self.plot_env()\n",
        "        #  self.x2frontier = ma.append(self.x2frontier, ma.masked)\n",
        "        #  self.y2frontier = ma.append(self.y2frontier, ma.masked)\n",
        "        #  self.x2frontier = ma.append(self.x2frontier, path[1, :])\n",
        "        #  self.y2frontier = ma.append(self.y2frontier, path[0, :])\n",
        "        #  self.xPoint = ma.append(self.xPoint, ma.masked)\n",
        "        #  self.yPoint = ma.append(self.yPoint, ma.masked)\n",
        "        #  self.xPoint = ma.append(self.xPoint, self.robot_position[0])\n",
        "        #  self.yPoint = ma.append(self.yPoint, self.robot_position[1])\n",
        "\n",
        "        return op_map, path\n",
        "\n",
        "    def take_action(self, action_index, robot_position):\n",
        "        move_action = self.action_space.get_action(action_index,\n",
        "                                                   robot_position)\n",
        "\n",
        "        robot_position[0] = np.round(robot_position[0] + move_action[0])\n",
        "        robot_position[1] = np.round(robot_position[1] + move_action[1])\n",
        "\n",
        "    def map_setup(self, location):\n",
        "        global_map = (io.imread(location, 1) * 255).astype(int)\n",
        "        robot_location = np.nonzero(global_map == 208)\n",
        "        robot_location = np.array([\n",
        "            np.array(robot_location)[1, 127],\n",
        "            np.array(robot_location)[0, 127]\n",
        "        ])\n",
        "        global_map = (global_map > 150)\n",
        "        global_map = global_map * 254 + 1\n",
        "        return global_map, robot_location\n",
        "\n",
        "    def map_points(self, map_glo):\n",
        "        map_x = map_glo.shape[1]\n",
        "        map_y = map_glo.shape[0]\n",
        "        x = np.linspace(0, map_x - 1, map_x)\n",
        "        y = np.linspace(0, map_y - 1, map_y)\n",
        "        t1, t2 = np.meshgrid(x, y)\n",
        "        points = np.vstack([t1.T.ravel(), t2.T.ravel()]).T\n",
        "        return points\n",
        "\n",
        "    def local_map(self, robot_location, map_glo, map_size, local_size):\n",
        "        minX = robot_location[0] - local_size\n",
        "        maxX = robot_location[0] + local_size\n",
        "        minY = robot_location[1] - local_size\n",
        "        maxY = robot_location[1] + local_size\n",
        "\n",
        "        if minX < 0:\n",
        "            maxX = abs(minX) + maxX\n",
        "            minX = 0\n",
        "        if maxX > map_size[1]:\n",
        "            minX = minX - (maxX - map_size[1])\n",
        "            maxX = map_size[1]\n",
        "        if minY < 0:\n",
        "            maxY = abs(minY) + maxY\n",
        "            minY = 0\n",
        "        if maxY > map_size[0]:\n",
        "            minY = minY - (maxY - map_size[0])\n",
        "            maxY = map_size[0]\n",
        "\n",
        "        map_loc = map_glo[minY:maxY][:, minX:maxX]\n",
        "        return map_loc\n",
        "\n",
        "    def free_points(self, op_map):\n",
        "        index = np.where(op_map == 255)\n",
        "        free = np.asarray([index[1], index[0]]).T\n",
        "        return free\n",
        "\n",
        "    def nearest_free(self, tree, point):\n",
        "        pts = np.atleast_2d(point)\n",
        "        index = tuple(tree.query(pts)[1])\n",
        "        nearest = tree.data[index]\n",
        "        return nearest\n",
        "\n",
        "    def robot_model(self, position, robot_size, points, map_glo):\n",
        "        map_copy = map_glo.copy()\n",
        "        robot_points = self.range_search(position, robot_size, points)\n",
        "        for i in range(0, robot_points.shape[0]):\n",
        "            rob_loc = np.int32(robot_points[i, :])\n",
        "            rob_loc = np.flipud(rob_loc)\n",
        "            map_copy[tuple(rob_loc)] = 76\n",
        "        map_with_robot = map_copy\n",
        "        return map_with_robot\n",
        "\n",
        "    def range_search(self, position, r, points):\n",
        "        nvar = position.shape[0]\n",
        "        r2 = r**2\n",
        "        s = 0\n",
        "        for d in range(0, nvar):\n",
        "            s += (points[:, d] - position[d])**2\n",
        "        idx = np.nonzero(s <= r2)\n",
        "        idx = np.asarray(idx).ravel()\n",
        "        inrange_points = points[idx, :]\n",
        "        return inrange_points\n",
        "\n",
        "    def collision_check(self, start_point, end_point, map_size, map_glo):\n",
        "        x0, y0 = start_point.round()\n",
        "        x1, y1 = end_point.round()\n",
        "        dx, dy = abs(x1 - x0), abs(y1 - y0)\n",
        "        x, y = x0, y0\n",
        "        error = dx - dy\n",
        "        x_inc = 1 if x1 > x0 else -1\n",
        "        y_inc = 1 if y1 > y0 else -1\n",
        "        dx *= 2\n",
        "        dy *= 2\n",
        "\n",
        "        coll_points = np.ones((1, 2), np.uint8) * -1\n",
        "\n",
        "        while 0 <= x < map_size[1] and 0 <= y < map_size[0]:\n",
        "            k = map_glo.item(y, x)\n",
        "            if k == 1:\n",
        "                coll_points.itemset((0, 0), x)\n",
        "                coll_points.itemset((0, 1), y)\n",
        "                break\n",
        "\n",
        "            if x == end_point[0] and y == end_point[1]:\n",
        "                break\n",
        "\n",
        "            if error > 0:\n",
        "                x += x_inc\n",
        "                error -= dy\n",
        "            else:\n",
        "                y += y_inc\n",
        "                error += dx\n",
        "        if np.sum(coll_points) == -2:\n",
        "            coll_index = False\n",
        "        else:\n",
        "            coll_index = True\n",
        "\n",
        "        return coll_points, coll_index\n",
        "\n",
        "    def inverse_sensor(self, robot_position, sensor_range, op_map, map_glo):\n",
        "        op_map = inverse_sensor_model(robot_position[0], robot_position[1],\n",
        "                                      sensor_range, op_map, map_glo)\n",
        "        return op_map\n",
        "\n",
        "    def frontier(self, op_map, map_size, points):\n",
        "        y_len = map_size[0]\n",
        "        x_len = map_size[1]\n",
        "        mapping = op_map.copy()\n",
        "        # 0-1 unknown area map\n",
        "        mapping = (mapping == 127) * 1\n",
        "        mapping = np.lib.pad(mapping, ((1, 1), (1, 1)),\n",
        "                             'constant',\n",
        "                             constant_values=0)\n",
        "        fro_map = mapping[2:][:, 1:x_len + 1] + mapping[:y_len][:, 1:x_len + 1] + mapping[1:y_len + 1][:, 2:] + \\\n",
        "                  mapping[1:y_len + 1][:, :x_len] + mapping[:y_len][:, 2:] + mapping[2:][:, :x_len] + mapping[2:][:,\n",
        "                                                                                                      2:] + \\\n",
        "                  mapping[:y_len][:, :x_len]\n",
        "        ind_free = np.where(op_map.ravel(order='F') == 255)[0]\n",
        "        ind_fron_1 = np.where(1 < fro_map.ravel(order='F'))[0]\n",
        "        ind_fron_2 = np.where(fro_map.ravel(order='F') < 8)[0]\n",
        "        ind_fron = np.intersect1d(ind_fron_1, ind_fron_2)\n",
        "        ind_to = np.intersect1d(ind_free, ind_fron)\n",
        "        f = points[ind_to]\n",
        "        f = f.astype(int)\n",
        "        return f[0]\n",
        "\n",
        "    def unique_rows(self, a):\n",
        "        a = np.ascontiguousarray(a)\n",
        "        unique_a = np.unique(a.view([('', a.dtype)] * a.shape[1]))\n",
        "        result = unique_a.view(a.dtype).reshape(\n",
        "            (unique_a.shape[0], a.shape[1]))\n",
        "        result = result[~np.isnan(result).any(axis=1)]\n",
        "        return result\n",
        "\n",
        "    def astar_path(self, weights, start, goal, allow_diagonal=True):\n",
        "        temp_start = [start[1], start[0]]\n",
        "        temp_goal = [goal[1], goal[0]]\n",
        "        temp_weight = (weights < 150) * 254 + 1\n",
        "        # For the heuristic to be valid, each move must cost at least 1.\n",
        "        if temp_weight.min(axis=None) < 1.:\n",
        "            raise ValueError(\"Minimum cost to move must be 1, but got %f\" %\n",
        "                             (temp_weight.min(axis=None)))\n",
        "        # Ensure start is within bounds.\n",
        "        if (temp_start[0] < 0 or temp_start[0] >= temp_weight.shape[0]\n",
        "                or temp_start[1] < 0 or temp_start[1] >= temp_weight.shape[1]):\n",
        "            raise ValueError(\"Start lies outside grid.\")\n",
        "        # Ensure goal is within bounds.\n",
        "        if (temp_goal[0] < 0 or temp_goal[0] >= temp_weight.shape[0]\n",
        "                or temp_goal[1] < 0 or temp_goal[1] >= temp_weight.shape[1]):\n",
        "            raise ValueError(\"Goal of lies outside grid.\")\n",
        "\n",
        "        height, width = temp_weight.shape\n",
        "        start_idx = np.ravel_multi_index(temp_start, (height, width))\n",
        "        goal_idx = np.ravel_multi_index(temp_goal, (height, width))\n",
        "\n",
        "        path = astar(\n",
        "            temp_weight.flatten(),\n",
        "            height,\n",
        "            width,\n",
        "            start_idx,\n",
        "            goal_idx,\n",
        "            allow_diagonal,\n",
        "        )\n",
        "        return path\n",
        "\n",
        "    def plot_env(self):\n",
        "        plt.cla()\n",
        "        plt.imshow(self.op_map, cmap='gray')\n",
        "        plt.axis((0, self.map_size[1], self.map_size[0], 0))\n",
        "        plt.plot(self.xPoint, self.yPoint, 'b', linewidth=2)\n",
        "        plt.plot(self.x2frontier, self.y2frontier, 'r', linewidth=2)\n",
        "        plt.plot(self.robot_position[0],\n",
        "                 self.robot_position[1],\n",
        "                 'mo',\n",
        "                 markersize=8)\n",
        "        plt.plot(self.xPoint[0], self.yPoint[0], 'co', markersize=8)\n",
        "        plt.pause(0.05)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edUqbZxCxIKW",
        "outputId": "7a9ef707-0c1b-47b9-e98a-0bd91e5efe25"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "np.random.seed(1000)\n",
        "random.seed(10)\n",
        "\n",
        "reward_func = PaperRewardFunction()\n",
        "action_space = PolarActionSpace(30, 60)\n",
        "\n",
        "robot = Robot(0, True, False, 'DRL_robot_exploration/DungeonMaps',action_space,reward_func, False)\n",
        "\n",
        "test_action = np.array([0.75, 0.5])\n",
        "print('start')\n",
        "print(robot.robot_position)\n",
        "\n",
        "for i in range(10):\n",
        "  (map, loc), reward, terminal, complete, new_loc, collision, all_map = robot.step(test_action)\n",
        "  print('reward', reward)\n",
        "  print('robot loc', loc)\n",
        "  print(collision)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start\n",
            "[111 327]\n",
            "reward 0.06842857142857142\n",
            "robot loc [ 66 327]\n",
            "False\n",
            "reward -1\n",
            "robot loc [ 66 327]\n",
            "True\n",
            "reward -1\n",
            "robot loc [ 66 327]\n",
            "True\n",
            "reward -1\n",
            "robot loc [ 66 327]\n",
            "True\n",
            "reward -1\n",
            "robot loc [ 66 327]\n",
            "True\n",
            "reward -1\n",
            "robot loc [ 66 327]\n",
            "True\n",
            "reward -1\n",
            "robot loc [ 66 327]\n",
            "True\n",
            "reward -1\n",
            "robot loc [ 66 327]\n",
            "True\n",
            "reward -1\n",
            "robot loc [ 66 327]\n",
            "True\n",
            "reward -1\n",
            "robot loc [ 66 327]\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO_EJKEoNC6T"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchsummary\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
        "\n",
        "def build_conv_feature_extractor(conv_dims, act):\n",
        "  #Create Conv2D + MaxPool layers\n",
        "  conv_layers = [nn.Conv2d(*conv_dim) if len(conv_dim) == 3 else nn.MaxPool2d(conv_dim) for conv_dim in conv_dims]\n",
        "  total_layers = []\n",
        "\n",
        "  #Add ReLU activations after each conv layer\n",
        "  for i, layer in enumerate(conv_layers):\n",
        "    total_layers.append(layer)\n",
        "    if type(layer) == nn.Conv2d:\n",
        "      total_layers.append(act())\n",
        "      total_layers.append(nn.BatchNorm2d(conv_dims[i][1]))\n",
        "  return nn.Sequential(*total_layers)\n",
        "  \n",
        "\n",
        "def get_output_shape(model, image_dim):\n",
        "    return model(torch.rand(*(image_dim))).data.shape\n",
        "\n",
        "class RNNActor(nn.Module):\n",
        "  #TODO Determine if the action space allows negative numbers\n",
        "  #Potentially replace tanh with sigmoid\n",
        "  def __init__(self, conv_dims, lstm_hidden, train_length, input_size=(1, 1,84,84), act=nn.ReLU, final_act=nn.Sigmoid):\n",
        "    super(RNNActor, self).__init__()\n",
        "\n",
        "    self.conv_mod = build_conv_feature_extractor(conv_dims, act)\n",
        "    \n",
        "    #Silly way to determine the size going into the RNN\n",
        "    with torch.no_grad():\n",
        "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
        "\n",
        "    print('LSTM Input Size', feature_size)\n",
        "\n",
        "    #Construct LSTM\n",
        "    self.lstm_hidden = lstm_hidden\n",
        "    self.lstm_input = np.prod(list(feature_size)) + 2\n",
        "    self.lstm = nn.LSTM(self.lstm_input, lstm_hidden)\n",
        "    self.linear = nn.Linear(lstm_hidden, 2)\n",
        "    self.train_length = train_length\n",
        "    self.final_act = final_act()\n",
        "\n",
        "  def forward(self, image, positions, lengths, hidden_state=None):\n",
        "    batch_size = image.size()[1]\n",
        "    seq_length = image.size()[0]\n",
        "    conv = self.conv_mod(image.view((seq_length * batch_size, 1, 84, 84)))\n",
        "\n",
        "    flat = conv.view(-1).view(seq_length, batch_size, self.lstm_input - 2)\n",
        "    state = torch.cat((flat, positions), 2)\n",
        "    packed = pack_padded_sequence(state, lengths, enforce_sorted=False)\n",
        "    self.lstm.flatten_parameters()\n",
        "    if hidden_state is not None:\n",
        "      states, final_state = self.lstm(packed, hidden_state)\n",
        "    else:\n",
        "      states, final_state = self.lstm(packed)\n",
        "\n",
        "    unpacked, end_lengths = pad_packed_sequence(states)\n",
        "    final = self.linear(unpacked)\n",
        "    return self.final_act(final), final_state, end_lengths"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgxUtoeMJ8Pa"
      },
      "source": [
        "def build_dense_regression(linear_dims, act, final_act=None):\n",
        "  linear_layers = [nn.Linear(*linear_dim)  for linear_dim in linear_dims]\n",
        "  activations = [act() for layer in range(len(linear_layers) - 1)]\n",
        "  #batch_norm = [nn.BatchNorm1d() for layer in range(len(linear_layers) - 1)]\n",
        "  #batch_norm.append(nn.Identity())\n",
        "  if final_act is not None:\n",
        "    activations.append(final_act())\n",
        "  else:\n",
        "    activations.append(nn.Identity())\n",
        "  return nn.Sequential(*[val for tup in zip(*[linear_layers, activations]) for val in tup]\n",
        ")\n",
        "\n",
        "class CNNCritic(nn.Module):\n",
        "  def __init__(self, conv_dims, fc_dims, input_size=(1, 1,84,84), conv_act=nn.ReLU, fc_act=nn.ReLU):\n",
        "    super(CNNCritic, self).__init__()\n",
        "    self.conv_mod = build_conv_feature_extractor(conv_dims, conv_act)\n",
        "\n",
        "    #Silly way to determine the size going into the RNN\n",
        "    with torch.no_grad():\n",
        "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
        "\n",
        "    #Add 4 for action + position\n",
        "    feature_size = np.prod(list(feature_size)) + 4\n",
        "    first_output = fc_dims[0][0]\n",
        "    fc_dims.insert(0, (feature_size, first_output))\n",
        "\n",
        "    self.fc = build_dense_regression(fc_dims, fc_act)\n",
        "    self.fc_dims = feature_size\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self, map, positions, action):\n",
        "    batch_size = map.size()[1]\n",
        "    seq_length =  map.size()[0]\n",
        "    conv = self.conv_mod(map.view((seq_length * batch_size, 1, 84, 84)))\n",
        "\n",
        "    flat = conv.view(-1).view(seq_length, batch_size, self.fc_dims - 4)\n",
        "    total_feats = torch.cat((flat, positions, action), 2)\n",
        "    return self.fc(total_feats)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjDpPhJi8gvh"
      },
      "source": [
        "class ActorPolicy:\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "\n",
        "  def __call__(self, map, position, env):\n",
        "    map = map.to(device='cuda').float().unsqueeze(0).unsqueeze(1)\n",
        "    position = position.to(device='cuda').float().unsqueeze(0)\n",
        "\n",
        "    result = self.model(map, position)\n",
        "\n",
        "    return [result.cpu().squeeze(0)]\n",
        "\n",
        "class CNNCriticNoSeq(nn.Module):\n",
        "  def __init__(self, conv_dims, fc_dims, input_size=(1, 1,84,84), conv_act=nn.LeakyReLU, fc_act=nn.LeakyReLU):\n",
        "    super(CNNCriticNoSeq, self).__init__()\n",
        "    self.conv_mod = build_conv_feature_extractor(conv_dims, conv_act)\n",
        "\n",
        "    #Silly way to determine the size going into the RNN\n",
        "    with torch.no_grad():\n",
        "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
        "\n",
        "    #Add 4 for action + position\n",
        "    feature_size = np.prod(list(feature_size)) + 4\n",
        "    first_output = fc_dims[0][0]\n",
        "    fc_dims.insert(0, (feature_size, first_output))\n",
        "\n",
        "    self.fc = nn.Linear(feature_size, int(feature_size/2))#build_dense_regression(fc_dims, fc_act)\n",
        "    self.fc_dims = feature_size\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "    self.fc2 = nn.Linear(int(feature_size/2),1)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self, map, positions, action):\n",
        "    conv = self.conv_mod(map)\n",
        "    batch_size = map.size()[0]\n",
        "    flat = conv.view(batch_size, self.fc_dims - 4)\n",
        "#     print('flat', flat.size())\n",
        "#     print('positions', positions.size())\n",
        "    total_feats = torch.cat((flat, positions, action), 1)\n",
        "    return self.fc2(self.dropout(self.fc(total_feats)))\n",
        "\n",
        "\n",
        "\n",
        "class FCActor(nn.Module):\n",
        "  #TODO Determine if the action space allows negative numbers\n",
        "  #Potentially replace tanh with sigmoid\n",
        "  def __init__(self, conv_dims, linear_dims, input_size=(1, 1,84,84), act=nn.LeakyReLU, final_act=nn.Sigmoid):\n",
        "    super(FCActor, self).__init__()\n",
        "    self.conv_mod = build_conv_feature_extractor(conv_dims, act)\n",
        "\n",
        "    #Silly way to determine the size going into the RNN\n",
        "    with torch.no_grad():\n",
        "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
        "\n",
        "    #Add 4 for action + position\n",
        "    feature_size = np.prod(list(feature_size)) + 2\n",
        "    first_output = linear_dims[0][0]\n",
        "    linear_dims.insert(0, (feature_size, first_output))\n",
        "\n",
        "    self.fc = nn.Linear(feature_size, int(feature_size/2))#build_dense_regression(linear_dims, act, final_act)\n",
        "    self.fc_dims = feature_size\n",
        "    self.dropout = nn.Dropout(p=0.2)\n",
        "    self.fc2 = nn.Linear(int(feature_size/2),2)\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, map, positions):\n",
        "    conv = self.conv_mod(map)\n",
        "\n",
        "    flat = conv.view(map.size()[0], self.fc_dims - 2)\n",
        "#     print('flat', flat.size())\n",
        "#     print('positions', positions.size())\n",
        "    total_feats = torch.cat((flat, positions), 1)\n",
        "    return self.sig(self.fc2(self.dropout(self.fc(total_feats))))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-eCOZDBC3pg",
        "outputId": "4a61b145-e5ce-467d-e57c-cc4981d5d973"
      },
      "source": [
        "\"\"\" Learn a policy using DDPG for the reach task\"\"\"\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import MultivariateNormal\n",
        "from torch.nn import MSELoss\n",
        "import random\n",
        "from skimage.transform import resize\n",
        "from io import BytesIO\n",
        "import itertools\n",
        "import lmdb\n",
        "from itertools import zip_longest\n",
        "\n",
        "import gym\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import time\n",
        "if not laptop:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "def save_models(actor, critic1, critic2, actor_target, critic1_target, critic2_target, i):\n",
        "   torch.save(actor.state_dict(), '/content/drive/My Drive/models/actor_{}.pt'.format(i))\n",
        "   torch.save(critic1.state_dict(), '/content/drive/My Drive/models/critic1_{}.pt'.format(i))\n",
        "   torch.save(critic2.state_dict(), '/content/drive/My Drive/models/critic2_{}.pt'.format(i))\n",
        "   torch.save(critic1_target.state_dict(), '/content/drive/My Drive/models/critic1_target_{}.pt'.format(i))\n",
        "   torch.save(critic2_target.state_dict(), '/content/drive/My Drive/models/critic2_target_{}.pt'.format(i))\n",
        "   torch.save(actor_target.state_dict(), '/content/drive/My Drive/models/actor_target_{}.pt'.format(i))\n",
        "  \n",
        "\n",
        "# TODO: A function to soft update target networks\n",
        "def weighSync(target_model, source_model, tau=0.001):\n",
        "  for (target, src) in zip(target_model.parameters(), source_model.parameters()):\n",
        "    target.data = (1-tau) * target.data + tau * src.data \n",
        "\n",
        "def grouper(iterable, n, fillvalue=None):\n",
        "  '''Collect data into fixed-length chunks or blocks'''\n",
        "  # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
        "  args = [iter(iterable)] * n\n",
        "  return zip_longest(*args, fillvalue=fillvalue)\n",
        "\n",
        "# TODO: Write the ReplayBuffer\n",
        "class Replay():\n",
        "    def __init__(self, buffer_size, init_sequences, max_episode_length, sequence_length, action_dim, env, test_env, env_width, env_height):\n",
        "        \"\"\"\n",
        "        A function to initialize the replay buffer.\n",
        "\n",
        "        param: init_length : Initial number of transitions to collect\n",
        "        param: state_dim : Size of the state space\n",
        "        param: action_dim : Size of the action space\n",
        "        param: env : gym environment object\n",
        "        \"\"\"\n",
        "        try:\n",
        "          os.remove('db.lmdb')\n",
        "        except OSError:\n",
        "          print('cant remove')\n",
        "          pass\n",
        "        shutil.copytree('/content/drive/My Drive/data.lmdb', 'db.lmdb')\n",
        "        self.db = lmdb.open('db.lmdb', map_size=30e9)\n",
        "        self.buffer = [{}] * buffer_size\n",
        "        self.noise = MultivariateNormal(torch.zeros(2), torch.diag(torch.tensor([0.1, 0.1])))\n",
        "        self.sequence_length = sequence_length\n",
        "        self.max_episode_length = max_episode_length\n",
        "        self.env = env\n",
        "        self.test_env = test_env\n",
        "        state = self.env.reset()\n",
        "        self.buffer_length = buffer_size\n",
        "        self.env_width = env_width\n",
        "        self.env_height = env_height\n",
        "        self.buffer_idx = 0\n",
        "        self.total_steps = 0\n",
        "        last_state = env.reset()\n",
        "        init_policy = GuidedExplorationPolicy(0.5, None, action_space, 0.2)\n",
        "        self.full_buffer = False\n",
        "        self.current_pointer = 0\n",
        "\n",
        "        map, position = self.env.reset()\n",
        "        map = np.pad(map, ((map.shape[0], map.shape[1]), (map.shape[0], map.shape[1])), constant_values=127)\n",
        "        #idx = (int(map.shape[0] / 2), int(position[1] - map.shape[1] / 2))\n",
        "        #map = np.roll(map, idx, [0, 1])\n",
        "        map = resize(map, (84, 84))\n",
        "        map = map / 255\n",
        "        position = position.astype(np.float64)\n",
        "        position[0] = position[0] / 480\n",
        "        position[1] = position[1] / 640\n",
        "        action = {'map':torch.from_numpy(map).float(), 'position':torch.from_numpy(position).float()}\n",
        "        \n",
        "        while self.buffer_idx < init_sequences:\n",
        "          action, terminal = self.generate_step(init_policy, action, False)\n",
        "#           print('action', action)\n",
        "#           print('terminal', terminal)\n",
        "          if terminal:\n",
        "           map, position = self.env.reset()\n",
        "\n",
        "           map = resize(map, (84, 84))\n",
        "           map = map / 255\n",
        "           position = position.astype(np.float64)\n",
        "           position[0] = position[0] / 480\n",
        "           position[1] = position[1] / 640\n",
        "           action = {'map':torch.from_numpy(map).float(), 'position':torch.from_numpy(position).float()}\n",
        "\n",
        "\n",
        "    def generate_step(self, policy, last_transition, add_noise=True, store=True, test=False):\n",
        "      if test:\n",
        "        env = self.test_env\n",
        "      else:\n",
        "        env = self.env\n",
        "      episode = []\n",
        "      last_map = last_transition['map']\n",
        "      last_position = last_transition['position']\n",
        "\n",
        "      terminal = False\n",
        "\n",
        "      total_reward = 0\n",
        "\n",
        "      actions = policy(last_map, last_position, env)\n",
        "      last_act = None\n",
        "      if len(actions) == 0:\n",
        "        terminal = True\n",
        "      for action in actions:\n",
        "        if add_noise:\n",
        "          sampled = self.noise.sample()\n",
        "          #print('adding noise', sampled)\n",
        "          action = action.cpu() + sampled\n",
        "        else:\n",
        "          action = action.cpu()\n",
        "\n",
        "        action_np = action.detach().numpy().flatten()\n",
        "        #print('action_np', action_np)\n",
        "        #if action_np[0] < 0:\n",
        "        #  action_np[0] = abs(action_np[0])\n",
        "        #elif action_np[0] > 1:\n",
        "        #  action_np[0] = action_np[0] - 1\n",
        "\n",
        "        #if action_np[1] < 0:\n",
        "        #  action_np[1] = abs(action_np[1])\n",
        "        #elif action_np[1] > 1:\n",
        "        #  action_np[1] = action_np[1] - 1\n",
        "\n",
        "    \n",
        "\n",
        "        (map, loc), reward, terminal, complete, new_loc, collision, all_map = env.step(action_np)\n",
        "        #map = np.pad(map, ((map.shape[0], map.shape[1]), (map.shape[0], map.shape[1])), constant_values=127)\n",
        "        #idx = (int(map.shape[0] / 2 - loc[0]), int(map.shape[1] / 2 - loc[1]))\n",
        "        #map = np.roll(map, idx, axis=[0, 1])\n",
        "\n",
        "        #print('shifted', idx)\n",
        "        #plt.imshow(map)\n",
        "        #plt.show()\n",
        "        map = resize(map, (84, 84))\n",
        "        map = (map / 255)\n",
        "        loc = loc.astype(np.float64)\n",
        "        loc[0] = loc[0] / 480.0\n",
        "        loc[1] = loc[1] / 640.0\n",
        "\n",
        "        map_tensor = torch.from_numpy(map).float()\n",
        "        position_tensor = torch.from_numpy(loc).float()\n",
        "        reward_tensor = torch.tensor(reward).float()\n",
        "        action = {'last_map':last_map, 'last_position':last_position, 'map': map_tensor.detach(), 'position': position_tensor.detach(), 'reward': reward_tensor.unsqueeze(0).detach(), 'action': action.detach()}\n",
        "        last_act = action\n",
        "        total_reward += reward\n",
        "\n",
        "        if store:\n",
        "          self.write_one_transition(action, self.buffer_idx)\n",
        "          self.buffer_idx = (self.buffer_idx + 1) % len(self.buffer)\n",
        "          if self.buffer_idx == 0:\n",
        "            self.full_buffer = True\n",
        "\n",
        "      return last_act, terminal\n",
        "\n",
        "    def write_one_transition(self, trans, idx):\n",
        "      actions = trans['action']\n",
        "      rewards = trans['reward']\n",
        "      maps = trans['map']\n",
        "      positions = trans['position']\n",
        "\n",
        "      last_map = trans['last_map']\n",
        "      last_position = trans['last_position']\n",
        "\n",
        "#       print('actions', actions.size())\n",
        "#       print('rewards', rewards.size())\n",
        "#       print('maps', maps.size())\n",
        "#       print('positions', positions.size())\n",
        "#       print('last_map', last_map.size())\n",
        "#       print('last_position', last_position.size())\n",
        "\n",
        "      total_tensor = torch.cat((actions, rewards, positions, last_position), 0)\n",
        "      total_maps = torch.cat((maps, last_map), 0)\n",
        "      with self.db.begin(write=True) as txn:\n",
        "        total_bytes = BytesIO()\n",
        "        maps_bytes = BytesIO()\n",
        "\n",
        "        torch.save(total_tensor, total_bytes)\n",
        "        torch.save(total_maps, maps_bytes)\n",
        "        \n",
        "        txn.put('{}_total'.format(idx).encode(), total_bytes.getvalue())\n",
        "        txn.put('{}_maps'.format(idx).encode(), maps_bytes.getvalue())\n",
        "\n",
        "    def sample_transitions(self, N):\n",
        "      \"\"\"\n",
        "      A function to sample N points from the buffer\n",
        "      param: N : Number of samples to obtain from the buffer\n",
        "      \"\"\"\n",
        "      if self.full_buffer:\n",
        "        samples = np.random.permutation(range(self.buffer_length))\n",
        "      else:\n",
        "        samples = np.random.permutation(range(self.buffer_idx))\n",
        "\n",
        "      samples = samples[:N]\n",
        "      return self.read_transitions(samples)\n",
        "\n",
        "    def read_transitions(self, transitions):\n",
        "      maps = []\n",
        "      positions = []\n",
        "      rewards = []\n",
        "      actions = []\n",
        "      last_maps = []\n",
        "      last_positions = []\n",
        "\n",
        "      for seq in transitions:\n",
        "        with self.db.begin() as txn:\n",
        "          total_data = BytesIO(txn.get('{}_total'.format(seq).encode()))\n",
        "          map_data = BytesIO(txn.get('{}_maps'.format(seq).encode()))      \n",
        "\n",
        "          total_tensor = torch.load(total_data)\n",
        "          map_tensor = torch.load(map_data)\n",
        "#           print('map tensor', map_tensor.size())\n",
        "          maps.append(map_tensor[:84, :].unsqueeze(0))\n",
        "          last_maps.append(map_tensor[84:, :].unsqueeze(0))\n",
        "          positions.append(total_tensor[3:5].unsqueeze(0))\n",
        "          actions.append(total_tensor[:2].unsqueeze(0))\n",
        "          rewards.append(total_tensor[2].unsqueeze(0))\n",
        "          last_positions.append(total_tensor[5:].unsqueeze(0))\n",
        "\n",
        "      map_pad = torch.cat(maps, 0).to(device='cuda').float()\n",
        "      pos_pad = torch.cat(positions, 0).to(device='cuda').float()\n",
        "      reward_pad = torch.cat(rewards, 0).to(device='cuda').float()\n",
        "      action_pad = torch.cat(actions, 0).to(device='cuda').float()\n",
        "      last_positions = torch.cat(last_positions, 0).to(device='cuda').float()\n",
        "      last_maps = torch.cat(last_maps, 0).to(device='cuda').float()\n",
        "\n",
        "      return map_pad, pos_pad, reward_pad, action_pad, last_positions, last_maps\n",
        "\n",
        "    def generate_episode(self, policy, add_noise=True, store=True, test=False, plot=False, do_print=False):\n",
        "      episode = []\n",
        "      self.env.plot = plot\n",
        "      map, position = self.env.reset()\n",
        "      position = position.astype(np.float64)\n",
        "      map = resize(map, (84, 84))\n",
        "      map = ((map - 127) / 255) * 2\n",
        "\n",
        "      position[0] = position[0]/ 640.0\n",
        "      position[1] = position[1] / 480.0\n",
        "      last_map = torch.from_numpy(map).float()\n",
        "      last_position = torch.from_numpy(position).float()\n",
        "      terminal = False\n",
        "\n",
        "      total_reward = 0\n",
        "      last_state = None\n",
        "      for i in range(self.max_episode_length):\n",
        "        if last_state is None:\n",
        "          action, last_state, lengths = policy(last_map.unsqueeze(0).unsqueeze(0).to(device='cuda'), last_position.unsqueeze(0).unsqueeze(0).to(device='cuda'), [1])\n",
        "        else:\n",
        "          action, last_state, lengths = policy(last_map.unsqueeze(0).unsqueeze(0).to(device='cuda'), last_position.unsqueeze(0).unsqueeze(0).to(device='cuda'), [1], last_state)\n",
        "      \n",
        "        if add_noise:\n",
        "          sampled = torch.clamp(self.noise.sample(), -0.25, 0.25)\n",
        "          #print('adding noise', sampled)\n",
        "          action = action.cpu().squeeze(0).squeeze(1) + sampled\n",
        "        else:\n",
        "          action = action.cpu().squeeze(0).squeeze(1)\n",
        "\n",
        "        action_np = action.detach().numpy().flatten()\n",
        "        if action_np[0] < 0:\n",
        "          action_np[0] = abs(action_np[0])\n",
        "        elif action_np[0] > 1:\n",
        "          action_np[0] = action_np[0] - 1\n",
        "\n",
        "        if action_np[1] < 0:\n",
        "          action_np[1] = abs(action_np[1])\n",
        "        elif action_np[1] > 1:\n",
        "          action_np[1] = action_np[1] - 1\n",
        "\n",
        "\n",
        "        if do_print:\n",
        "          print('action', action_np)\n",
        "\n",
        "    \n",
        "\n",
        "        (map, loc), reward, terminal, complete, new_loc, collision, all_map = self.env.step(action_np)\n",
        "        map = resize(map, (84, 84))\n",
        "        map = ((map - 127) / 255) * 2\n",
        "        loc = loc.astype(np.float64)\n",
        "        loc[0] = loc[0] / 640.0\n",
        "        loc[1] = loc[1] / 480.0\n",
        "\n",
        "        map_tensor = torch.from_numpy(map).float()\n",
        "        position_tensor = torch.from_numpy(loc).float()\n",
        "        reward_tensor = torch.tensor(reward).float()\n",
        "        episode.append({'map': map_tensor.detach(), 'position': position_tensor.detach(), 'reward': reward_tensor.detach(), 'action': action.detach()})\n",
        "        last_map = map_tensor.to(device='cuda')\n",
        "        last_position = position_tensor.to(device='cuda')\n",
        "        total_reward += reward\n",
        "        if terminal:\n",
        "          break\n",
        "\n",
        "      if store:\n",
        "        sequences = self.episode_to_sequences(episode)\n",
        "        for sequence in sequences:\n",
        "          self.write_sequence(sequence, self.buffer_idx)\n",
        "          self.buffer_idx = (self.buffer_idx + 1) % len(self.buffer)\n",
        "          if self.buffer_idx == 0:\n",
        "            self.full_buffer = True\n",
        "\n",
        "      self.env.plot = False\n",
        "      return total_reward\n",
        "\n",
        "    def write_sequence(self, sequence, idx):\n",
        "      actions = sequence['actions']\n",
        "      rewards = sequence['rewards']\n",
        "      maps = sequence['maps']\n",
        "      positions = sequence['positions']\n",
        "\n",
        "      len = sequence['len']\n",
        "      total_tensor = torch.cat((actions, rewards.unsqueeze(1).unsqueeze(1), positions.unsqueeze(1)), 2)\n",
        "      with self.db.begin(write=True) as txn:\n",
        "        total_bytes = BytesIO()\n",
        "        maps_bytes = BytesIO()\n",
        "\n",
        "        torch.save(total_tensor, total_bytes)\n",
        "        torch.save(maps, maps_bytes)\n",
        "        \n",
        "        txn.put('{}_total'.format(idx).encode(), total_bytes.getvalue())\n",
        "        txn.put('{}_maps'.format(idx).encode(), maps_bytes.getvalue())\n",
        "        txn.put('{}_len'.format(idx).encode(), str(len).encode())\n",
        "\n",
        "    def read_sequences(self, sequences):\n",
        "        map_sequences = []\n",
        "        position_sequences = []\n",
        "        reward_sequences = []\n",
        "        action_sequences = []\n",
        "        seq_lens = []\n",
        "\n",
        "        for seq in sequences:\n",
        "            with self.db.begin() as txn:\n",
        "                total_data = BytesIO(txn.get('{}_total'.format(seq).encode()))\n",
        "                map_data = BytesIO(txn.get('{}_maps'.format(seq).encode()))\n",
        "                length = txn.get('{}_len'.format(seq).encode())\n",
        "\n",
        "\n",
        "                total_tensor = torch.load(total_data)\n",
        "                map_tensor = torch.load(map_data)\n",
        "                map_sequences.append(map_tensor)\n",
        "                position_sequences.append(total_tensor[:, :, 3:])\n",
        "                action_sequences.append(total_tensor[:, :, :2])\n",
        "                reward_sequences.append(total_tensor[:, :, 2])\n",
        "                seq_lens.append(int(length))\n",
        "\n",
        "        map_pad = pad_sequence(map_sequences).to(device='cuda').float()\n",
        "        pos_pad = pad_sequence(position_sequences).to(device='cuda').float()\n",
        "        reward_pad = pad_sequence(reward_sequences).to(device='cuda').float()\n",
        "        action_pad = pad_sequence(action_sequences).to(device='cuda').float()\n",
        "        seqs = seq_lens\n",
        "\n",
        "\n",
        "\n",
        "        return map_pad, pos_pad, reward_pad, action_pad, seqs\n",
        "    \n",
        "    def episode_to_sequences(self, episode):\n",
        "      sequences = []\n",
        "      last_idx = 0\n",
        "      for i in np.arange(self.sequence_length, len(episode), self.sequence_length):\n",
        "        window = episode[last_idx:i]\n",
        "        map_tensor = torch.cat([torch.unsqueeze(data['map'], 0) for data in window], 0)\n",
        "        position_tensor = torch.cat([torch.unsqueeze(data['position'], 0) for data in window], 0)\n",
        "        reward_tensor = torch.cat([torch.unsqueeze(data['reward'], 0) for data in window], 0)\n",
        "        action_tensor = torch.cat([torch.unsqueeze(data['action'], 0) for data in window], 0)\n",
        "        sequences.append({'maps':map_tensor, 'positions': position_tensor, 'rewards': reward_tensor, 'actions':action_tensor, 'len':len(window)})\n",
        "        last_idx = i\n",
        "\n",
        "      window = episode[last_idx:]\n",
        "      map_tensor = torch.cat([torch.unsqueeze(data['map'], 0) for data in window], 0)\n",
        "      position_tensor = torch.cat([torch.unsqueeze(data['position'], 0) for data in window], 0)\n",
        "      reward_tensor = torch.cat([torch.unsqueeze(data['reward'], 0) for data in window], 0)\n",
        "      action_tensor = torch.cat([torch.unsqueeze(data['action'], 0) for data in window], 0)\n",
        "      sequences.append({'maps':map_tensor, 'positions': position_tensor, 'rewards': reward_tensor, 'actions':action_tensor, 'len':len(window)})\n",
        "      return sequences\n",
        "    \n",
        "\n",
        "    #TODO: Complete the function\n",
        "    def buffer_sample(self, N):\n",
        "        \"\"\"\n",
        "        A function to sample N points from the buffer\n",
        "        param: N : Number of samples to obtain from the buffer\n",
        "        \"\"\"\n",
        "        if self.full_buffer:\n",
        "          samples = np.random.permutation(range(self.buffer_length))\n",
        "        else:\n",
        "          samples = np.random.permutation(range(self.buffer_idx))\n",
        "\n",
        "        samples = samples[:N]\n",
        "        return self.read_sequences(samples)\n",
        "\n",
        "    def batchify(self, samples):\n",
        "      \n",
        "      map_sequences = []\n",
        "      position_sequences = []\n",
        "      reward_sequences = []\n",
        "      action_sequences = []\n",
        "      seq_lens = []\n",
        "\n",
        "      for sequence in samples:\n",
        "\n",
        "        map_sequences.append(sequence['maps'])\n",
        "        position_sequences.append(sequence['positions'])\n",
        "        reward_sequences.append(sequence['rewards'])\n",
        "        action_sequences.append(sequence['actions'])\n",
        "        seq_lens.append(sequence['len'])\n",
        "\n",
        "      map_pad = pad_sequence(map_sequences).to(device='cuda').float()\n",
        "      pos_pad = pad_sequence(position_sequences).to(device='cuda').float()\n",
        "      reward_pad = pad_sequence(reward_sequences).to(device='cuda').float()\n",
        "      action_pad = pad_sequence(action_sequences).to(device='cuda').float()\n",
        "      seqs = seq_lens\n",
        "\n",
        "      return map_pad, pos_pad, reward_pad, action_pad, seqs\n",
        "\n",
        "      \n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILCmP0qIanRV"
      },
      "source": [
        "!rm -rf db.lmdb"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFMjDGz1N958"
      },
      "source": [
        "# TODO: Implement a DDPG class\n",
        "def plot_grad_flow(named_parameters):\n",
        "    ave_grads = []\n",
        "    layers = []\n",
        "    for n, p in named_parameters:\n",
        "        if(p.requires_grad) and (\"bias\" not in n):\n",
        "            layers.append(n)\n",
        "            ave_grads.append(p.grad.abs().mean())\n",
        "    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
        "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
        "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
        "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
        "    plt.xlabel(\"Layers\")\n",
        "    plt.ylabel(\"average gradient\")\n",
        "    plt.title(\"Gradient flow\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "import shutil\n",
        "class TD3():\n",
        "    def __init__(\n",
        "            self,\n",
        "            env,\n",
        "            conv_dims,\n",
        "            state_dim,\n",
        "            linear_dims,\n",
        "            actor_linear_dims,\n",
        "            sequence_length,\n",
        "            replay,\n",
        "            critic_lr=3e-4,\n",
        "            actor_lr=3e-4,\n",
        "            gamma=0.99,\n",
        "            batch_size=100,\n",
        "            seed=1000\n",
        "    ):\n",
        "        \"\"\"\n",
        "        param: env: An gym environment\n",
        "        param: action_dim: Size of action space\n",
        "        param: state_dim: Size of state space\n",
        "        param: critic_lr: Learning rate of the critic\n",
        "        param: actor_lr: Learning rate of the actor\n",
        "        param: gamma: The discount factor\n",
        "        param: batch_size: The batch size for training\n",
        "        \"\"\"\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        action_dim = 2\n",
        "        self.gamma = gamma\n",
        "        self.batch_size = batch_size\n",
        "        self.sequence_length = sequence_length\n",
        "        self.env = env\n",
        "        self.state_dim = state_dim\n",
        "        self.actor = FCActor(conv_dims, actor_linear_dims).float().to(device='cuda')\n",
        "        print(self.actor)\n",
        "\n",
        "        # TODO: Create a actor and actor_target\n",
        "        self.actor_target = copy.deepcopy(self.actor)\n",
        "\n",
        "        # TODO: Make sure that both networks have the same initial weights\n",
        "\n",
        "        # TODO: Create a critic and critic_target object\n",
        "        self.critic1 = CNNCriticNoSeq(conv_dims, linear_dims).float().to(device='cuda')\n",
        "        self.critic1_target = copy.deepcopy(self.critic1)\n",
        "        # TODO: Make sure that both networks have the same initial weights\n",
        "\n",
        "        self.critic2 = CNNCriticNoSeq(conv_dims, linear_dims).float().to(device='cuda')\n",
        "        self.critic2_target = copy.deepcopy(self.critic2)\n",
        "        # TODO: Make sure that both networks have the same initial weights\n",
        "\n",
        "        # TODO: Define the optimizer for the actor\n",
        "        self.optimizer_actor = optim.Adam(self.actor.parameters(), actor_lr)\n",
        "        self.lr_sched_actor = optim.lr_scheduler.StepLR(self.optimizer_actor, step_size=100, gamma=0.95)\n",
        "        # TODO: Define the optimizer for the critic\n",
        "        self.optimizer_critic1 = optim.Adam(self.critic1.parameters(), critic_lr)\n",
        "        self.lr_sched_critic1 = optim.lr_scheduler.StepLR(self.optimizer_critic1, step_size=100, gamma=0.95)\n",
        "        \n",
        "        self.optimizer_critic2 = optim.Adam(self.critic2.parameters(), critic_lr)\n",
        "        self.lr_sched_critic2 = optim.lr_scheduler.StepLR(self.optimizer_critic2, step_size=100, gamma=0.95)\n",
        "\n",
        "        # TODO: define a replay buffer\n",
        "        #buffer_size, init_episodes, max_episode_length, state_dim, action_dim, env, env_width, env_height\n",
        "        self.replay = replay\n",
        "\n",
        "    # TODO: Complete the function\n",
        "    def update_target_networks(self):\n",
        "        \"\"\"\n",
        "        A function to update the target networks\n",
        "        \"\"\"\n",
        "        weighSync(self.actor_target, self.actor)\n",
        "        weighSync(self.critic1_target, self.critic1)\n",
        "        weighSync(self.critic2_target, self.critic2)\n",
        "\n",
        "    # TODO: Complete the function\n",
        "    def update_network(self, y_i, maps, positions, actions, last_maps, last_positions, i):\n",
        "        \"\"\"\n",
        "        A function to update the function just once\n",
        "        \"\"\"\n",
        "        \n",
        "        qs1 = self.critic1(last_maps, last_positions, actions)\n",
        "        #print('critic loss sizes')\n",
        "        #print(y_i.size())\n",
        "        #print(qs.size())\n",
        "        #should be (seq_len, batch, 1)\n",
        "        #should be (seq_len, batch, 1)\n",
        "        criterion = nn.MSELoss()\n",
        "        critic1_loss = criterion(qs1, y_i)\n",
        "        #print('critic loss', critic_loss)\n",
        "        critic1_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.critic1.parameters(), 1)\n",
        "        if i % 500 == 0:\n",
        "          print(\"CRITIC\")\n",
        "          plot_grad_flow(self.critic1.named_parameters())\n",
        "\n",
        "        self.optimizer_critic1.step()\n",
        "        self.lr_sched_critic1.step()\n",
        "        \n",
        "        qs2 = self.critic2(last_maps, last_positions, actions)\n",
        "\n",
        "        #print('critic loss sizes')\n",
        "        #print(y_i.size())\n",
        "        #print(qs.size())\n",
        "        #should be (seq_len, batch, 1)\n",
        "        #should be (seq_len, batch, 1)\n",
        "        critic2_loss = criterion(qs2, y_i)\n",
        "        torch.nn.utils.clip_grad_norm_(self.critic2.parameters(), 1)\n",
        "\n",
        "        #print('critic loss', critic_loss)\n",
        "        critic2_loss.backward()\n",
        "        self.optimizer_critic2.step()\n",
        "        self.lr_sched_critic2.step()\n",
        "\n",
        "        #last_positions = (last_positions - last_positions.mean(0)) / last_positions.std(0)\n",
        "\n",
        "        if i%2==0:\n",
        "            new_act = self.actor(last_maps, last_positions)\n",
        "            new_qs = self.critic1(last_maps, last_positions, new_act)\n",
        "            actor_loss = -new_qs.mean()\n",
        "            #print('actor_loss', actor_loss)\n",
        "            actor_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.actor.parameters(), 1)\n",
        "\n",
        "            if i % 500 == 0:\n",
        "                print(\"ACTOR\")\n",
        "                plot_grad_flow(self.actor.named_parameters())\n",
        "                \n",
        "            self.optimizer_actor.step()\n",
        "            self.lr_sched_actor.step()\n",
        "            \n",
        "\n",
        "  \n",
        "    # TODO: Complete the function\n",
        "    def train(self, num_steps):\n",
        "        \"\"\"\n",
        "        Train the policy for the given number of iterations\n",
        "        :param num_steps:The number of steps to train the policy for\n",
        "        \"\"\"\n",
        "        self.critic_criterion = MSELoss()\n",
        "        num_episodes = 0\n",
        "        i = 0\n",
        "        total_reward = 0\n",
        "        total_test_reward = 0\n",
        "        total_steps = 0\n",
        "        episode_reward = 0\n",
        "        steps_list = []\n",
        "        self.rewards = []\n",
        "        start = time.time()\n",
        "        total_target_time = 0\n",
        "        total_backprop_time = 0\n",
        "        total_gen_episode_time = 0\n",
        "        total_test_time = 0\n",
        "        total_dataload_time = 0\n",
        "\n",
        "        \n",
        "        map, position = self.replay.env.reset()\n",
        "        #map, position = self.env.reset(self.env.index_map, False)\n",
        "        map = resize(map, (84, 84))\n",
        "        map = map / 255\n",
        "        position = position.astype(np.float64)\n",
        "        position[0] = position[0] / 480\n",
        "        position[1] = position[1] / 640\n",
        "        action = {'map':torch.from_numpy(map).float(), 'position':torch.from_numpy(position).float()}\n",
        "        \n",
        "        while i < num_steps:\n",
        "            self.optimizer_critic1.zero_grad()\n",
        "            self.optimizer_critic2.zero_grad()\n",
        "            self.optimizer_actor.zero_grad()\n",
        "            gen_start = time.time()\n",
        "            action, terminal = self.replay.generate_step(ActorPolicy(self.actor), action)\n",
        "            total_gen_episode_time += time.time() - gen_start\n",
        "            total_reward += action['reward'].item()\n",
        "            if i%100==0:\n",
        "                print('step {}'.format(i))\n",
        "                save_models(self.actor, self.critic1, self.critic2, self.actor_target, self.critic1_target, self.critic2_target, i)\n",
        "                shutil.rmtree('/content/drive/My Drive/data.lmdb')\n",
        "                shutil.copytree('db.lmdb', '/content/drive/My Drive/data.lmdb')\n",
        "                #print(total_reward)\n",
        "                #print(action)\n",
        "            if terminal:\n",
        "                self.rewards.append(total_reward)\n",
        "                total_reward = 0                \n",
        "                map, position = self.env.reset()\n",
        "                #map, position = #self.env.reset(self.env.index_map, False)\n",
        "                map = resize(map, (84, 84))\n",
        "                map = map / 255\n",
        "                position = position.astype(np.float64)\n",
        "                position[0] = position[0] / 480\n",
        "                position[1] = position[1] / 640\n",
        "                action = {'map':torch.from_numpy(map).float(), 'position':torch.from_numpy(position).float()}\n",
        "\n",
        "\n",
        "            #maps.size() -> (seq_len, batch_size, 1, 224, 224)\n",
        "            #positons.size() -> (seq_len, batch_size, 2)\n",
        "            #rewards.size() -> (seq_len, batch_size, 1)\n",
        "            # actions -> (seq_len, batch_size, 2)\n",
        "            dataload_time = time.time()\n",
        "            maps, positions, rewards, actions, last_positions, last_maps = self.replay.sample_transitions(self.batch_size)\n",
        "            maps = maps.unsqueeze(1)\n",
        "            last_maps = last_maps.unsqueeze(1)\n",
        "\n",
        "            total_dataload_time += time.time() - dataload_time\n",
        "\n",
        "            target_start = time.time()\n",
        "            with torch.no_grad():\n",
        "                target_action = self.actor_target(last_maps, last_positions)\n",
        "                #print('target action', target_action.size())\n",
        "                #Should be (seq_len, batch_size, 2)\n",
        "                #Should be (seq_len, batch_size, 1)\n",
        "                crit1 = self.critic1_target(maps, positions, target_action)\n",
        "                crit2 = self.critic2_target(maps, positions, target_action)\n",
        "                #print('rewards', rewards.size())\n",
        "                #print('crit', crit.size())\n",
        "                ys = rewards.unsqueeze(1) + self.gamma * torch.minimum(crit1, crit2)\n",
        "\n",
        "            total_target_time += time.time() - target_start\n",
        "            update_start = time.time()\n",
        "            self.update_network(ys, maps, positions, actions, last_maps, last_positions, i)\n",
        "\n",
        "            if i%2==0:\n",
        "              self.update_target_networks()\n",
        "            total_backprop_time += time.time() - update_start\n",
        "            i += 1\n",
        "            if i % 100 == 0:\n",
        "              print('step {}'.format(i))\n",
        "              print('avg iter time {}'.format((time.time() - start) / i))\n",
        "\n",
        "              reward = 0\n",
        "              start_test = time.time()\n",
        "              for j in range(5):\n",
        "                test_map, test_position = self.replay.test_env.reset()\n",
        "                #test_map, test_position = self.replay.test_env.reset(self.env.index_map, False)\n",
        "                test_map = resize(test_map, (84, 84))\n",
        "                test_map = test_map / 255\n",
        "                test_position = test_position.astype(np.float64)\n",
        "                test_position[0] = test_position[0] / 480\n",
        "                test_position[1] = test_position[1] / 640\n",
        "                test_action = {'map':torch.from_numpy(test_map).float(), 'position':torch.from_numpy(test_position).float()}\n",
        "                x = 0\n",
        "                reward= 0\n",
        "                total_test_reward = 0\n",
        "                while x < 300:\n",
        "                  test_action, test_terminal = self.replay.generate_step(ActorPolicy(self.actor), test_action, False, False, True)\n",
        "                  print('action', test_action)\n",
        "                  print('terminal', test_terminal)\n",
        "                  reward += test_action['reward'].item()\n",
        "                  if test_terminal:\n",
        "                    test_map, test_position = self.replay.test_env.reset()\n",
        "                    #test_map, test_position = self.replay.test_env.reset(self.env.index_map, False)\n",
        "\n",
        "                    test_map = resize(test_map, (84, 84))\n",
        "                    test_map = test_map / 255\n",
        "                    test_position = test_position.astype(np.float64)\n",
        "                    test_position[0] = test_position[0] / 480\n",
        "                    test_position[1] = test_position[1] / 640\n",
        "                    test_action = {'map':torch.from_numpy(test_map).float(), 'position':torch.from_numpy(test_position).float()}\n",
        "                    break\n",
        "                  x += 1\n",
        "                print('reward', reward)\n",
        "\n",
        "#             print('test reward', total_reward)\n",
        "#             total_test_time = time.time() - start\n",
        "#             print('avg test time', total_test_time / 5)\n",
        "#             print('avg target time', total_target_time / i)\n",
        "#             print('avg backprop time', total_backprop_time / i)\n",
        "#             print('avg data load time', total_dataload_time / i)\n",
        "#             print('avg gen episode time', total_gen_episode_time / i)\n",
        "            #  test_done = False\n",
        "            #  episode_reward = 0\n",
        "            #  the_steps = 0\n",
        "            #  s = test_env.reset()\n",
        "            #  while not test_done:\n",
        "            #    total_steps += 1\n",
        "            #    the_steps += 1\n",
        "            #    action = self.actor(torch.from_numpy(s).float().to(device='cuda')).detach().squeeze().cpu().numpy()\n",
        "            #    n_state, r, test_done, _ = test_env.step(action)\n",
        "            #    s = n_state\n",
        "            #    episode_reward += r\n",
        "\n",
        "            #  rewards.append(episode_reward)\n",
        "            #  steps_list.append(the_steps)\n",
        "            #  print('Episode reward')\n",
        "            #  print(episode_reward)\n",
        "\n",
        "        return rewards, steps_list"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "xjFt7JBRQVyT",
        "outputId": "96bccacf-e978-4cc2-b7c8-901a99561268"
      },
      "source": [
        "class ClippedLinearFrontierDistanceReward:\n",
        "    def __init__(self, reward_scale):\n",
        "        self.reward_scale = reward_scale\n",
        "        self.paper_reward = PaperRewardFunction()\n",
        "\n",
        "    def frontiers(self, op_map, map_size, points):\n",
        "        y_len = map_size[0]\n",
        "        x_len = map_size[1]\n",
        "        mapping = op_map.copy()\n",
        "        # 0-1 unknown area map\n",
        "        mapping = (mapping == 127) * 1\n",
        "        mapping = np.lib.pad(mapping, ((1, 1), (1, 1)),\n",
        "                             'constant',\n",
        "                             constant_values=0)\n",
        "        fro_map = mapping[2:][:, 1:x_len + 1] + mapping[:y_len][:, 1:x_len + 1] + mapping[1:y_len + 1][:, 2:] + \\\n",
        "                  mapping[1:y_len + 1][:, :x_len] + mapping[:y_len][:, 2:] + mapping[2:][:, :x_len] + mapping[2:][:,\n",
        "                                                                                                      2:] + \\\n",
        "                  mapping[:y_len][:, :x_len]\n",
        "\n",
        "        ind_free = np.where(op_map.ravel(order='F') == 255)[0]\n",
        "        ind_fron_1 = np.where(1 < fro_map.ravel(order='F'))[0]\n",
        "        ind_fron_2 = np.where(fro_map.ravel(order='F') < 8)[0]\n",
        "        ind_fron = np.intersect1d(ind_fron_1, ind_fron_2)\n",
        "        ind_to = np.intersect1d(ind_free, ind_fron)\n",
        "        f = points[ind_to]\n",
        "        f = f.astype(int)\n",
        "        return f\n",
        "\n",
        "    def map_points(self, map_glo):\n",
        "        map_x = map_glo.shape[1]\n",
        "        map_y = map_glo.shape[0]\n",
        "        x = np.linspace(0, map_x - 1, map_x)\n",
        "        y = np.linspace(0, map_y - 1, map_y)\n",
        "        t1, t2 = np.meshgrid(x, y)\n",
        "        points = np.vstack([t1.T.ravel(), t2.T.ravel()]).T\n",
        "        return points\n",
        "\n",
        "    def astar_path(self, weights, start, goal, allow_diagonal=True):\n",
        "        temp_start = [start[1], start[0]]\n",
        "        temp_goal = [goal[1], goal[0]]\n",
        "        temp_weight = (weights < 150) * 254 + 1\n",
        "        # For the heuristic to be valid, each move must cost at least 1.\n",
        "        if temp_weight.min(axis=None) < 1.:\n",
        "            raise ValueError(\"Minimum cost to move must be 1, but got %f\" % (\n",
        "                temp_weight.min(axis=None)))\n",
        "        # Ensure start is within bounds.\n",
        "        if (temp_start[0] < 0 or temp_start[0] >= temp_weight.shape[0] or\n",
        "                temp_start[1] < 0 or temp_start[1] >= temp_weight.shape[1]):\n",
        "            raise ValueError(\"Start lies outside grid.\")\n",
        "        # Ensure goal is within bounds.\n",
        "        if (temp_goal[0] < 0 or temp_goal[0] >= temp_weight.shape[0] or\n",
        "                temp_goal[1] < 0 or temp_goal[1] >= temp_weight.shape[1]):\n",
        "            raise ValueError(\"Goal of lies outside grid.\")\n",
        "\n",
        "        height, width = temp_weight.shape\n",
        "        start_idx = np.ravel_multi_index(temp_start, (height, width))\n",
        "        goal_idx = np.ravel_multi_index(temp_goal, (height, width))\n",
        "\n",
        "        path = astar(\n",
        "            temp_weight.flatten(), height, width, start_idx, goal_idx, allow_diagonal,\n",
        "        )\n",
        "        return path\n",
        "\n",
        "    def get_reward(self, robot_pos, old_op_map, op_map, coll_index):\n",
        "        paper_reward = self.paper_reward.get_reward(robot_pos, old_op_map,\n",
        "                                                    op_map, coll_index)\n",
        "        \n",
        "        #If there was a collision return the collision reward\n",
        "        if coll_index:\n",
        "            return paper_reward\n",
        "\n",
        "        frontiers = np.array(\n",
        "            self.frontiers(op_map, op_map.shape, self.map_points(op_map)))\n",
        "        \n",
        "        frontiers = frontiers[np.random.choice(np.arange(0, frontiers.shape[0]), (10,)), :]\n",
        "\n",
        "        for frontier in range(frontiers.shape[0]):\n",
        "          frontier = frontiers[frontier, :]\n",
        "          path = self.astar_path(op_map, robot_pos, frontier)\n",
        "          dist = 0\n",
        "          last_point = robot_pos\n",
        "          for point in range(1, path.shape[1]):\n",
        "            point = path[:, point]\n",
        "            dist += np.linalg.norm(point - last_point)\n",
        "            paper_reward += np.clip(-self.reward_scale * dist + 1, 0, 1)\n",
        "        \n",
        "        return paper_reward\n",
        "\n",
        "\n",
        "import random\n",
        "from copy import deepcopy\n",
        "\n",
        "class GuidedExplorationPolicy:\n",
        "\n",
        "  def __init__(self, prob_guided, model, action_space, noise_var):\n",
        "    self.prob_guided = prob_guided\n",
        "    self.model = model\n",
        "    self.action_space = action_space\n",
        "    #self.noise = torch.MultivariateGaussian(torch.zeros(2), torch.diag([noise_var,noise_var]))\n",
        "\n",
        "  def __call__(self, map, location, env):\n",
        "    p = random.random()\n",
        "    actions = []\n",
        "    if p < self.prob_guided:\n",
        "      rescue_map, rescue_path = env.rescuer()\n",
        "      location = location.cpu().numpy()\n",
        "      location[0] *= 640\n",
        "      location[1] *= 480\n",
        "      last_point = location\n",
        "      point = 0\n",
        "      count  = 0\n",
        "      while point < rescue_path.shape[1]:\n",
        "        count += 1\n",
        "        next_point = rescue_path[[1, 0], point].astype(np.float64)\n",
        "        dist = np.linalg.norm(next_point - location)\n",
        "        _, coll = env.collision_check(location.astype(np.int64), next_point.astype(np.int64), env.map_size, env.global_map) \n",
        "\n",
        "        if coll or dist > self.action_space.max_distance:\n",
        "          diff = (last_point - location).astype(np.float64)\n",
        "          angle = np.arctan2(diff[0], diff[1])\n",
        "          dist = np.linalg.norm(diff)\n",
        "          if angle < 0:\n",
        "            angle += 2 * np.pi\n",
        "          angle = angle / (2 * np.pi)\n",
        "          dist = np.clip((dist - self.action_space.min_travel) / (self.action_space.max_distance - self.action_space.min_travel), 0, 1)\n",
        "          location = next_point\n",
        "          last_point = next_point\n",
        "          print('appending', angle, dist)\n",
        "          actions.append(torch.from_numpy(np.array([angle, dist])).to(device='cuda').float())\n",
        "        else:\n",
        "          point += 1\n",
        "          last_point = next_point\n",
        "      \n",
        "      \n",
        "      _, coll = env.collision_check(location.astype(np.int64), last_point.astype(np.int64), env.map_size, env.global_map)\n",
        "      dist = np.linalg.norm(last_point - location)\n",
        "      #if coll or dist > self.action_space.max_distance:\n",
        "      diff = (last_point - location).astype(np.float64)\n",
        "      angle = np.arctan2(diff[0], diff[1])\n",
        "      if angle < 0:\n",
        "        angle += 2 * np.pi\n",
        "      dist = np.linalg.norm(diff)\n",
        "      print('appending last', angle, dist)\n",
        "      angle = angle / (2 * np.pi)\n",
        "      dist = (dist - self.action_space.min_travel) / (self.action_space.max_distance - self.action_space.min_travel)\n",
        "      actions.append(torch.from_numpy(np.array([angle, dist])).to(device='cuda').float())\n",
        "    else:\n",
        "      return [torch.from_numpy(np.random.uniform(0, 1, (2,)))]\n",
        "\n",
        "    return actions\n",
        "\n",
        "reward_func = PaperRewardFunction()#ClippedLinearFrontierDistanceReward(1/320)\n",
        "action_space = PolarActionSpace(1, 100)\n",
        "\n",
        "if laptop:\n",
        "    robot = Robot(0, True, False, 'DungeonMaps',action_space,reward_func, False)\n",
        "    test_robot = Robot(0, True, True, 'DungeonMaps',action_space,reward_func, False)\n",
        "else:\n",
        "    robot = Robot(0, True, False, 'DRL_robot_exploration/DungeonMaps',action_space,reward_func, False)\n",
        "    test_robot = Robot(0, True, True, 'DRL_robot_exploration/DungeonMaps',action_space,reward_func, False)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCg-zeJMGV5U",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "51f0f8dc-2793-4330-8869-93f2505de6c0"
      },
      "source": [
        "replay = Replay(50000, 10000, 300, 4, 2, robot, test_robot, 640, 480)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "appending 0.9710535766755708 0.8834245461087945\n",
            "appending last 5.755110858753227 13.892443989449804\n",
            "appending 0.0 0.0\n",
            "appending last 3.1249275298758525 60.00833275470999\n",
            "appending 0.0 0.0\n",
            "appending 0.3087812772689675 0.32567212401201334\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.522400692465974 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 6.219978475282126 79.1580697086532\n",
            "appending 0.0 0.0\n",
            "appending 0.0 0.3838383838383838\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.397174280633979 96.76776322722355\n",
            "appending 0.0 0.0\n",
            "appending 0.7473027168581134 0.5859441814921992\n",
            "appending last 4.71238898038469 19.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.917265697421798 78.64477096412705\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.488912379244057 90.24411338142782\n",
            "appending 0.0 0.0\n",
            "appending 0.7210896907986387 0.9963570672388808\n",
            "appending last 4.71238898038469 68.0\n",
            "appending 0.0 0.0\n",
            "appending 0.826535587713105 0.776027582085223\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 2.6238107949771066 90.91754506144565\n",
            "appending 0.0 0.0\n",
            "appending last 1.5707963267948966 30.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7129465308239906 0.9968638182288164\n",
            "appending 0.75 0.2727272727272727\n",
            "appending 0.5 0.1414141414141414\n",
            "appending 0.375 0.8898530750455049\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.5 0.25252525252525254\n",
            "appending 0.375 0.8898530750455049\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.9032653078973423 0.5559161909544202\n",
            "appending last 5.657700266940357 22.20360331117452\n",
            "appending 0.0 0.0\n",
            "appending last 4.687077931241841 79.02531240052139\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 5.885385548169317 89.48758645994076\n",
            "appending 0.0 0.0\n",
            "appending last 5.250433188210314 72.20110802473879\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 5.31793364398966 79.05694150420949\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.0 0.0\n",
            "appending 0.20396108956414172 0.8751647925093126\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending last 4.392480100423305 57.237332367308234\n",
            "appending 0.0 0.0\n",
            "appending last 4.243123452958928 79.60527620704548\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.0802405049080853 0.9935653633340926\n",
            "appending last 0.0 38.0\n",
            "appending 0.0 0.0\n",
            "appending 0.0 0.3838383838383838\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.43979264133604407 0.8377222047573049\n",
            "appending 0.4701362027966999 0.8021357774939242\n",
            "appending last 2.356194490192345 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending 0.5 0.0\n",
            "appending last 2.356194490192345 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending 0.8816276223066355 0.33303611619117235\n",
            "appending last 4.71238898038469 31.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.881604767070707 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.0 0.0\n",
            "appending 0.8548522371868741 0.38590496533156887\n",
            "appending last 4.71238898038469 17.0\n",
            "appending 0.0 0.0\n",
            "appending last 6.2703654967066855 78.00640999302557\n",
            "appending 0.0 0.0\n",
            "appending last 3.9982982817725317 79.39773296511683\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.9241678549685199 0.34227805136388706\n",
            "appending last 5.793227980925858 34.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.8667077563108085 91.0823802938856\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8428467021953725 0.9984555665989038\n",
            "appending last 3.3576776258865793 41.97618372363071\n",
            "appending 0.0 0.0\n",
            "appending last 4.124386376837123 79.32212806020776\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 5.279118197908196 78.23042886243178\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.9124111073746863 0.9942544929620273\n",
            "appending last 0.0 14.0\n",
            "appending 0.9128278709067483 0.9985627400968282\n",
            "appending last 0.0 17.0\n",
            "appending 0.9122013826493086 0.9921029686472662\n",
            "appending last 0.0 22.0\n",
            "appending 0.8822955712174744 0.7692493612509226\n",
            "appending last 0.0 55.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.7756714209624315 0.9962276246878111\n",
            "appending last 4.71238898038469 65.0\n",
            "appending last 4.521943649172443 96.40975697914052\n",
            "appending 0.0 0.0\n",
            "appending last 4.780775323975194 73.17103251970687\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.5431731936986726 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 5.604522816431274 79.64923100695951\n",
            "appending 0.0 0.0\n",
            "appending 0.1720208696226307 0.16161616161616163\n",
            "appending 0.125 0.4470185252115055\n",
            "appending 0.25 0.13131313131313133\n",
            "appending last 2.976443976175166 6.082762530298219\n",
            "appending 0.0 0.0\n",
            "appending 0.39956059600053245 0.31517660986069934\n",
            "appending last 3.141592653589793 4.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending last 5.482615811178942 42.725955301221006\n",
            "appending 0.0 0.0\n",
            "appending last 3.1249275298758525 60.00833275470999\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.383513222274198 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.634767471647296 90.27181176868004\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7459199980155949 0.3839678626895184\n",
            "appending last 4.6867535718630124 39.01281840626232\n",
            "appending 0.0 0.0\n",
            "appending last 5.410629869227854 73.10950690573696\n",
            "appending 0.0 0.0\n",
            "appending 0.7741728438609634 0.9913263968245742\n",
            "appending last 4.71238898038469 54.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.599590605187015 79.1580697086532\n",
            "appending last 4.563499060755852 26.965002918199325\n",
            "appending last 4.688625849943699 94.69340653275145\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.7329260398343148 0.6502609748962082\n",
            "appending last 4.71238898038469 13.0\n",
            "appending 0.1704183979022804 0.8800213742798182\n",
            "appending 0.25 0.30303030303030304\n",
            "appending last 0.0 0.0\n",
            "appending 0.11198361155693694 0.5363405305147071\n",
            "appending 0.25 0.31313131313131315\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.20210705722516673 0.6033222808359182\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.30508924958393996 0.6449088014898374\n",
            "appending last 0.0 0.0\n",
            "appending last 4.360080255710548 72.44998274671983\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 3.8432178732434745 92.9569792968769\n",
            "appending 0.0 0.0\n",
            "appending 0.9583470024189555 0.5754962844701311\n",
            "appending last 6.012238456841166 18.681541692269406\n",
            "appending 0.0 0.0\n",
            "appending last 6.143083582782956 78.77182237323191\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 5.881604767070707 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 3.358886084512814 78.85429601486528\n",
            "appending last 4.057689129743006 35.718908464405374\n",
            "appending 0.0 0.0\n",
            "appending last 4.85249070478132 78.77182237323191\n",
            "appending 0.0 0.0\n",
            "appending last 4.969712695355778 78.587530817554\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.9195342759831555 0.6364425456891014\n",
            "appending last 5.755110858753227 13.892443989449804\n",
            "appending 0.0 0.0\n",
            "appending last 6.168308701762687 78.5175139698144\n",
            "appending 0.0 0.0\n",
            "appending 0.17620819117478337 0.5319760753534843\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.17888281235710618 0.5275346821079299\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending 0.27304762491621354 0.4798760741670668\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.152449183270301 79.07591289387686\n",
            "appending 0.0 0.0\n",
            "appending last 4.215046264037867 79.64923100695951\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7355710308118477 0.9940227187341955\n",
            "appending last 4.71238898038469 36.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.0 0.0\n",
            "appending 0.0 0.3838383838383838\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 3.1249275298758525 60.00833275470999\n",
            "appending 0.0 0.0\n",
            "appending last 3.1249275298758525 60.00833275470999\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 39.0\n",
            "appending 0.0 0.0\n",
            "appending 0.11139140985058955 0.9935145332019573\n",
            "appending last 0.0 45.0\n",
            "appending 0.0 0.0\n",
            "appending 0.49839242898442293 0.9899500038003113\n",
            "appending last 3.141592653589793 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.204799485487253 79.1580697086532\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.199000768226593 87.14355971613737\n",
            "appending 0.0 0.0\n",
            "appending last 4.310274964732927 94.54099639838793\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.737700029527538 79.02531240052139\n",
            "appending 0.0 0.0\n",
            "appending 0.2132207780133689 0.5191186625224136\n",
            "appending 0.25 0.12121212121212122\n",
            "appending 0.5 0.6262626262626263\n",
            "appending 0.5298637972033001 0.8021357774939242\n",
            "appending last 3.836330929786496 7.810249675906654\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 4.3654113315969205 79.39842310785518\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8098807757917714 0.8696152068607275\n",
            "appending last 4.71238898038469 77.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.09637542647564992 0.3093209757745838\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.09931635348454654 0.3010691272878659\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.10241638234956672 0.29292929292929293\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 6.105589139896098 79.2464510246358\n",
            "appending 0.0 0.0\n",
            "appending 0.0 0.1111111111111111\n",
            "appending last 6.246165191305656 54.037024344425184\n",
            "appending 0.011422850006494394 0.5063801839153411\n",
            "appending last 2.2264919530364327 32.802438933713454\n",
            "appending 0.0 0.0\n",
            "appending last 4.522400692465974 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 3.9358177497781264 46.72978998483661\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8610483473881199 0.9960924079095953\n",
            "appending last 4.71238898038469 55.0\n",
            "appending 0.8360104348113153 0.6966810377590262\n",
            "appending last 3.141592653589793 38.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7094539568736273 0.9919375201973155\n",
            "appending last 4.71238898038469 32.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.18618688519214263 0.999242139938247\n",
            "appending 0.21858352090549943 0.04140423751103823\n",
            "appending 0.25 0.2828282828282828\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.3300299826193696 0.45101867517225563\n",
            "appending last 2.356194490192345 1.4142135623730951\n",
            "appending last 4.542177055099215 64.93843238021688\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.8698677492611262 0.43296388281740017\n",
            "appending last 5.1888563998583965 34.88552708502482\n",
            "appending 0.0 0.0\n",
            "appending last 5.853423028082898 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.7926693750342726 79.20227269466452\n",
            "appending 0.8119711722957975 0.9943814698585254\n",
            "appending last 4.71238898038469 39.0\n",
            "appending 0.826303628671515 0.9917370364327107\n",
            "appending last 4.71238898038469 59.0\n",
            "appending last 4.4382215635490905 80.33373212913267\n",
            "appending 0.8893779906687258 0.9993211102426436\n",
            "appending last 5.797563213882118 40.70626487409524\n",
            "appending 0.9548327646991335 1.0\n",
            "appending 0.0 0.7373737373737373\n",
            "appending last 6.054688667887724 44.14748010928823\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.809029181964259 0.770230622861736\n",
            "appending last 4.71238898038469 1.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7213754264756499 0.21576444217169594\n",
            "appending last 4.658868711925375 56.08029957123981\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.9420314226698245 79.07591289387686\n",
            "appending 0.0 0.0\n",
            "appending last 4.661799271615305 79.1012010022604\n",
            "appending 0.0 0.0\n",
            "appending 0.8605710308118477 0.4632474551054538\n",
            "appending last 4.994943932854277 32.28002478313795\n",
            "appending 0.0 0.0\n",
            "appending 0.7832670345672315 0.3306490463319798\n",
            "appending last 5.309565638477367 60.4648658313239\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.6697594950919148 0.3244544477106908\n",
            "appending last 4.582686443228777 46.389654018972806\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 5.829846690375607 57.842696341662794\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.657499117790536 91.13725912051558\n",
            "appending 0.0 0.0\n",
            "appending 0.9855710308118477 0.3246068995107251\n",
            "appending last 6.000630354709998 32.28002478313795\n",
            "appending 0.0 0.0\n",
            "appending 0.8413018859260208 0.7716023197553881\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7707802393875658 0.998483710413464\n",
            "appending last 4.71238898038469 60.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.034139534781332 79.05694150420949\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7329260398343148 0.6502609748962082\n",
            "appending last 4.71238898038469 13.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.096519028445163 79.63039620647382\n",
            "appending 0.7471963856905159 0.9934216395997447\n",
            "appending last 4.71238898038469 9.0\n",
            "appending 0.0 0.0\n",
            "appending 0.6351450632786287 0.9990399477987907\n",
            "appending last 4.71238898038469 57.0\n",
            "appending 0.0 0.0\n",
            "appending 0.991968695566054 0.9911735577007081\n",
            "appending last 0.0 77.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.1249275298758525 60.00833275470999\n",
            "appending 0.0 0.0\n",
            "appending 0.7013178656285476 0.9962049921803674\n",
            "appending last 4.71238898038469 20.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 6.078308590142478 78.64477096412705\n",
            "appending 0.0 0.0\n",
            "appending 0.0 0.18181818181818182\n",
            "appending last 6.258190513560666 40.01249804748511\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7473027168581134 0.5859441814921992\n",
            "appending last 4.71238898038469 19.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.353345565407494 78.60025445251433\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7400657378472295 0.15183050042304444\n",
            "appending last 4.631917969119229 62.20128616033595\n",
            "appending 0.0 0.0\n",
            "appending 0.4557072336085476 0.21050838048324802\n",
            "appending last 3.141592653589793 38.0\n",
            "appending 0.0 0.0\n",
            "appending 0.125 0.9898479733951178\n",
            "appending last 1.0303768265243125 58.309518948453004\n",
            "appending 0.0 0.0\n",
            "appending 0.24591999801559494 0.3839678626895184\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.25 0.3838383838383838\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.1289351017557414 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.522400692465974 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending 0.6510985167210191 0.9962049921803674\n",
            "appending last 4.71238898038469 1.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.813310765051984 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.8847320323466236 0.34053646379211683\n",
            "appending last 5.54859084784036 41.773197148410844\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.3712350958749275 79.07591289387686\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.734363464681352 91.02197536858887\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.674432535196376 79.05694150420949\n",
            "appending 0.0 0.0\n",
            "appending last 4.152449183270301 79.07591289387686\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.8084375306261717 0.6933529432921273\n",
            "appending last 4.71238898038469 18.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.674432535196376 79.05694150420949\n",
            "appending 0.0 0.0\n",
            "appending 0.7473027168581134 0.5859441814921992\n",
            "appending last 4.71238898038469 19.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.256469259006692 78.5175139698144\n",
            "appending last 4.3420655809645705 30.393715170879815\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.6521733528661314 0.20008739441095771\n",
            "appending last 4.095197588844327 38.01315561749642\n",
            "appending 0.0 0.0\n",
            "appending last 3.154250205423845 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.8683267863149916 0.9412818596964154\n",
            "appending last 5.1888563998583965 34.88552708502482\n",
            "appending 0.0 0.0\n",
            "appending 0.8489664091428358 0.7355287084428516\n",
            "appending last 4.71238898038469 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.7835965474361447 0.5683968106374284\n",
            "appending last 4.71238898038469 29.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.8803690882769885 0.9957771578123948\n",
            "appending last 0.0 38.0\n",
            "appending 0.8698677397573498 0.9314118346429698\n",
            "appending last 0.0 61.0\n",
            "appending 0.0 0.0\n",
            "appending last 6.09319701926087 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending 0.0 0.1111111111111111\n",
            "appending last 6.246165191305656 54.037024344425184\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7837341056932418 0.8061456101348252\n",
            "appending last 4.71238898038469 54.0\n",
            "appending 0.0 0.0\n",
            "appending 0.9487918088252166 0.05378338707410868\n",
            "appending 0.9627986173506914 0.6440515094421082\n",
            "appending last 6.038206644052722 4.123105625617661\n",
            "appending 0.0 0.0\n",
            "appending last 0.714090698612158 79.39773296511683\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.2299694397346417 79.30952023559341\n",
            "appending 0.8530591045218576 0.9904121986828237\n",
            "appending last 5.7876336336937575 42.05948168962618\n",
            "appending 0.8712470470263175 0.9996519792028405\n",
            "appending last 0.0 47.0\n",
            "appending 0.0 0.0\n",
            "appending 0.6073883562613613 0.31328910290064893\n",
            "appending 0.6091372412847231 0.9948352810592249\n",
            "appending last 3.141592653589793 10.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.827265585801589 78.5175139698144\n",
            "appending 0.0 0.0\n",
            "appending last 5.586836726416636 79.51100552753688\n",
            "appending 0.0 0.0\n",
            "appending 0.0 0.18181818181818182\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.9228929427748332 0.6405326430378956\n",
            "appending last 4.71238898038469 78.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.825187355582364 79.1580697086532\n",
            "appending 0.9439311650274227 0.6436879943177601\n",
            "appending last 1.5707963267948966 16.0\n",
            "appending 0.0 0.0\n",
            "appending 0.125 0.07560890277008656\n",
            "appending last 1.5707963267948966 2.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.124386376837123 79.32212806020776\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.6304859278080055 0.1971543891786181\n",
            "appending last 3.9603118128654886 42.44997055358225\n",
            "appending last 5.226452507843116 32.538867864272255\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 3.829555965694985 94.49338601193207\n",
            "appending 0.0 0.0\n",
            "appending last 3.154250205423845 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.44971176934859275 0.5425082572359567\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.6250227194214976 97.41663102366043\n",
            "appending 0.0 0.0\n",
            "appending 0.625 0.9898479733951178\n",
            "appending last 3.3556533371536146 23.53720459187964\n",
            "appending 0.0 0.0\n",
            "appending 0.9983924289844229 0.9899500038003113\n",
            "appending last 0.0 2.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.517368712979768 82.56512580987206\n",
            "appending 0.7911846748991664 0.9964765411217789\n",
            "appending last 4.71238898038469 70.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7920946334730905 0.994530647204554\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7459199980155949 0.3839678626895184\n",
            "appending last 4.6867535718630124 39.01281840626232\n",
            "appending 0.0 0.0\n",
            "appending 0.013051890325831778 0.7297591950395955\n",
            "appending 0.0 0.2727272727272727\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 2.449258218916763 53.2634959423431\n",
            "appending 0.0 0.0\n",
            "appending 0.5026972831418866 0.5859441814921992\n",
            "appending last 3.141592653589793 19.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.687077931241841 79.02531240052139\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.6762081911747834 0.012485535126260503\n",
            "appending last 4.633605019395546 76.23647421018367\n",
            "appending 0.0 0.0\n",
            "appending 0.09637542647564992 0.3093209757745838\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.09931635348454654 0.3010691272878659\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.013804835355861956 0.689498770542335\n",
            "appending last 0.0 4.0\n",
            "appending 0.0 0.0\n",
            "appending 0.01511203341945974 0.6291421144362319\n",
            "appending last 0.0 5.0\n",
            "appending 0.0 0.0\n",
            "appending 0.01669168321526257 0.5688375709457414\n",
            "appending last 0.0 5.0\n",
            "appending 0.0 0.0\n",
            "appending 0.019007703923974835 0.4985728610914817\n",
            "appending last 0.0 6.0\n",
            "appending 0.0 0.0\n",
            "appending 0.022065199473862256 0.4284503706281295\n",
            "appending last 0.0 6.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 32.0\n",
            "appending 0.0 0.0\n",
            "appending 0.09637542647564992 0.3093209757745838\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.5292467808318448 61.40032573203501\n",
            "appending 0.0 0.0\n",
            "appending last 3.5431731936986726 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.5 0.18181818181818182\n",
            "appending last 3.1585401833961977 59.00847396772772\n",
            "appending 0.0 0.0\n",
            "appending 0.877893407433361 0.3828010169449843\n",
            "appending last 5.250433188210314 72.20110802473879\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7564270069384006 0.9907149002845969\n",
            "appending last 4.71238898038469 1.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.929682411307711 78.85429601486528\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 4.974102482785895 28.98706608127149\n",
            "appending 0.7721113503048088 0.9928283766329825\n",
            "appending last 4.71238898038469 6.0\n",
            "appending last 4.771395747200316 97.50302194112722\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending last 5.758701329528495 85.20274278726154\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.141051500551063 83.21658488546619\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 5.664023843733121 71.22110140522517\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7400657378472295 0.15183050042304444\n",
            "appending last 4.631917969119229 62.20128616033595\n",
            "appending 0.0 0.0\n",
            "appending 0.9064164790945005 0.026318699752161508\n",
            "appending last 5.665993915639224 38.01315561749642\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 96.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.096519028445163 79.63039620647382\n",
            "appending 0.0 0.0\n",
            "appending last 4.338891834278212 79.47955712005447\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.2173964909509323 79.22752047110903\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.5598169831690223 78.79086241436883\n",
            "appending 0.0 0.0\n",
            "appending 0.0802405049080853 0.9935653633340926\n",
            "appending 0.0 1.0\n",
            "appending last 0.0 53.0\n",
            "appending 0.0 0.0\n",
            "appending 0.0 0.3838383838383838\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.896377921450046 0.2565733087362441\n",
            "appending last 5.644865499170541 38.600518131237564\n",
            "appending 0.0 0.0\n",
            "appending 0.8095147049946873 0.8471171518899849\n",
            "appending last 4.71238898038469 17.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7658627587152768 0.9035240463645253\n",
            "appending last 4.71238898038469 10.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.649182148487229 79.1580697086532\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.7473027168581134 0.5859441814921992\n",
            "appending last 4.71238898038469 18.0\n",
            "appending 0.7472057602549721 0.9967880709505045\n",
            "appending last 3.985746639702964 12.041594578792296\n",
            "appending 0.0 0.0\n",
            "appending last 3.7750185365589375 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 5.7232455100651975 79.07591289387686\n",
            "appending 0.0 0.0\n",
            "appending 0.4461829450870623 0.9642669486752875\n",
            "appending last 3.141592653589793 54.0\n",
            "appending 0.0 0.0\n",
            "appending 0.08423224128486108 0.610104300323586\n",
            "appending last 0.24997862146082248 97.01546268507923\n",
            "appending 0.0 0.0\n",
            "appending 0.5451672353008665 1.0\n",
            "appending last 3.141592653589793 18.0\n",
            "appending last 4.079404534574003 38.03543464278696\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.338891834278212 79.47955712005447\n",
            "appending 0.0 0.0\n",
            "appending 0.7403660298363413 0.991733853827265\n",
            "appending last 4.71238898038469 20.0\n",
            "appending 0.0 0.0\n",
            "appending 0.826535587713105 0.776027582085223\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8441007447691561 0.9956485105795482\n",
            "appending last 4.71238898038469 39.0\n",
            "appending 0.0 0.0\n",
            "appending last 6.219978475282126 79.1580697086532\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 3.1249275298758525 60.00833275470999\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.9232971449358764 0.7308616135391235\n",
            "appending last 5.81953769817878 4.47213595499958\n",
            "appending 0.92313310386709 0.9251563915058223\n",
            "appending last 5.9075450717065205 76.32168761236873\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 4.902377268303406 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 5.481915460790348 89.10667763978185\n",
            "appending 0.0 0.0\n",
            "appending 0.27304762491621354 0.4798760741670668\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.024385409172718538 41.012193308819754\n",
            "appending 0.0 0.0\n",
            "appending 0.8063821382561908 0.7760924736278807\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 5.470766694594873 78.5175139698144\n",
            "appending 0.0 0.0\n",
            "appending 0.9213867895388711 0.13903861677003435\n",
            "appending last 5.426479678996848 19.849433241279208\n",
            "appending 0.0 0.0\n",
            "appending 0.8413018859260208 0.7716023197553881\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.687077931241841 79.02531240052139\n",
            "appending 0.8007454155518595 0.9968809597785128\n",
            "appending last 4.490739417406012 72.78049189171504\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.737700029527538 79.02531240052139\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 5.259673308399657 24.982218068419424\n",
            "appending 0.0 0.0\n",
            "appending 0.40279994389289264 0.359794614618193\n",
            "appending last 3.141592653589793 61.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 5.158992785390498 78.7210264160726\n",
            "appending 0.0 0.0\n",
            "appending 0.8811183282271273 0.3615832220802848\n",
            "appending last 5.532256244781646 41.036569057366385\n",
            "appending 0.0 0.0\n",
            "appending last 4.1698096562587 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 0.3686959026580498 47.16990566028302\n",
            "appending 0.0 0.0\n",
            "appending 0.2686384355771026 0.3357018741136099\n",
            "appending 0.25 0.7474747474747475\n",
            "appending last 0.12435499454676144 8.06225774829855\n",
            "appending 0.0 0.0\n",
            "appending 0.315079702246515 0.320157226752966\n",
            "appending 0.25 0.7777777777777778\n",
            "appending last 0.12435499454676144 8.06225774829855\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.7473027168581134 0.5859441814921992\n",
            "appending last 4.71238898038469 19.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 4.70329832171963 55.00227268031749\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7459199980155949 0.3839678626895184\n",
            "appending last 4.6867535718630124 39.01281840626232\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.6124611431722187 0.5344174534118608\n",
            "appending last 3.8098820724203772 24.20743687382041\n",
            "appending last 4.604534502378875 95.21996240692881\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.27304762491621354 0.4798760741670668\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.024385409172718538 41.012193308819754\n",
            "appending 0.0 0.0\n",
            "appending 0.2670739601656852 0.6502609748962082\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 5.022091924927146 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.1607638932211458 0.5027677686782264\n",
            "appending last 0.7853981633974483 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending 0.1645480012937808 0.483610077165654\n",
            "appending last 0.7853981633974483 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending 0.16863510508059928 0.46475391004214783\n",
            "appending last 0.7853981633974483 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.9528458348113064 0.9932094983304256\n",
            "appending last 5.961434752782944 3.1622776601683795\n",
            "appending 0.951706710298642 0.9927860534755234\n",
            "appending last 0.0 15.0\n",
            "appending 0.951586677680101 0.9903764502896412\n",
            "appending last 0.0 5.0\n",
            "appending 0.951706710298642 0.9927860534755234\n",
            "appending last 0.0 1.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 3.5598169831690223 78.79086241436883\n",
            "appending 0.0 0.0\n",
            "appending 0.5 0.1111111111111111\n",
            "appending last 3.171886413508568 66.03029607687671\n",
            "appending 0.7254305948478138 0.9917115753060467\n",
            "appending last 4.5952802358178255 17.11724276862369\n",
            "appending 0.8607417690968909 0.9944718336421594\n",
            "appending last 4.818653843275769 75.4254598925323\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 6.078308590142478 78.64477096412705\n",
            "appending 0.0 0.0\n",
            "appending last 5.497787143782138 22.627416997969522\n",
            "appending 0.0 0.0\n",
            "appending 0.37845934518546764 0.6471635751514118\n",
            "appending 0.49177517740510074 0.5765407513426911\n",
            "appending 0.5 0.20202020202020202\n",
            "appending last 3.6052402625905993 4.47213595499958\n",
            "appending 0.0 0.0\n",
            "appending last 4.9941608476580415 79.12016177940993\n",
            "appending 0.7927246170850369 0.9991085556923505\n",
            "appending last 4.6228851620330795 78.31347265956222\n",
            "appending 0.869543005115863 0.8927645308666206\n",
            "appending 0.0 0.41414141414141414\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.9644325942630924 0.2177881651046157\n",
            "appending last 6.042651059233681 54.57105459856901\n",
            "appending 0.0 0.0\n",
            "appending 0.4563648949194007 0.6614452581250369\n",
            "appending 0.25 0.1414141414141414\n",
            "appending last 0.0 23.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.6365851430235505 79.22752047110903\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 5.695182703632018 79.32212806020776\n",
            "appending 0.882894827454599 0.998230773802461\n",
            "appending last 5.28091352811573 42.720018726587654\n",
            "appending 0.0 0.0\n",
            "appending last 0.09306372872441795 75.32595834106593\n",
            "appending 0.0 0.0\n",
            "appending 0.5482056239896147 0.15922277388121425\n",
            "appending 0.5927995127491914 0.5586136670811817\n",
            "appending last 4.2487413713838835 11.180339887498949\n",
            "appending 0.0 0.0\n",
            "appending 0.7063648949194007 0.9972183922380603\n",
            "appending last 4.71238898038469 6.0\n",
            "appending 0.804556477932772 0.9515718771380076\n",
            "appending last 4.671870627906342 74.06078584514209\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8736753107119232 0.9910731040468448\n",
            "appending last 6.186711531996999 31.144823004794873\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.853423028082898 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 1.2018367805890402 80.4114419718985\n",
            "appending 0.0 0.0\n",
            "appending 0.51283312078239 0.9931586501683966\n",
            "appending last 3.141592653589793 53.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 39.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.055508629227499946 0.9357333261187576\n",
            "appending last 0.0 32.0\n",
            "appending 0.0 0.0\n",
            "appending 0.08386561933599336 0.6326439705023448\n",
            "appending last 0.0 32.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 0.019605330857204686 51.0098029794274\n",
            "appending last 5.699955937070695 87.15826122634618\n",
            "appending 0.0 0.0\n",
            "appending 0.6475836176504333 1.0\n",
            "appending last 4.71238898038469 50.0\n",
            "appending 0.0 0.0\n",
            "appending 0.07379180882521663 0.6900818919443786\n",
            "appending last 0.0 28.0\n",
            "appending 0.9097510258795084 0.9928283999176788\n",
            "appending last 0.0 44.0\n",
            "appending 0.9673590838045761 0.9984081769112069\n",
            "appending last 0.0 3.0\n",
            "appending 0.9672777250232558 0.9959359778576917\n",
            "appending last 0.0 1.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 5.022091924927146 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 6.219978475282126 79.1580697086532\n",
            "appending 0.9291994658066222 0.9914127344271176\n",
            "appending last 0.0 10.0\n",
            "appending 0.9295432782239482 0.995974041439853\n",
            "appending last 0.0 32.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.0 0.0\n",
            "appending 0.4497991051417792 0.9992926816447978\n",
            "appending 0.5 0.3333333333333333\n",
            "appending last 3.141592653589793 84.0\n",
            "appending last 4.441896214593768 98.23869523144602\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.8879423877470778 0.99376050798282\n",
            "appending last 5.128453486108512 47.01063709417264\n",
            "appending 0.0 0.0\n",
            "appending last 4.625111267435228 80.30566605165541\n",
            "appending last 4.202796715575763 38.948684188300895\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7473027168581134 0.5859441814921992\n",
            "appending last 4.71238898038469 19.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.4527725280076105 78.56844150166147\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.935840143503499 79.90619500389191\n",
            "appending 0.0 0.0\n",
            "appending 0.02830972736118803 0.9033006661517818\n",
            "appending last 0.0 34.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.902377268303406 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.686299721006695 0.275062509363497\n",
            "appending last 3.7662280763614064 53.009433122794285\n",
            "appending 0.0 0.0\n",
            "appending 0.506915424783331 0.22244170572164318\n",
            "appending last 3.196084109830524 55.08175741568164\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.12281993165835588 0.5113498787531437\n",
            "appending last 0.7853981633974483 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending last 1.590793660768047 50.00999900019995\n",
            "appending 0.0 0.0\n",
            "appending last 1.590793660768047 50.00999900019995\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.46208216907011945 0.7175223621596769\n",
            "appending last 3.141592653589793 1.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.3012072488739705 78.84795495128583\n",
            "appending 0.0 0.0\n",
            "appending last 6.075689080744383 77.6659513557904\n",
            "appending 0.0 0.0\n",
            "appending last 5.434807481349194 78.64477096412705\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.9871926407814984 0.6181948097003631\n",
            "appending last 6.192525419978841 11.045361017187261\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.0935835209054994 0.6818734771092505\n",
            "appending last 0.0 18.0\n",
            "appending 0.046900712934809394 0.6390957603183666\n",
            "appending last 0.0 17.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.5634990327751925 80.89499366462674\n",
            "appending 0.0 0.0\n",
            "appending last 5.289828596529204 78.77182237323191\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.649182148487229 79.1580697086532\n",
            "appending 0.0 0.0\n",
            "appending last 5.0380305657279765 81.27115109311545\n",
            "appending 0.0 0.0\n",
            "appending 0.25963397016365874 0.991733853827265\n",
            "appending 0.25 1.0\n",
            "appending 0.25 0.36363636363636365\n",
            "appending 0.5 0.30303030303030304\n",
            "appending last 3.456807353340504 48.38388161361178\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8780025555179424 0.9995510376839264\n",
            "appending 0.875 0.004183975377506011\n",
            "appending 0.75 0.45454545454545453\n",
            "appending last 4.2379890975927825 41.593268686170845\n",
            "appending 0.0 0.0\n",
            "appending last 3.7750185365589375 79.40403012442127\n",
            "appending 0.8019416189005031 0.6830520591635459\n",
            "appending last 3.141592653589793 38.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.7720376002929961 0.9961631479813887\n",
            "appending last 4.71238898038469 43.0\n",
            "appending 0.8668695447859839 0.9923461805678951\n",
            "appending last 5.835665332022416 27.730849247724095\n",
            "appending 0.8784942472100631 0.9930657039533103\n",
            "appending last 6.253782018975581 34.0147027033899\n",
            "appending 0.9769949235083654 0.5742759792076446\n",
            "appending last 1.5707963267948966 5.0\n",
            "appending 0.0 0.0\n",
            "appending last 2.1866662787344233 79.63039620647382\n",
            "appending 0.0 0.0\n",
            "appending 0.745320321339177 0.3334818454887869\n",
            "appending 0.5 0.1414141414141414\n",
            "appending 0.375 0.4470185252115055\n",
            "appending last 1.5707963267948966 41.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7461189415908434 0.4041635687759571\n",
            "appending 0.5 0.1414141414141414\n",
            "appending 0.375 0.4470185252115055\n",
            "appending last 1.5707963267948966 41.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.1306414284357031 0.9976234669110488\n",
            "appending last 1.5707963267948966 65.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.7660756740770122 0.9916377147621946\n",
            "appending last 4.71238898038469 35.0\n",
            "appending 0.04991427705599171 0.7757030439909787\n",
            "appending last 0.0 36.0\n",
            "appending 0.07653558771310501 0.5139847180231453\n",
            "appending last 0.0 37.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.411181731510719 78.84795495128583\n",
            "appending 0.0 0.0\n",
            "appending 0.625 0.9898479733951178\n",
            "appending last 4.481298313188793 52.392747589718944\n",
            "appending 0.0 0.0\n",
            "appending 0.5367792219866311 0.1663055474401311\n",
            "appending last 3.9111191339954514 44.553338819890925\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.6947634302392904 0.9995958787555393\n",
            "appending last 4.71238898038469 43.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.6208126784478473 0.5329163658874995\n",
            "appending last 3.8984271591484814 24.758836806279895\n",
            "appending 0.0 0.0\n",
            "appending last 4.522400692465974 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending last 3.8104048115259257 79.02531240052139\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8052365697607096 0.9995958787555393\n",
            "appending 0.9950280260882054 0.31328910290064893\n",
            "appending last 5.961434752782944 28.460498941515414\n",
            "appending 0.7938297894431621 0.9835703399647948\n",
            "appending last 4.71238898038469 60.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.522400692465974 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7195215548949677 0.998230773802461\n",
            "appending last 4.71238898038469 44.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 5.353345565407494 78.60025445251433\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending last 5.846558147366045 66.2117814289874\n",
            "appending 0.856576348291282 0.9947876881069777\n",
            "appending last 4.71238898038469 53.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.197937667325662 79.25906888173743\n",
            "appending 0.7817558265288476 0.9963997085741705\n",
            "appending last 4.277718765235445 30.870698080866262\n",
            "appending 0.0 0.0\n",
            "appending 0.5254509640158936 0.6242552916407104\n",
            "appending last 3.9269908169872414 16.97056274847714\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 5.881604767070707 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 4.604534502378875 95.21996240692881\n",
            "appending 0.8134461508516387 0.998259232338567\n",
            "appending last 4.71238898038469 71.0\n",
            "appending last 4.406918037780372 61.514449354470266\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 6.216617143403762 90.19977827023745\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.809029181964259 0.770230622861736\n",
            "appending last 4.71238898038469 1.0\n",
            "appending 0.810090058433561 0.996847330223436\n",
            "appending last 3.19709115883551 18.027756377319946\n",
            "appending last 4.842893020526509 94.13380190811043\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7459199980155949 0.3839678626895184\n",
            "appending last 4.6867535718630124 39.01281840626232\n",
            "appending 0.0 0.0\n",
            "appending 0.6805086292274999 0.9931077994291019\n",
            "appending last 4.71238898038469 17.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.7588032819401416 0.9948027962904334\n",
            "appending last 4.71238898038469 21.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.2763840980266075 97.082439194738\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 5.425187690051644 77.98717843338096\n",
            "appending 0.0 0.0\n",
            "appending last 6.025861592208497 78.587530817554\n",
            "appending 0.0 0.0\n",
            "appending last 5.649759424210441 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 5.733625293653207 93.81364506296512\n",
            "appending 0.8954627576984102 0.9879673721250272\n",
            "appending last 5.484089370409272 51.62363799656123\n",
            "appending 0.0 0.0\n",
            "appending 0.17620819117478337 0.5319760753534843\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.625 0.9898479733951178\n",
            "appending last 4.270014757407944 42.04759208325728\n",
            "appending 0.0 0.0\n",
            "appending last 4.844151246862616 83.72574275573791\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.243123452958928 79.60527620704548\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.929682411307711 78.85429601486528\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.737075322440289 81.02468759581859\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7129465308239906 0.9968638182288164\n",
            "appending 0.75 0.25252525252525254\n",
            "appending last 4.71238898038469 19.0\n",
            "appending 0.0 0.0\n",
            "appending 0.8173924745902161 0.7765465645429308\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.2890244595215445 79.12016177940993\n",
            "appending 0.0 0.0\n",
            "appending last 1.5707963267948966 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.5707963267948966 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.5707963267948966 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.5707963267948966 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.625 0.9898479733951178\n",
            "appending last 4.195693841622413 50.60632371551998\n",
            "appending 0.0 0.0\n",
            "appending last 5.4527725280076105 78.56844150166147\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.7527942393173226 0.9967882250559332\n",
            "appending last 4.312148323350716 28.231188426986208\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.0 0.0\n",
            "appending 0.8894289691881523 0.6999216877086858\n",
            "appending last 5.580928375670579 17.029386365926403\n",
            "appending 0.8097375511661329 0.9887281432500121\n",
            "appending last 5.832115651191063 71.11258679024411\n",
            "appending 0.0 0.0\n",
            "appending 0.9737157716443733 0.35855126446251834\n",
            "appending last 6.105589139896098 39.6232255123179\n",
            "appending 0.7917082381335026 0.9938734659167079\n",
            "appending last 4.71238898038469 67.0\n",
            "appending last 4.895071888635715 92.20091033581771\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.6125427610845983 0.7206705958660979\n",
            "appending last 3.9269908169872414 5.656854249492381\n",
            "appending 0.0 0.0\n",
            "appending last 4.522400692465974 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending last 4.600360017958701 80.50465825031493\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.8104048115259257 79.02531240052139\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending 0.6131447408325255 0.4697767078876648\n",
            "appending last 4.242205516737952 68.42514157822401\n",
            "appending 0.0 0.0\n",
            "appending last 4.418519645352222 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.6552375751518298 0.36811404498684963\n",
            "appending last 4.226766887087221 40.70626487409524\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.8988645150895211 0.9939719117551948\n",
            "appending last 0.0 29.0\n",
            "appending 0.8458570082990788 0.7744035490483878\n",
            "appending last 0.0 29.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.85870426838972 96.0260381354974\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 5.864960977600357 78.79086241436883\n",
            "appending 0.0 0.0\n",
            "appending last 3.185043548981324 69.06518659932803\n",
            "appending 0.0 0.0\n",
            "appending last 4.338891834278212 79.47955712005447\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.7829282264629105 0.9979284713327901\n",
            "appending last 4.71238898038469 55.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.2901952613890719 0.31328910290064893\n",
            "appending last 3.141592653589793 17.0\n",
            "appending 0.0 0.0\n",
            "appending 0.766021913605317 0.9949875633620807\n",
            "appending last 4.71238898038469 49.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.661799271615305 79.1012010022604\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7396797524849201 0.7693148171256737\n",
            "appending last 3.788984793329722 51.40038910358559\n",
            "appending 0.0 0.0\n",
            "appending last 3.7750185365589375 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.5 0.3838383838383838\n",
            "appending last 3.141592653589793 39.0\n",
            "appending 0.0 0.0\n",
            "appending 0.1317973573397878 0.8263333791377845\n",
            "appending last 1.5707963267948966 10.0\n",
            "appending 0.0 0.0\n",
            "appending 0.6564164790945007 0.09915811945850474\n",
            "appending 0.5 0.30303030303030304\n",
            "appending last 1.7033478590915707 15.132745950421556\n",
            "appending 0.7336350509844201 0.9985935966946325\n",
            "appending last 4.71238898038469 5.0\n",
            "appending 0.7221768133152653 0.9917001578553915\n",
            "appending last 0.0 0.0\n",
            "appending 0.7291503541020847 0.9951453595115831\n",
            "appending last 4.227911051347666 21.470910553583888\n",
            "appending 0.8729282661804789 0.9958853515932216\n",
            "appending last 5.584525482458123 32.64965543462902\n",
            "appending 0.8879423877470778 0.99376050798282\n",
            "appending last 0.0 39.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7176380571179509 0.990307028271576\n",
            "appending last 4.71238898038469 52.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.522400692465974 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending 0.6962657520218857 0.9962049921803674\n",
            "appending last 4.71238898038469 60.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7323883562613613 0.9045843573876179\n",
            "appending 0.6782750222939187 0.33776111833782957\n",
            "appending last 4.597112854413737 95.63472172804185\n",
            "appending 0.0 0.0\n",
            "appending 0.125 0.9898479733951178\n",
            "appending 0.03056539125485973 0.36034587516954036\n",
            "appending last 0.0 26.0\n",
            "appending 0.9197594950919148 0.9935653633340926\n",
            "appending last 0.0 11.0\n",
            "appending 0.8453617144319536 0.992904370691427\n",
            "appending last 4.71238898038469 68.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.17620819117478337 0.5319760753534843\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.17888281235710618 0.5275346821079299\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.18160120892732332 0.5232476275734984\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.24805918226949036 0.8182434074170063\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.737700029527538 79.02531240052139\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.9221541651886936 0.6993466540465808\n",
            "appending last 5.764039192933064 8.06225774829855\n",
            "appending 0.0 0.0\n",
            "appending 0.7250760371808433 0.3784926073064918\n",
            "appending last 4.687394186765769 40.01249804748511\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 72.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 32.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending last 5.89095395697444 97.66698468778227\n",
            "appending 0.852068571892535 0.9143119306077169\n",
            "appending last 4.235921560910983 34.88552708502482\n",
            "appending 0.0 0.0\n",
            "appending last 3.5431731936986726 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.692391646411539 50.00999900019995\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 63.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.470766694594873 78.5175139698144\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.06444052920457831 0.22067999310698713\n",
            "appending last 0.5926974047350627 59.07622195096772\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.3548522371868741 0.38590496533156887\n",
            "appending last 3.141592653589793 1.0\n",
            "appending 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 2.9441970937399127 5.0990195135927845\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 1.3659196097577881 78.64477096412705\n",
            "appending 0.0 0.0\n",
            "appending last 1.5707963267948966 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.5707963267948966 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.5707963267948966 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.5707963267948966 25.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 5.883908462325749 21.43611407951488\n",
            "appending 0.0 0.0\n",
            "appending 0.44998843998357396 0.8395854886793168\n",
            "appending last 3.141592653589793 1.0\n",
            "appending 0.0 0.0\n",
            "appending 0.5694913707725 0.9931077994291019\n",
            "appending last 3.141592653589793 16.0\n",
            "appending 0.7917082381335026 0.9938734659167079\n",
            "appending last 4.71238898038469 67.0\n",
            "appending last 4.895071888635715 92.20091033581771\n",
            "appending 0.0 0.0\n",
            "appending 0.7741728438609634 0.9913263968245742\n",
            "appending last 4.71238898038469 47.0\n",
            "appending last 4.71238898038469 34.66667175292969\n",
            "appending 0.0 0.0\n",
            "appending 0.4342164229873932 0.6186006593775933\n",
            "appending last 3.141592653589793 20.0\n",
            "appending last 3.546613816877285 84.59417107965075\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 0.028563657838759995 35.014282800023196\n",
            "appending 0.0 0.0\n",
            "appending 0.0 0.3838383838383838\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.917947827056783 0.3382008010013468\n",
            "appending last 5.7790193457004335 33.12099032335839\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.8650657378472295 0.21890472825766938\n",
            "appending last 5.446983439723916 41.773197148410844\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.809029181964259 0.770230622861736\n",
            "appending last 4.71238898038469 1.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.661799271615305 79.1012010022604\n",
            "appending last 0.30077464258373987 75.3842018686342\n",
            "appending 0.0 0.0\n",
            "appending last 3.796587509098108 87.00574693662483\n",
            "appending last 4.43822156033496 44.322058599215\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.27010256118324444 0.6313727801740375\n",
            "appending last 3.141592653589793 23.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 3.1669037027326414 79.02531240052139\n",
            "appending 0.8205971692261202 0.5900690181203563\n",
            "appending 0.3165624693738283 0.08938240203834448\n",
            "appending last 2.356194490192345 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.809029181964259 0.770230622861736\n",
            "appending last 4.71238898038469 1.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.006258315417157 79.40403012442127\n",
            "appending 0.8134917190274166 0.9910731621014737\n",
            "appending 0.875 0.9898479733951178\n",
            "appending last 5.133052329517724 41.6293165929973\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 3.9269908169872414 98.99494936611666\n",
            "appending 0.0 0.0\n",
            "appending 0.6273403451687234 0.9613830334177447\n",
            "appending last 4.71238898038469 14.0\n",
            "appending last 5.482615811178942 42.725955301221006\n",
            "appending 0.0 0.0\n",
            "appending 0.8373800648820979 0.996407753818992\n",
            "appending last 4.71238898038469 66.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7459199980155949 0.3839678626895184\n",
            "appending last 4.71238898038469 24.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.154250205423845 79.00632886041473\n",
            "appending last 4.3047574749270625 35.945270898965276\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.9982982817725317 79.39773296511683\n",
            "appending 0.0 0.0\n",
            "appending 0.6227585292913823 0.4970662711366946\n",
            "appending last 3.7001919689333556 28.30194339616981\n",
            "appending 0.0 0.0\n",
            "appending 0.9517943760103852 0.6671941258278873\n",
            "appending last 6.012238456841166 18.681541692269406\n",
            "appending 0.9633736143453997 0.9936333474470196\n",
            "appending last 0.0 42.0\n",
            "appending 0.9519450530855599 0.997606958890964\n",
            "appending 0.21858352090549943 0.04140423751103823\n",
            "appending last 0.0 10.0\n",
            "appending 0.0 0.0\n",
            "appending last 2.329652052440948 79.93122043357026\n",
            "appending 0.0 0.0\n",
            "appending 0.25 1.0\n",
            "appending 0.25 0.21212121212121213\n",
            "appending last 0.3217505543966422 3.1622776601683795\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 6.263187973206436 50.00999900019995\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.1306414284357031 0.9976234669110488\n",
            "appending last 1.5707963267948966 65.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.5431731936986726 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 5.38505953219176 75.43208866258443\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 5.160331074554357 85.42833253669417\n",
            "appending 0.8062809719219268 0.9087039652807886\n",
            "appending last 4.71238898038469 77.0\n",
            "appending 0.0 0.0\n",
            "appending 0.8888715110717317 0.7283788576337067\n",
            "appending last 5.497787143782138 4.242640687119285\n",
            "appending 0.0 0.0\n",
            "appending 0.7396350083356654 0.4555325483481256\n",
            "appending last 4.649970170388732 32.0624390837628\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.29209463347309056 0.994530647204554\n",
            "appending 0.25 1.0\n",
            "appending 0.25 0.1919191919191919\n",
            "appending last 3.141592653589793 39.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.902377268303406 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending last 4.4785132816468245 29.12628403845176\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.6891424865883836 0.9915301460447753\n",
            "appending last 4.71238898038469 15.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.340321221526569 88.02272433866155\n",
            "appending 0.0 0.0\n",
            "appending 0.6546382855680464 0.992904370691427\n",
            "appending last 4.71238898038469 32.0\n",
            "appending 0.0 0.0\n",
            "appending 0.9983924289844229 0.9899500038003113\n",
            "appending last 0.0 10.0\n",
            "appending 0.0 0.0\n",
            "appending 0.48557103081184777 0.10146829310290163\n",
            "appending 0.35913724128472324 0.9948352810592249\n",
            "appending 0.25 1.0\n",
            "appending 0.25 0.7575757575757576\n",
            "appending 0.27492396281915665 0.9613830334177447\n",
            "appending last 2.819842099193151 3.1622776601683795\n",
            "appending 0.0 0.0\n",
            "appending 0.3568894395787306 0.9963570672388808\n",
            "appending 0.25 1.0\n",
            "appending 0.25 0.7474747474747475\n",
            "appending 0.27492396281915665 0.9613830334177447\n",
            "appending last 2.819842099193151 3.1622776601683795\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.6865538491483613 0.998259232338567\n",
            "appending last 0.0 0.0\n",
            "appending 0.7904117038960022 0.9951963085107877\n",
            "appending last 3.2622163221698957 66.48308055437865\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 3.1249275298758525 60.00833275470999\n",
            "appending 0.0 0.0\n",
            "appending 0.3087812772689675 0.32567212401201334\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.4100335861690618 74.96665925596525\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.14758361765043326 0.3939393939393939\n",
            "appending last 0.7853981633974483 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending 0.15177093920258597 0.3738702587625901\n",
            "appending last 0.7853981633974483 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending last 5.38912592794155 78.24321056807422\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7210896907986387 0.9963570672388808\n",
            "appending last 4.71238898038469 8.0\n",
            "appending last 4.278894708876779 64.27891539667255\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending 0.025757227158889725 0.992904370691427\n",
            "appending 0.0 0.23232323232323232\n",
            "appending 0.25 0.1414141414141414\n",
            "appending last 2.356194490192345 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending 0.5 0.010101010101010102\n",
            "appending last 3.3327771131868076 31.575306807693888\n",
            "appending 0.0 0.0\n",
            "appending 0.6713867895388712 0.5864574973831677\n",
            "appending last 4.635617089114912 52.15361924162119\n",
            "appending 0.0 0.0\n",
            "appending 0.9433058810172111 0.45333615139209943\n",
            "appending last 5.928479655168646 28.792360097775937\n",
            "appending 0.851777850397078 0.9969778020605324\n",
            "appending last 4.71238898038469 69.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7451785983640877 0.6568716775442092\n",
            "appending last 4.71238898038469 12.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.3464693706269015 78.64477096412705\n",
            "appending 0.0 0.0\n",
            "appending last 3.3086944535208986 84.17244204607586\n",
            "appending 0.0 0.0\n",
            "appending 0.5 0.3838383838383838\n",
            "appending last 3.141592653589793 39.0\n",
            "appending 0.0 0.0\n",
            "appending 0.5803511828757044 0.8670017513572691\n",
            "appending last 4.1795450927653 90.55385138137417\n",
            "appending 0.0 0.0\n",
            "appending 0.5856606442907979 0.7781014616120971\n",
            "appending last 3.9269908169872414 5.656854249492381\n",
            "appending 0.8735865829573994 0.9952444874428396\n",
            "appending last 4.71238898038469 60.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.7926693750342726 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.5909311840891878 0.9985848672985801\n",
            "appending last 3.141592653589793 41.0\n",
            "appending 0.0 0.0\n",
            "appending 0.019197853108401892 0.9972183922380603\n",
            "appending 0.021814759172161722 0.2856016397637262\n",
            "appending 0.0 0.26262626262626265\n",
            "appending last 5.81953769817878 6.708203932499369\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7400657378472295 0.15183050042304444\n",
            "appending last 4.631917969119229 62.20128616033595\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.85249070478132 78.77182237323191\n",
            "appending 0.0 0.0\n",
            "appending 0.27304762491621354 0.4798760741670668\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.024385409172718538 41.012193308819754\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending 0.17620819117478337 0.5319760753534843\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.17888281235710618 0.5275346821079299\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 6.237762027758009 66.06814663663572\n",
            "appending 0.0 0.0\n",
            "appending last 2.7522759317566523 84.30895563343196\n",
            "appending 0.0 0.0\n",
            "appending 0.5 0.3838383838383838\n",
            "appending last 3.141592653589793 39.0\n",
            "appending 0.7932507606327385 0.996537626531192\n",
            "appending last 4.504892753949487 19.4164878389476\n",
            "appending last 4.589957493878781 42.98844119515143\n",
            "appending 0.0 0.0\n",
            "appending 0.375 0.647008321910731\n",
            "appending last 3.141592653589793 22.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending last 5.421827330493308 33.38922590641749\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.1306414284357031 0.9976234669110488\n",
            "appending last 1.5707963267948966 65.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7329260398343148 0.6502609748962082\n",
            "appending last 4.71238898038469 13.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7145035189210943 0.9945814259281986\n",
            "appending last 4.71238898038469 47.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.571850991094707 0.36034587516954036\n",
            "appending last 3.5922539796704265 34.438350715445125\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.7693267345446344 0.9905337463556769\n",
            "appending last 4.71238898038469 65.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 0.3964412832184413 46.61544808322666\n",
            "appending 0.0 0.0\n",
            "appending 0.7866405853116858 0.6538819567492846\n",
            "appending last 4.71238898038469 13.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7348879665805402 0.20298003141140392\n",
            "appending last 3.7345952154713187 55.47071299343465\n",
            "appending 0.0 0.0\n",
            "appending last 3.154250205423845 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 5.434807481349194 78.64477096412705\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7473027168581134 0.5859441814921992\n",
            "appending last 4.71238898038469 19.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.289828596529204 78.77182237323191\n",
            "appending last 5.634254715925578 70.60103452775314\n",
            "appending 0.0 0.0\n",
            "appending last 4.064797914846708 97.8008179924892\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7459199980155949 0.3839678626895184\n",
            "appending last 4.71238898038469 24.0\n",
            "appending 0.0 0.0\n",
            "appending 0.5032476092441872 0.484951545650216\n",
            "appending last 3.5860118634908917 23.259406699226016\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 5.957543721836299 81.27115109311545\n",
            "appending 0.0 0.0\n",
            "appending last 5.949483130642036 79.37883848986453\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.3315809415085087 79.42921376924235\n",
            "appending last 4.2487413713838835 17.88854381999832\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.38525384996236467 0.4336541946765413\n",
            "appending last 3.141592653589793 23.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.892546881191539 79.05694150420949\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.586476354698892 79.63039620647382\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.243123452958928 79.60527620704548\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.6622013826493086 0.45245467239819437\n",
            "appending last 4.690653273542897 46.010868281309364\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.741968695566054 0.9911735577007081\n",
            "appending last 4.71238898038469 25.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.8384695869973757 0.774728624502255\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.9371670418109987 0.3838383838383838\n",
            "appending last 5.886105861954604 33.61547262794322\n",
            "appending 0.0 0.0\n",
            "appending 0.6549563829654517 0.2952771001582015\n",
            "appending last 3.8131988098435334 49.8196748283246\n",
            "appending 0.0 0.0\n",
            "appending last 3.154250205423845 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.9610104348113153 0.4480218371898411\n",
            "appending last 5.176036589385496 24.596747752497688\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.9068598064801858 0.9956471869005357\n",
            "appending last 5.20633034930427 59.0592922409336\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8438045692954366 0.9984457739657798\n",
            "appending last 5.81953769817878 29.068883707497267\n",
            "appending 0.7720376002929961 0.9961631479813887\n",
            "appending last 4.71238898038469 27.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.736767661970205 0.9933652047983479\n",
            "appending last 4.649970170388732 16.0312195418814\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.31793364398966 79.05694150420949\n",
            "appending 0.0 0.0\n",
            "appending last 4.584879422169451 78.63841300535\n",
            "appending 0.0 0.0\n",
            "appending 0.0 0.3838383838383838\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.8104048115259257 79.02531240052139\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 5.425187690051644 77.98717843338096\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.649759424210441 79.40403012442127\n",
            "appending 0.9477780967815204 0.992904370691427\n",
            "appending last 0.0 29.0\n",
            "appending 0.0 0.0\n",
            "appending 0.26380483535586197 0.689498770542335\n",
            "appending last 1.5707963267948966 6.0\n",
            "appending 0.0 0.0\n",
            "appending 0.2681841410647057 0.610104300323586\n",
            "appending last 1.5707963267948966 8.0\n",
            "appending 0.0 0.0\n",
            "appending 0.2742948951737645 0.5213311692107436\n",
            "appending last 1.5707963267948966 9.0\n",
            "appending 0.0 0.0\n",
            "appending 0.2880748916779995 0.41618076456584224\n",
            "appending last 1.5707963267948966 10.0\n",
            "appending 0.0 0.0\n",
            "appending 0.4394405292045783 0.09869019812392937\n",
            "appending last 3.141592653589793 1.0\n",
            "appending 0.0 0.0\n",
            "appending 0.5056816902469089 0.27290759042670504\n",
            "appending last 3.1841201882095773 47.042533945356304\n",
            "appending 0.8142911723802325 0.6966109542056109\n",
            "appending 0.75 0.29292929292929293\n",
            "appending last 4.647263817050304 46.09772228646444\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7400657378472295 0.15183050042304444\n",
            "appending last 4.647962140959136 31.064449134018133\n",
            "appending 0.0 0.0\n",
            "appending last 3.5431731936986726 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.9181414904709837 79.90619500389191\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.8517751804027551 0.9927689994165423\n",
            "appending 0.75 0.29292929292929293\n",
            "appending last 5.26669647658624 74.09453421137081\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.9841372412847232 0.29444067538750174\n",
            "appending last 6.170034325589102 44.28317965096906\n",
            "appending 0.0 0.0\n",
            "appending last 1.9379701606131159 83.57032966310472\n",
            "appending 0.0 0.0\n",
            "appending last 1.590793660768047 50.00999900019995\n",
            "appending 0.0 0.0\n",
            "appending 0.861888508524879 0.771080052565063\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.416883044626907 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 6.065891876256565 78.85429601486528\n",
            "appending last 0.08902485308088369 59.98755646699637\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.124386376837123 79.32212806020776\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.9528458348113064 0.9932094983304256\n",
            "appending 0.0 0.10101010101010101\n",
            "appending last 6.17252808600569 9.055385138137417\n",
            "appending 0.0 0.0\n",
            "appending 0.6840878025667985 0.9939719117551948\n",
            "appending last 4.71238898038469 31.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.5713549326864813 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending 0.818819834913422 0.13452344508359954\n",
            "appending 0.0 1.0\n",
            "appending 0.0 0.25252525252525254\n",
            "appending 0.0 1.0\n",
            "appending last 0.0 40.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.85249070478132 78.77182237323191\n",
            "appending 0.8924453486221989 0.9964840867994206\n",
            "appending last 5.928479655168646 28.792360097775937\n",
            "appending 0.9041844382997477 0.988737719767265\n",
            "appending last 6.200044075291145 36.124783736376884\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 5.158992785390498 78.7210264160726\n",
            "appending 0.0 0.0\n",
            "appending last 5.961434752782944 79.05694150420949\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.1306414284357031 0.9976234669110488\n",
            "appending last 1.5707963267948966 65.0\n",
            "appending 0.0 0.0\n",
            "appending 0.32968374326038735 0.600153837050231\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.024385409172718538 41.012193308819754\n",
            "appending last 4.935581186197152 25.977690556124898\n",
            "appending 0.0 0.0\n",
            "appending 0.9497991051417792 0.9992926816447978\n",
            "appending last 0.0 9.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.745210829256566 0.9970890104040495\n",
            "appending last 4.71238898038469 6.0\n",
            "appending 0.7309922932031797 0.6681307161347821\n",
            "appending last 3.141592653589793 22.0\n",
            "appending 0.6788828123571061 0.6619436051601649\n",
            "appending last 3.141592653589793 33.0\n",
            "appending last 3.686752954650643 87.42238357512693\n",
            "appending 0.0 0.0\n",
            "appending last 3.1289351017557414 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 5.022091924927146 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.9269908169872414 45.254833995939045\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7473027168581134 0.5859441814921992\n",
            "appending last 4.71238898038469 19.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.125 0.9898479733951178\n",
            "appending 0.25 0.3939393939393939\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.25 0.0\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.7853981633974483 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.8411722713031811 0.9915559222948623\n",
            "appending last 4.71238898038469 37.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 5.632108585735106 79.20227269466452\n",
            "appending 0.9029227790211712 0.4366149946744362\n",
            "appending last 5.900108241642578 72.2357252334328\n",
            "appending 0.0 0.0\n",
            "appending 0.18408780256679852 0.9939719117551948\n",
            "appending last 1.5707963267948966 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.169846701428803 99.92497185388645\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.9181414904709837 79.90619500389191\n",
            "appending 0.0 0.0\n",
            "appending last 6.09319701926087 79.42921376924235\n",
            "appending last 2.4498424163090444 64.2748006609122\n",
            "appending last 3.914942835075364 19.56470034855725\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 5.649759424210441 79.40403012442127\n",
            "appending last 6.167758633174625 92.61629340944559\n",
            "appending 0.0 0.0\n",
            "appending last 0.028563657838759995 35.014282800023196\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.338891834278212 79.47955712005447\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.803048867585435 88.36288813749809\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.522400692465974 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending 0.7959918649323241 0.7697074369946982\n",
            "appending last 4.71238898038469 13.0\n",
            "appending 0.8809001801617545 0.8410356005769437\n",
            "appending last 0.0 49.0\n",
            "appending 0.0 0.0\n",
            "appending last 6.09319701926087 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending last 4.124386376837123 79.32212806020776\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.77559581228215 79.1580697086532\n",
            "appending 0.0 0.0\n",
            "appending 0.7213754264756499 0.10283171603534291\n",
            "appending last 4.524167475079919 64.13267497929586\n",
            "appending 0.0 0.0\n",
            "appending 0.5314164790945005 0.04140423751103823\n",
            "appending last 4.285761487257814 12.083045973594572\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.28326703456723157 0.3306490463319798\n",
            "appending last 0.0 0.0\n",
            "appending 0.834848740529379 0.9985627400968282\n",
            "appending last 3.7934617678953697 47.80167361086848\n",
            "appending 0.0 0.0\n",
            "appending 0.6101884475509457 0.527914100427708\n",
            "appending last 3.8414855233090366 24.839484696748443\n",
            "appending 0.0 0.0\n",
            "appending 0.6125427610845983 0.7206705958660979\n",
            "appending last 3.9269908169872414 5.656854249492381\n",
            "appending 0.0 0.0\n",
            "appending last 4.902377268303406 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending 0.125 0.9898479733951178\n",
            "appending last 1.39408747072486 28.442925306655784\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7258271561390366 0.9913263968245742\n",
            "appending last 4.71238898038469 39.0\n",
            "appending 0.0 0.0\n",
            "appending 0.5794734990721255 0.11646428369840069\n",
            "appending last 3.6531487807600986 65.36818798161687\n",
            "appending 0.0 0.0\n",
            "appending last 4.31080844027581 79.30952023559341\n",
            "appending last 5.876263479022173 80.85210263190439\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 5.4887783784917215 78.49203781276162\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.417451921535883 82.56512580987206\n",
            "appending 0.0 0.0\n",
            "appending 0.2942927663914524 0.21050838048324802\n",
            "appending last 3.141592653589793 70.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.920591153202733 0.651343792840836\n",
            "appending last 6.266793332871581 61.00819617067857\n",
            "appending last 3.6109873257538028 97.27056337865017\n",
            "appending 0.0 0.0\n",
            "appending last 4.827265585801589 78.5175139698144\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6857286320100915 75.02666192761077\n",
            "appending 0.0 0.0\n",
            "appending last 1.2087089191011682 70.57619995437555\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending 0.6533221895757967 0.9986354419371036\n",
            "appending last 4.71238898038469 66.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 6.09319701926087 79.42921376924235\n",
            "appending 0.8803690799505748 0.9957771015125382\n",
            "appending last 4.817265919114924 38.2099463490856\n",
            "appending 0.0 0.0\n",
            "appending last 4.85249070478132 78.77182237323191\n",
            "appending 0.0 0.0\n",
            "appending 0.8155195292364673 0.7724502605352148\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7195215548949677 0.998230773802461\n",
            "appending last 4.71238898038469 7.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7292197606124342 0.998483710413464\n",
            "appending last 4.71238898038469 19.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7167329654327685 0.3306490463319798\n",
            "appending last 4.71238898038469 45.0\n",
            "appending 0.9655453782078179 0.9931134551562978\n",
            "appending last 0.0 9.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending 0.7329260398343148 0.6502609748962082\n",
            "appending last 4.71238898038469 13.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.741631145821713 0.182083814044853\n",
            "appending last 4.644695957690721 59.135437767890075\n",
            "appending 0.0 0.0\n",
            "appending last 4.702288313799368 99.00505037623081\n",
            "appending 0.0 0.0\n",
            "appending last 4.003762708257019 82.97590011563598\n",
            "appending 0.0 0.0\n",
            "appending last 4.124386376837123 79.32212806020776\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.736767661970205 0.9933652047983479\n",
            "appending last 4.649970170388732 16.0312195418814\n",
            "appending 0.9612045261091117 0.99434020412785\n",
            "appending last 0.0 28.0\n",
            "appending 0.9019678326740447 0.9922994618875379\n",
            "appending last 0.0 35.0\n",
            "appending 0.9004329815733999 0.996120818102064\n",
            "appending 0.07379180882521663 0.012485535126260503\n",
            "appending 0.0 0.35353535353535354\n",
            "appending last 0.0 0.0\n",
            "appending 0.8995316071025752 0.9940145432621549\n",
            "appending 0.0 0.04040404040404041\n",
            "appending last 6.0169332580286605 45.60701700396552\n",
            "appending 0.9508014933887665 0.8753008145183725\n",
            "appending last 1.5707963267948966 33.0\n",
            "appending 0.0 0.0\n",
            "appending 0.5149703104443706 0.5276295617861076\n",
            "appending 0.5 0.09090909090909091\n",
            "appending 0.4326280007657872 0.9980789813760941\n",
            "appending last 3.141592653589793 51.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.02531104914284831 79.02531240052139\n",
            "appending 0.0 0.0\n",
            "appending 0.7085238411718402 0.30351868073252575\n",
            "appending 0.75 0.4444444444444444\n",
            "appending 0.0 0.1414141414141414\n",
            "appending 0.07172497770608134 0.33776111833782957\n",
            "appending 0.25 0.6262626262626263\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.38608586971786046 0.2977727404874378\n",
            "appending 0.4823883562613614 0.9960528941364807\n",
            "appending last 3.141592653589793 11.0\n",
            "appending 0.0 0.0\n",
            "appending last 2.3889696345964206 86.31338250816034\n",
            "appending 0.0 0.0\n",
            "appending 0.008031304433946012 0.9911735577007081\n",
            "appending last 0.0 10.0\n",
            "appending 0.0 0.0\n",
            "appending last 2.9319528077155805 96.1041102138717\n",
            "appending 0.0 0.0\n",
            "appending 0.11910806556482931 0.18287851691457374\n",
            "appending last 1.5707963267948966 5.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7258271561390366 0.9913263968245742\n",
            "appending last 4.71238898038469 16.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.9420314226698245 79.07591289387686\n",
            "appending 0.0 0.0\n",
            "appending 0.7200436170345483 0.2058339224892116\n",
            "appending last 4.659805918773748 57.07889277132134\n",
            "appending 0.0 0.0\n",
            "appending 0.8888715110717317 0.7283788576337067\n",
            "appending last 5.497787143782138 4.242640687119285\n",
            "appending 0.0 0.0\n",
            "appending last 4.674432535196376 79.05694150420949\n",
            "appending 0.8893779906687258 0.9993211102426436\n",
            "appending last 5.327051932306855 62.42595614005443\n",
            "appending 0.9000021122605502 0.9980962299194225\n",
            "appending last 6.045650675283974 97.74456506629922\n",
            "appending 0.0 0.0\n",
            "appending 0.45107617265854494 0.6575597119054845\n",
            "appending 0.5 1.0\n",
            "appending last 3.141592653589793 2.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 4.633106368143473 78.9145597762744\n",
            "appending 0.0 0.0\n",
            "appending 0.17620819117478337 0.5319760753534843\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.17888281235710618 0.5275346821079299\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.18160120892732332 0.5232476275734984\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.338891834278212 79.47955712005447\n",
            "appending 0.0 0.0\n",
            "appending 0.38608586971786046 0.2977727404874378\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.1585401833961977 59.00847396772772\n",
            "appending 0.0 0.0\n",
            "appending 0.0802405049080853 0.9935653633340926\n",
            "appending last 0.0 35.0\n",
            "appending 0.0 0.0\n",
            "appending 0.4513178656285476 0.9962049921803674\n",
            "appending last 3.141592653589793 17.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 5.187399736649787 78.71467461661771\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.7123088331579915 0.9909020900568464\n",
            "appending last 4.71238898038469 20.0\n",
            "appending last 0.14897531244730608 96.56963558669752\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.8893779906687258 0.9993211102426436\n",
            "appending last 0.0 12.0\n",
            "appending 0.9217387219913183 0.9953967077715232\n",
            "appending last 0.0 13.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8314589678824449 0.9592335161353929\n",
            "appending last 4.71238898038469 61.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.737700029527538 79.02531240052139\n",
            "appending 0.7984607667678667 0.9922348619323899\n",
            "appending last 4.71238898038469 47.0\n",
            "appending last 3.9513138422893506 46.03448468977597\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.917947827056783 0.3382008010013468\n",
            "appending last 5.776086802787249 30.886890422961002\n",
            "appending 0.0 0.0\n",
            "appending 0.9973027168581134 0.5859441814921992\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.9232056239896148 0.46881897337897765\n",
            "appending last 5.755110858753227 27.784887978899608\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.6568598064801858 0.9956471869005357\n",
            "appending last 4.71238898038469 25.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7516075710155771 0.9899500038003113\n",
            "appending last 4.71238898038469 13.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.522400692465974 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.9378962789392963 0.7953982606215784\n",
            "appending last 3.506794103377966 72.80109889280519\n",
            "appending last 4.336722453681485 41.565290982288104\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.522400692465974 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending 0.7258271561390366 0.9913263968245742\n",
            "appending last 4.71238898038469 67.0\n",
            "appending 0.0 0.0\n",
            "appending last 6.053542864894451 79.07591289387686\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 5.614373149243454 79.02531240052139\n",
            "appending 0.0 0.0\n",
            "appending 0.0 0.18181818181818182\n",
            "appending last 6.258190513560666 40.01249804748511\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8309953274850953 0.30605798400430123\n",
            "appending last 3.141592653589793 2.0\n",
            "appending last 4.441896214593768 98.23869523144602\n",
            "appending 0.0 0.0\n",
            "appending 0.7789103092013613 0.9963570672388808\n",
            "appending last 4.71238898038469 20.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7617677633307189 0.5368479341689246\n",
            "appending 0.75 0.25252525252525254\n",
            "appending last 4.643532491083645 29.068883707497267\n",
            "appending 0.0 0.0\n",
            "appending last 4.902377268303406 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending 0.5374033558189214 0.7273419090280395\n",
            "appending last 3.3389882134396736 5.0990195135927845\n",
            "appending last 4.174802333725943 60.53924347066124\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.1306414284357031 0.9976234669110488\n",
            "appending last 1.5707963267948966 65.0\n",
            "appending 0.0 0.0\n",
            "appending 0.00993426215277042 0.31376201094709893\n",
            "appending last 0.0 2.0\n",
            "appending 0.0 0.0\n",
            "appending 0.011348935499930213 0.2734478555074384\n",
            "appending last 0.0 3.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.5431731936986726 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 3.8221138782570074 81.05553651663777\n",
            "appending 0.0 0.0\n",
            "appending 0.5 0.3838383838383838\n",
            "appending last 3.141592653589793 16.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7450280260882054 0.6366792159023079\n",
            "appending last 4.71238898038469 14.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.7721113469176799 0.9928285292770967\n",
            "appending last 4.71238898038469 54.0\n",
            "appending 0.7721113503048088 0.9928283766329825\n",
            "appending last 4.71238898038469 36.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 6.00008952188009 57.28001396647874\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 3.358886084512814 78.85429601486528\n",
            "appending last 3.739351045182875 28.429737951659\n",
            "appending 0.0 0.0\n",
            "appending 0.2670739601656852 0.6502609748962082\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.6462036960756424 0.6889151626988265\n",
            "appending last 4.45983470460663 32.01562118716424\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7400657378472295 0.15183050042304444\n",
            "appending last 4.631917969119229 62.20128616033595\n",
            "appending 0.8610483473881199 0.9960924079095953\n",
            "appending last 4.986556431504349 33.24154027718932\n",
            "appending 0.0 0.0\n",
            "appending 0.014428969188152238 0.9940227187341955\n",
            "appending last 0.0 65.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.124386376837123 79.32212806020776\n",
            "appending 0.0 0.0\n",
            "appending 0.9610104348113153 0.07319405304278102\n",
            "appending last 4.71238898038469 31.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.560623825056986 85.98837130682264\n",
            "appending 0.0 0.0\n",
            "appending last 5.261541883063701 78.54934754662193\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7318894395787306 0.34573565563249564\n",
            "appending last 4.642734406656121 43.104524124504614\n",
            "appending 0.9698936282053545 0.9926344765698494\n",
            "appending last 0.0 22.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.8650657378472295 0.44791046661634887\n",
            "appending last 5.081722638058315 33.24154027718932\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8018797244397596 0.9992814990441\n",
            "appending last 4.71238898038469 26.0\n",
            "appending 0.9173753297307161 0.8857054063766064\n",
            "appending last 0.0 7.0\n",
            "appending 0.9124491350833263 0.8400693579109799\n",
            "appending last 0.0 7.0\n",
            "appending 0.2559655173521404 0.05728636341949385\n",
            "appending last 3.141592653589793 46.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 5.3458148633538345 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.313328031808556 90.07774419910837\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.807100125609954 0.7666266031096746\n",
            "appending last 4.71238898038469 1.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7516075710155771 0.9899500038003113\n",
            "appending last 4.71238898038469 61.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.258031304433946 0.9911735577007081\n",
            "appending 0.25 0.1717171717171717\n",
            "appending last 3.141592653589793 40.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.9477780967815204 0.4914016802952085\n",
            "appending last 5.961434752782944 28.460498941515414\n",
            "appending 0.0 0.0\n",
            "appending 0.43858486571180094 0.33878618260950594\n",
            "appending 0.5 1.0\n",
            "appending last 3.141592653589793 22.0\n",
            "appending 0.0 0.0\n",
            "appending 0.1068894395787306 0.9963570672388808\n",
            "appending 0.0 1.0\n",
            "appending last 0.0 4.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.7750185365589375 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.8120573554444281 0.7871112534293189\n",
            "appending last 4.71238898038469 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.9804997634545165 94.37160589923221\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 5.842005826764606 79.62411694957753\n",
            "appending 0.0 0.0\n",
            "appending last 0.028563657838759995 35.014282800023196\n",
            "appending 0.929371762591932 0.9936928023951295\n",
            "appending last 0.0 6.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.5431731936986726 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.5549968787625692 0.25828950011285706\n",
            "appending last 3.438656865930836 51.24451190127583\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.9181414904709837 79.90619500389191\n",
            "appending 0.0 0.0\n",
            "appending 0.9765138120078405 0.7455868733037612\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.848576284438114 0.9947369198066359\n",
            "appending last 4.743148506455158 65.03076195155643\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7400657378472295 0.15183050042304444\n",
            "appending last 4.631917969119229 62.20128616033595\n",
            "appending 0.0 0.0\n",
            "appending 0.436904410130091 0.4607621018507743\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.154250205423845 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7195215548949677 0.998230773802461\n",
            "appending last 4.71238898038469 23.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7094539568736273 0.9919375201973155\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.481986544325828 83.19855767980596\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.398157081300351 84.11896337925236\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.7990626954280319 0.9969683039006403\n",
            "appending last 4.671870627906342 74.06078584514209\n",
            "appending last 4.2932462650925345 36.85707204180035\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 5.448646409366118 86.37129152675674\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.741631145821713 0.182083814044853\n",
            "appending last 4.643532491083645 29.068883707497267\n",
            "appending 0.0 0.0\n",
            "appending 0.5024865936394751 0.6364425456891014\n",
            "appending last 3.522099030702158 5.385164807134504\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8261670756383909 0.9988770869358636\n",
            "appending last 4.71238898038469 52.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 67.0\n",
            "appending 0.0 0.0\n",
            "appending 0.3165624693738283 0.18886581417769907\n",
            "appending last 3.141592653589793 13.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.9941608476580415 79.12016177940993\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.3989163685608816 78.587530817554\n",
            "appending 0.0 0.0\n",
            "appending 0.27304762491621354 0.4798760741670668\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.024385409172718538 41.012193308819754\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending 0.5 0.3838383838383838\n",
            "appending last 3.141592653589793 39.0\n",
            "appending 0.0 0.0\n",
            "appending 0.8489994699946852 0.6486366559870856\n",
            "appending last 4.71238898038469 40.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.1669037027326414 79.02531240052139\n",
            "appending 0.0 0.0\n",
            "appending 0.6127813740139012 0.36240583665829845\n",
            "appending last 3.8581343276861966 41.10960958218893\n",
            "appending 0.0 0.0\n",
            "appending last 3.5431731936986726 79.30952023559341\n",
            "appending last 3.9161721690674427 38.12707545011154\n",
            "appending last 5.712832599647648 86.43113300481306\n",
            "appending 0.862305889697904 0.9984109476571902\n",
            "appending last 5.264043962913236 45.79301256742124\n",
            "appending 0.0 0.0\n",
            "appending 0.8293094218693339 0.7718633225439154\n",
            "appending last 4.71238898038469 1.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.6754944966622736 0.9972690354799585\n",
            "appending last 4.71238898038469 33.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.759972083661673 84.09518416651456\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7773364771100956 0.9945814259281986\n",
            "appending last 4.71238898038469 59.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.8413018859260208 0.7716023197553881\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7977108433770743 0.5713873925100709\n",
            "appending 0.75 0.30303030303030304\n",
            "appending last 4.647263817050304 46.09772228646444\n",
            "appending 0.0 0.0\n",
            "appending last 6.105589139896098 79.2464510246358\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.0 0.0\n",
            "appending 0.3156371603629356 0.3427121049812723\n",
            "appending last 1.5707963267948966 44.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7459199980155949 0.3839678626895184\n",
            "appending last 4.71238898038469 24.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.154250205423845 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.5917329654327684 0.4717923410859218\n",
            "appending last 3.710905844690455 29.68164415931166\n",
            "appending 0.9319790413409861 0.9971681088132147\n",
            "appending last 0.0 24.0\n",
            "appending 0.9048637972033001 0.9949907356647121\n",
            "appending last 0.0 40.0\n",
            "appending 0.9342485042091099 0.9962842008075341\n",
            "appending last 0.0 39.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.26486900522752 83.19254774317228\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.30120819117478337 0.5968007630626182\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 4.82853060726468 15.101738310538956\n",
            "appending 0.0 0.0\n",
            "appending 0.36057103081184777 0.6999216877086858\n",
            "appending last 2.356194490192345 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending 0.5838153334156787 0.994733746702698\n",
            "appending last 3.141592653589793 14.0\n",
            "appending 0.862305898955352 0.9984109976351323\n",
            "appending 0.8002008948582208 0.9992926816447978\n",
            "appending last 4.71238898038469 19.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.8379412343527437 79.51100552753688\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 0.028563657838759995 35.014282800023196\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.0 0.0\n",
            "appending 0.9610104348113153 0.23978417933036325\n",
            "appending last 6.0288172486263205 51.66236541235796\n",
            "appending 0.0 0.0\n",
            "appending last 0.9652516631899266 79.05694150420949\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.637705336833058 0.34816460304986263\n",
            "appending last 4.676689867705366 56.0357029044876\n",
            "appending 0.9097510258795084 0.9928283999176788\n",
            "appending last 0.0 18.0\n",
            "appending 0.938797090006303 0.9951316975093715\n",
            "appending last 0.0 14.0\n",
            "appending 0.9405778682550021 0.9960870290428913\n",
            "appending last 0.0 6.0\n",
            "appending 0.9402851157415435 0.9913861628813171\n",
            "appending last 0.0 2.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.849455154694877 87.82368700982668\n",
            "appending 0.0 0.0\n",
            "appending 0.2901952613890719 0.31328910290064893\n",
            "appending last 3.141592653589793 62.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7329260398343148 0.6502609748962082\n",
            "appending last 4.71238898038469 13.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.358886084512814 78.85429601486528\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.338891834278212 79.47955712005447\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.9945140721919945 0.2830023864352911\n",
            "appending last 6.233226911457644 40.049968789001575\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.9269908169872414 45.254833995939045\n",
            "appending 0.8428467155931273 0.9984554379612443\n",
            "appending 0.8509078498670006 0.41618076456584224\n",
            "appending last 4.71238898038469 21.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.649182148487229 79.1580697086532\n",
            "appending 0.0 0.0\n",
            "appending last 4.676260129871914 83.05419917138447\n",
            "appending 0.0 0.0\n",
            "appending 0.7226635228899044 0.9945814259281986\n",
            "appending last 4.71238898038469 11.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.5105946523174733 0.14175046846841322\n",
            "appending 0.6431105604212694 0.9963570672388808\n",
            "appending last 4.71238898038469 18.0\n",
            "appending 0.0 0.0\n",
            "appending 0.809029181964259 0.770230622861736\n",
            "appending last 4.71238898038469 1.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 39.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 69.0\n",
            "appending 0.848576284438114 0.9947369198066359\n",
            "appending last 5.050267168624968 39.21734310225516\n",
            "appending 0.0 0.0\n",
            "appending 0.584750659461432 0.6464646464646465\n",
            "appending last 4.255110712002547 70.21395872616783\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.7749656591616902 0.9921029686472662\n",
            "appending last 3.529911371762259 23.769728648009426\n",
            "appending last 4.516997425868117 97.86214794290998\n",
            "appending 0.0 0.0\n",
            "appending 0.7691978531084018 0.9972183922380603\n",
            "appending last 4.71238898038469 27.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.9347262064556886 0.4965630789488668\n",
            "appending last 5.8686784325948 27.313000567495326\n",
            "appending 0.8429258595946463 0.8373648583105977\n",
            "appending last 4.71238898038469 63.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.85249070478132 78.77182237323191\n",
            "appending 0.0 0.0\n",
            "appending 0.8625079121814784 0.6275440041247123\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 6.263187973206436 50.00999900019995\n",
            "appending last 6.060015240692385 96.39041041316331\n",
            "appending 0.0 0.0\n",
            "appending last 3.5437066692415558 94.54099639838793\n",
            "appending 0.0 0.0\n",
            "appending 0.32797913037736937 0.16161616161616163\n",
            "appending last 3.141592653589793 1.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.4876550949064553 96.33275663033837\n",
            "appending 0.7933133637201844 0.8917783549717057\n",
            "appending last 4.41389004879851 68.00735254367721\n",
            "appending 0.7080443549902562 0.9977809023823171\n",
            "appending last 3.141592653589793 14.0\n",
            "appending 0.774882405653916 0.9954287190137822\n",
            "appending last 4.71238898038469 36.0\n",
            "appending 0.7927246041911803 0.9991088529101527\n",
            "appending last 0.0 0.0\n",
            "appending 0.7927246041911803 0.9991088529101527\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 5.785842590832764 79.64923100695951\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.800765766529539 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.687077931241841 79.02531240052139\n",
            "appending last 5.815704134353732 68.05150443893166\n",
            "appending 0.7270954666554751 0.993540250731501\n",
            "appending last 4.71238898038469 6.0\n",
            "appending last 4.487654553453896 99.84407487503671\n",
            "appending 0.0 0.0\n",
            "appending last 4.87194070131795 88.11923740024082\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8018797322220657 0.9992813530312727\n",
            "appending last 3.912907241164381 50.20956084253277\n",
            "appending 0.8072875871759034 0.9936161908920942\n",
            "appending last 4.71238898038469 48.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8371030060803083 0.9992815381179565\n",
            "appending last 4.849455154694877 58.54912467321779\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.689128934551077 0.788327759761749\n",
            "appending last 3.141592653589793 17.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.7001919689333556 94.33981132056604\n",
            "appending 0.7047684401828452 0.9895960412450225\n",
            "appending last 3.4633432079864352 3.1622776601683795\n",
            "appending 0.7452646435583131 0.8387595368323397\n",
            "appending 0.5 0.6161616161616161\n",
            "appending last 3.4972285378905528 37.33630940518894\n",
            "appending 0.862305898955352 0.9984109976351323\n",
            "appending 0.0 1.0\n",
            "appending 0.0 1.0\n",
            "appending last 0.0 24.0\n",
            "appending 0.0 0.0\n",
            "appending last 6.168308701762687 78.5175139698144\n",
            "appending 0.0 0.0\n",
            "appending 0.28326703456723157 0.3306490463319798\n",
            "appending last 1.5707963267948966 10.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.7821470245015126 0.9969031208424616\n",
            "appending last 4.193242866138167 64.4980619863884\n",
            "appending last 2.0106389096106327 18.788294228055936\n",
            "appending 0.8044866723201273 0.9978892086986548\n",
            "appending 0.6531240879316607 0.39620576487108616\n",
            "appending 0.5 0.1414141414141414\n",
            "appending last 2.0344439357957027 2.23606797749979\n",
            "appending 0.0 0.0\n",
            "appending 0.6564164790945007 0.09915811945850474\n",
            "appending 0.5 0.1414141414141414\n",
            "appending last 2.0344439357957027 2.23606797749979\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 4.604534502378875 95.21996240692881\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.9604165758394345 0.6464646464646465\n",
            "appending last 6.0169332580286605 11.40175425099138\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8297276800873254 0.9994666602502308\n",
            "appending last 4.71238898038469 65.0\n",
            "appending 0.0 0.0\n",
            "appending 0.9275684567112534 0.5184434526040861\n",
            "appending last 5.837079758236182 25.495097567963924\n",
            "appending 0.0 0.0\n",
            "appending 0.39886451508952125 0.9939719117551948\n",
            "appending last 3.141592653589793 58.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 0.15660187698201536 57.706152185014034\n",
            "appending 0.0 0.0\n",
            "appending last 6.263187973206436 50.00999900019995\n",
            "appending 0.0 0.0\n",
            "appending 0.42300416214393516 0.6631144526445104\n",
            "appending last 1.5707963267948966 23.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.368583179294532 86.03487664894976\n",
            "appending 0.0 0.0\n",
            "appending last 4.567347282058084 89.94442728707543\n",
            "appending 0.0 0.0\n",
            "appending last 6.213852173491378 72.17340230306452\n",
            "appending 0.0 0.0\n",
            "appending last 5.31793364398966 79.05694150420949\n",
            "appending 0.0 0.0\n",
            "appending last 5.893267443248734 78.92401408950256\n",
            "appending last 3.22538553245279 63.7235786155422\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7564270069384006 0.9907149002845969\n",
            "appending last 4.71238898038469 47.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.661799271615305 79.1012010022604\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.741631145821713 0.182083814044853\n",
            "appending last 4.643532491083645 29.068883707497267\n",
            "appending 0.0 0.0\n",
            "appending 0.6978926379226605 0.5552849280467285\n",
            "appending last 3.515534573573539 84.86459803710851\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.8698677492611262 0.43296388281740017\n",
            "appending last 5.1888563998583965 34.88552708502482\n",
            "appending 0.0 0.0\n",
            "appending last 5.853423028082898 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.49128789342129836 0.7283788576337067\n",
            "appending last 3.141592653589793 14.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.9737157716443733 0.051341035659577976\n",
            "appending last 6.053953373902591 30.805843601498726\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 2.449258218916763 53.2634959423431\n",
            "appending 0.0 0.0\n",
            "appending 0.5040800019844051 0.3839678626895184\n",
            "appending last 3.1672280621114703 39.01281840626232\n",
            "appending 0.0 0.0\n",
            "appending last 4.687077931241841 79.02531240052139\n",
            "appending 0.0 0.0\n",
            "appending 0.7473027168581134 0.5859441814921992\n",
            "appending last 4.71238898038469 19.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.289828596529204 78.77182237323191\n",
            "appending 0.810286863614319 0.993718143477276\n",
            "appending last 4.71238898038469 23.0\n",
            "appending 0.0 0.0\n",
            "appending 0.16618466658432132 0.994733746702698\n",
            "appending last 1.5707963267948966 31.0\n",
            "appending 0.0 0.0\n",
            "appending 0.75 0.030303030303030304\n",
            "appending last 3.563843807041065 75.64390259630977\n",
            "appending 0.0 0.0\n",
            "appending last 3.154250205423845 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.75446938782658 95.08417323613851\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7691978531084018 0.9972183922380603\n",
            "appending last 4.71238898038469 29.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.42985232390396144 0.5818216292518631\n",
            "appending last 3.141592653589793 19.0\n",
            "appending 0.0 0.0\n",
            "appending 0.5223585047268736 0.9998484734831437\n",
            "appending last 3.141592653589793 18.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.687077931241841 79.02531240052139\n",
            "appending 0.0 0.0\n",
            "appending 0.7400657378472295 0.15183050042304444\n",
            "appending last 4.647962140959136 31.064449134018133\n",
            "appending 0.0 0.0\n",
            "appending 0.9195342759831555 0.6364425456891014\n",
            "appending last 5.755110858753227 13.892443989449804\n",
            "appending 0.0 0.0\n",
            "appending last 6.168308701762687 78.5175139698144\n",
            "appending 0.35708464431663006 0.05878382854964468\n",
            "appending 0.5 1.0\n",
            "appending last 3.141592653589793 28.0\n",
            "appending 0.5064270069384006 0.9907149002845969\n",
            "appending last 3.141592653589793 11.0\n",
            "appending 0.0 0.0\n",
            "appending 0.47272416489233915 0.5229605980589399\n",
            "appending 0.5 1.0\n",
            "appending last 3.141592653589793 25.0\n",
            "appending last 4.66554826746872 16.017568479641348\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.902377268303406 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 5.565353311218637 94.26027795418386\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.1306414284357031 0.9976234669110488\n",
            "appending last 1.5707963267948966 65.0\n",
            "appending last 5.358493844405739 76.81691078218695\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7400657378472295 0.15183050042304444\n",
            "appending last 4.647962140959136 31.064449134018133\n",
            "appending 0.0 0.0\n",
            "appending 0.5051322507388739 0.30319318018728936\n",
            "appending last 3.9269908169872414 32.526911934581186\n",
            "appending 0.0 0.0\n",
            "appending 0.6125427610845983 0.7206705958660979\n",
            "appending last 3.9269908169872414 5.656854249492381\n",
            "appending 0.0 0.0\n",
            "appending 0.5893119309480065 0.40747528502210884\n",
            "appending last 3.691445836266378 36.359317925395686\n",
            "appending 0.8819644629575089 0.9967639132149142\n",
            "appending last 5.5263508016208975 24.758836806279895\n",
            "appending 0.0 0.0\n",
            "appending last 5.524329581533535 79.93122043357026\n",
            "appending 0.9075245185174957 0.9959011534555894\n",
            "appending last 0.0 81.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending last 4.237514848340112 46.47587034128635\n",
            "appending 0.0 0.0\n",
            "appending 0.39035427819904495 0.6572540064306638\n",
            "appending last 3.141592653589793 6.0\n",
            "appending 0.0 0.0\n",
            "appending 0.11777066054861166 0.9336815051958042\n",
            "appending last 0.3120421215625333 32.57299494980466\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.7459199980155949 0.3839678626895184\n",
            "appending last 4.71238898038469 26.0\n",
            "appending 0.0 0.0\n",
            "appending 0.6313628056739959 0.1686041011409508\n",
            "appending 0.5727780967815204 0.6991308962239174\n",
            "appending last 3.5464844398748765 7.615773105863909\n",
            "appending last 4.231044132080051 84.23842276930253\n",
            "appending 0.0 0.0\n",
            "appending last 4.64431252212669 88.20430828479978\n",
            "appending 0.0 0.0\n",
            "appending last 3.5598169831690223 78.79086241436883\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7459199980155949 0.3839678626895184\n",
            "appending last 4.6867535718630124 39.01281840626232\n",
            "appending 0.0 0.0\n",
            "appending last 5.289828596529204 78.77182237323191\n",
            "appending 0.0 0.0\n",
            "appending 0.4677995127491915 0.794182999490682\n",
            "appending last 3.141592653589793 27.0\n",
            "appending 0.0 0.0\n",
            "appending 0.2635125401048904 0.4663626834372022\n",
            "appending last 3.141592653589793 14.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending last 3.8212416251082946 42.42771950480603\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.338891834278212 79.47955712005447\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 5.462088031102814 79.2464510246358\n",
            "appending 0.0 0.0\n",
            "appending 0.20483276469913345 0.494949494949495\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.20790536652690944 0.49221481855177196\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.21021466672721237 0.4798760741670668\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.0380305657279765 81.27115109311545\n",
            "appending 0.0 0.0\n",
            "appending last 6.263187973206436 50.00999900019995\n",
            "appending 0.8360789784543365 0.995360152330004\n",
            "appending 0.0 0.35353535353535354\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.686040299976311 0.4289154305474895\n",
            "appending last 4.343055322711064 33.24154027718932\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.078963097415545 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 5.36346570182917 79.20227269466452\n",
            "appending last 5.813208620630008 94.21488671368367\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 73.0\n",
            "appending last 6.229573129331041 80.86618761768268\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.3464693706269015 78.64477096412705\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 3.9181414904709837 79.90619500389191\n",
            "appending 0.0 0.0\n",
            "appending 0.809029181964259 0.770230622861736\n",
            "appending last 4.71238898038469 1.0\n",
            "appending 0.0 0.0\n",
            "appending 0.436904410130091 0.4607621018507743\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.154250205423845 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 56.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.5883383868522991 57.0087712549569\n",
            "appending 0.0 0.0\n",
            "appending 0.883368854178287 0.39758456708304174\n",
            "appending 0.0 0.45454545454545453\n",
            "appending last 0.8023456932038532 41.72529209005013\n",
            "appending 0.0 0.0\n",
            "appending 0.7079053665269095 0.994530647204554\n",
            "appending last 4.71238898038469 19.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.820255144338106 79.64923100695951\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.8231968542637732 0.9968893167450913\n",
            "appending 0.75 0.3939393939393939\n",
            "appending last 5.149016140198231 33.1058907144937\n",
            "appending 0.0 0.0\n",
            "appending 0.9583470024189555 0.5754962844701311\n",
            "appending last 6.012238456841166 18.681541692269406\n",
            "appending 0.0 0.0\n",
            "appending 0.9618436991510484 0.45782766957173615\n",
            "appending last 6.053953373902591 30.805843601498726\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7459199980155949 0.3839678626895184\n",
            "appending last 4.6867535718630124 39.01281840626232\n",
            "appending 0.0 0.0\n",
            "appending 0.8466778104242033 0.9986354419371036\n",
            "appending last 4.71238898038469 41.0\n",
            "appending 0.0 0.0\n",
            "appending 0.9946967987972323 0.29309759635966937\n",
            "appending last 4.840712208070484 62.51399843235114\n",
            "appending 0.0 0.0\n",
            "appending last 6.238439075724971 67.06713054842886\n",
            "appending 0.0 0.0\n",
            "appending 0.3999239628191567 0.5394533538883007\n",
            "appending 0.375 0.43273353973298934\n",
            "appending 0.5 1.0\n",
            "appending last 3.141592653589793 8.0\n",
            "appending 0.0 0.0\n",
            "appending 0.2533152483999501 0.4748526821881941\n",
            "appending 0.5 1.0\n",
            "appending last 3.141592653589793 8.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.338891834278212 79.47955712005447\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.7758147478686611 0.7404915206430077\n",
            "appending last 4.71238898038469 42.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.827265585801589 78.5175139698144\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.3772164132479565 94.2443632266673\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.825187355582364 79.1580697086532\n",
            "appending 0.8843512796206383 0.9933652047983479\n",
            "appending last 6.192525419978841 44.181444068749045\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.243123452958928 79.60527620704548\n",
            "appending 0.7721113503048088 0.9928283766329825\n",
            "appending last 4.71238898038469 6.0\n",
            "appending last 4.771395747200316 97.50302194112722\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.625 0.13274884468415102\n",
            "appending last 4.434089321379578 65.52098900352466\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.5840456587875813 0.13022670696413943\n",
            "appending last 3.8381166421741333 71.7007670809734\n",
            "appending 0.0 0.0\n",
            "appending last 1.2087089191011682 70.57619995437555\n",
            "appending 0.0 0.0\n",
            "appending last 1.200472897092122 91.18113840043894\n",
            "appending 0.0 0.0\n",
            "appending last 4.917265697421798 78.64477096412705\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 0.028563657838759995 35.014282800023196\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.154250205423845 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.5 0.1111111111111111\n",
            "appending last 3.173839536025047 62.03224967708329\n",
            "appending 0.0 0.0\n",
            "appending last 4.687077931241841 79.02531240052139\n",
            "appending 0.0 0.0\n",
            "appending last 5.4277265611436825 80.8084154033477\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.0 0.0\n",
            "appending 0.0 0.3838383838383838\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7459199980155949 0.3839678626895184\n",
            "appending last 4.6867535718630124 39.01281840626232\n",
            "appending last 4.85131868908152 79.43200894050895\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 5.911941951990579 73.50755450004097\n",
            "appending 0.0 0.0\n",
            "appending 0.6790626822482323 0.9974209499321123\n",
            "appending last 4.71238898038469 2.0\n",
            "appending last 4.47983203857978 78.10249675906654\n",
            "appending 0.0 0.0\n",
            "appending last 4.522400692465974 79.42921376924235\n",
            "appending 0.7800869601280949 0.9977531829657229\n",
            "appending last 4.71238898038469 33.0\n",
            "appending 0.8161276175873858 0.990890507668453\n",
            "appending 0.75 0.020202020202020204\n",
            "appending last 5.371195016502166 39.20459156782532\n",
            "appending 0.0 0.0\n",
            "appending last 4.604377255684644 83.48652585896721\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.8155195292364673 0.7724502605352148\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7459199980155949 0.3839678626895184\n",
            "appending last 4.6867535718630124 39.01281840626232\n",
            "appending 0.0 0.0\n",
            "appending last 4.661799271615305 79.1012010022604\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending 0.7921469870709035 0.6073839077001182\n",
            "appending last 4.71238898038469 29.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7459199980155949 0.3839678626895184\n",
            "appending last 4.6867535718630124 39.01281840626232\n",
            "appending 0.0 0.0\n",
            "appending 0.436904410130091 0.4607621018507743\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.35764341204156047 0.9742682076529507\n",
            "appending last 2.677945044588987 2.23606797749979\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending 0.001607571015577117 0.9899500038003113\n",
            "appending last 0.0 77.0\n",
            "appending 0.8864693836042207 0.9984177392105481\n",
            "appending 0.0 0.24242424242424243\n",
            "appending last 6.233226911457644 40.049968789001575\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.8581559221397814 0.9984671212828756\n",
            "appending last 4.300581675022973 94.93682109698007\n",
            "appending last 4.715566936198805 78.66705373895172\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.2422424934285742 0.40453284347017765\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.1915624693738283 0.13058978057761736\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.961434752782944 79.05694150420949\n",
            "appending 0.0 0.0\n",
            "appending 0.0 0.3838383838383838\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending 0.917947827056783 0.3382008010013468\n",
            "appending last 5.77832393552046 43.41658669218482\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 2.449258218916763 53.2634959423431\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 4.6093073718619895 87.46427842267951\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 1.112643167997307 81.39410298049853\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending last 4.2587913594053965 29.666671238588567\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 4.508991129393229 54.45590445042661\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.125 0.9898479733951178\n",
            "appending 0.14992396281915665 0.12728758089631761\n",
            "appending last 0.4636476090008061 2.23606797749979\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7564270069384006 0.9907149002845969\n",
            "appending last 5.176036589385496 38.01315561749642\n",
            "appending 0.0 0.0\n",
            "appending 0.5122186259860987 0.1216000485899525\n",
            "appending 0.75 0.6262626262626263\n",
            "appending last 5.176036589385496 38.01315561749642\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.7744874306394754 0.995038620694017\n",
            "appending last 3.8984271591484814 24.758836806279895\n",
            "appending 0.7484031813252542 0.9966837206952494\n",
            "appending last 3.30674133100442 36.49657518178932\n",
            "appending 0.8832896846978284 0.9959739506555604\n",
            "appending 0.0 0.3838383838383838\n",
            "appending last 5.798707378142563 42.941821107167776\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.75 1.0\n",
            "appending last 4.71238898038469 8.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.881604767070707 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.358886084512814 78.85429601486528\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.6351450632786287 0.9990399477987907\n",
            "appending last 4.71238898038469 81.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 5.604522816431274 79.64923100695951\n",
            "appending 0.0 0.0\n",
            "appending 0.27304762491621354 0.4798760741670668\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.948845122584607 85.37564055396598\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.629247748496248 84.29116205154607\n",
            "appending 0.0 0.0\n",
            "appending last 5.36346570182917 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.0593628396370644 0.23937553606522158\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.5707963267948966 30.0\n",
            "appending 0.0 0.0\n",
            "appending 0.25467967866082303 0.3334818454887869\n",
            "appending 0.375 0.8898530750455049\n",
            "appending last 3.141592653589793 15.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.5401223214569228 0.6783256247025752\n",
            "appending last 3.360261599463735 9.219544457292887\n",
            "appending 0.7278144110308756 0.9894939747102536\n",
            "appending last 3.4633432079864352 3.1622776601683795\n",
            "appending last 4.5565678630080555 99.87671952829018\n",
            "appending 0.0 0.0\n",
            "appending last 4.522400692465974 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending 0.7028458348113064 0.9932094983304256\n",
            "appending last 4.71238898038469 78.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.6657677587151389 0.610104300323586\n",
            "appending 0.6840878025667985 0.9939719117551948\n",
            "appending last 4.71238898038469 3.0\n",
            "appending 0.0 0.0\n",
            "appending 0.07672520828632091 0.9703215753573885\n",
            "appending 0.0 0.32323232323232326\n",
            "appending last 0.0 0.0\n",
            "appending 0.05272712503447439 0.993994501307664\n",
            "appending 0.0 0.3333333333333333\n",
            "appending last 0.0 0.0\n",
            "appending 0.07117538194627882 0.7684871339630099\n",
            "appending 0.0 0.32323232323232326\n",
            "appending last 0.0 0.0\n",
            "appending 0.07117538194627882 0.7684871339630099\n",
            "appending 0.0 0.32323232323232326\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending 0.826535587713105 0.776027582085223\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 64.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 47.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.022091924927146 78.74642849044012\n",
            "appending 0.85624620482416 0.9974298212716123\n",
            "appending last 5.3503499796542 72.20110802473879\n",
            "appending 0.8971042367414365 0.9959641596586281\n",
            "appending 0.0 0.1717171717171717\n",
            "appending last 6.107245681727059 45.70557952810576\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7473027168581134 0.5859441814921992\n",
            "appending last 4.71238898038469 19.0\n",
            "appending 0.0 0.0\n",
            "appending 0.8138131148078575 0.999242139938247\n",
            "appending last 4.71238898038469 15.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8065367476335246 0.991848421254471\n",
            "appending last 4.71238898038469 64.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 5.050267168624968 78.43468620451031\n",
            "appending 0.0 0.0\n",
            "appending last 4.674432535196376 79.05694150420949\n",
            "appending 0.0 0.0\n",
            "appending last 4.166733925857698 98.2700361249552\n",
            "appending 0.9354007919416258 0.9876294263772577\n",
            "appending last 0.0 64.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.7776383396784692 0.9983321049548165\n",
            "appending last 4.71238898038469 50.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.812340981570262 0.9953427990407518\n",
            "appending last 4.71238898038469 1.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7564270069384006 0.9907149002845969\n",
            "appending last 4.71238898038469 3.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 5.632108585735106 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 0.6688121579361327 79.02531240052139\n",
            "appending 0.0 0.0\n",
            "appending 0.6485309573139301 0.6686988935923814\n",
            "appending last 4.71238898038469 20.0\n",
            "appending 0.0 0.0\n",
            "appending 0.6927124128240966 0.9936161908920942\n",
            "appending last 4.71238898038469 22.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.9090688159108122 0.9985848672985801\n",
            "appending last 0.0 32.0\n",
            "appending 0.0 0.0\n",
            "appending 0.826535587713105 0.776027582085223\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.649182148487229 79.1580697086532\n",
            "appending 0.0 0.0\n",
            "appending 0.8413018859260208 0.7716023197553881\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.8198466267518859 0.5366613576858327\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.158992785390498 78.7210264160726\n",
            "appending 0.0 0.0\n",
            "appending 0.3435835209054994 0.06273840960533311\n",
            "appending last 3.141592653589793 34.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.7886032675417093 0.999242139938247\n",
            "appending 0.757573086094184 0.20226056607705697\n",
            "appending 0.75 0.25252525252525254\n",
            "appending last 4.71238898038469 7.0\n",
            "appending 0.9957248170589872 0.9927860395041158\n",
            "appending last 0.0 13.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.1306414284357031 0.9976234669110488\n",
            "appending last 1.5707963267948966 65.0\n",
            "appending 0.0 0.0\n",
            "appending 0.23488796658054026 0.20298003141140392\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.24242691390581594 0.20226056607705697\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 5.649759424210441 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.8365870806325552 0.9461398017001105\n",
            "appending last 4.71238898038469 14.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.614373149243454 79.02531240052139\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.8413018859260208 0.7716023197553881\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.738418557575494 94.30270409696638\n",
            "appending last 3.848018803426208 41.08130818728267\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.124386376837123 79.32212806020776\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.522400692465974 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 5.842005826764606 79.62411694957753\n",
            "appending 0.0 0.0\n",
            "appending last 0.0 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.36346570182917 79.20227269466452\n",
            "appending last 5.919206350669942 89.88882021697692\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7210896907986387 0.9963570672388808\n",
            "appending last 4.71238898038469 53.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.104586984270729 84.0535543567314\n",
            "appending 0.0 0.0\n",
            "appending 0.0802405049080853 0.9935653633340926\n",
            "appending last 0.0 37.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.021814759172161722 0.2856016397637262\n",
            "appending last 1.0799445463968773 65.76473218982953\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 3.7911420757254493 99.20181449953424\n",
            "appending 0.0 0.0\n",
            "appending last 4.470468411700285 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 74.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.586476354698892 79.63039620647382\n",
            "appending 0.0 0.0\n",
            "appending 0.6899142032318947 0.6201405046386463\n",
            "appending last 4.691983649698152 49.01020301937138\n",
            "appending 0.0 0.0\n",
            "appending 0.7292197606124342 0.998483710413464\n",
            "appending last 4.71238898038469 43.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 4.514993420534809 81.58431221748455\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.625 0.004183975377506011\n",
            "appending last 4.634624040781957 77.23341245859851\n",
            "appending 0.834848740529379 0.9985627400968282\n",
            "appending last 4.71238898038469 41.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.2901952613890719 0.31328910290064893\n",
            "appending last 3.141592653589793 17.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.5608575134116164 0.9915301460447753\n",
            "appending last 3.141592653589793 40.0\n",
            "appending 0.0 0.0\n",
            "appending 0.08163614296200096 0.998483710413464\n",
            "appending last 0.0 100.0\n",
            "appending 0.0 0.0\n",
            "appending 0.9945140721919945 0.2830023864352911\n",
            "appending last 6.233226911457644 40.049968789001575\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 5.65916225420283 46.20876540224809\n",
            "appending 0.0 0.0\n",
            "appending 0.42620819117478337 0.6900818919443786\n",
            "appending last 3.141592653589793 14.0\n",
            "appending 0.0 0.0\n",
            "appending 0.5587812772689674 0.9972183922380603\n",
            "appending last 3.141592653589793 53.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.0 0.3838383838383838\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.9700436170345483 0.2058339224892116\n",
            "appending last 6.0791673275870375 29.614185789921695\n",
            "appending 0.0 0.0\n",
            "appending 0.7804784451050323 0.998230773802461\n",
            "appending last 4.71238898038469 76.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.418519645352222 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 5.022091924927146 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.4633432079864352 79.05694150420949\n",
            "appending 0.0 0.0\n",
            "appending 0.0530374777791267 0.2678144745898506\n",
            "appending 0.0 1.0\n",
            "appending last 0.0 24.0\n",
            "appending 0.0 0.0\n",
            "appending 0.23330831678473746 0.18287851691457374\n",
            "appending 0.0 1.0\n",
            "appending last 0.0 25.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.522400692465974 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.2742948951737645 0.12275703472692834\n",
            "appending last 3.141592653589793 36.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8230748995159494 0.9927517720576673\n",
            "appending last 4.71238898038469 69.0\n",
            "appending 0.9786931956946782 0.9989276047543069\n",
            "appending last 0.0 13.0\n",
            "appending 0.9785325066423074 0.9914201442178445\n",
            "appending last 0.0 4.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7459199980155949 0.3839678626895184\n",
            "appending last 4.6867535718630124 39.01281840626232\n",
            "appending 0.0 0.0\n",
            "appending last 4.969712695355778 78.587530817554\n",
            "appending 0.0 0.0\n",
            "appending last 4.687077931241841 79.02531240052139\n",
            "appending 0.0 0.0\n",
            "appending 0.7386510645000698 0.13167342270321414\n",
            "appending last 4.617437274041933 63.28506932918696\n",
            "appending 0.0 0.0\n",
            "appending 0.4217261385834468 0.3107551550357291\n",
            "appending last 3.141592653589793 28.0\n",
            "appending last 4.491074578884334 27.333338295541182\n",
            "appending 0.0 0.0\n",
            "appending last 3.3315809415085087 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.8117155396375508 0.7645878581338994\n",
            "appending last 4.71238898038469 24.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.649182148487229 79.1580697086532\n",
            "appending 0.0 0.0\n",
            "appending last 3.7926693750342726 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 3.1249275298758525 60.00833275470999\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending 0.8109155215282648 0.8283436755332175\n",
            "appending 0.75 1.0\n",
            "appending last 4.71238898038469 3.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8003661144446721 0.9960922315199456\n",
            "appending last 5.535505096249002 75.0066663703967\n",
            "appending 0.842606892251084 0.9410315420271872\n",
            "appending last 0.0 56.0\n",
            "appending 0.0 0.0\n",
            "appending 0.9008147461094365 0.38796081808561683\n",
            "appending last 5.644865499170541 38.600518131237564\n",
            "appending 0.0 0.0\n",
            "appending last 0.348771003583907 70.22819946431775\n",
            "appending 0.0 0.0\n",
            "appending last 4.85249070478132 78.77182237323191\n",
            "appending 0.0 0.0\n",
            "appending last 6.065891876256565 78.85429601486528\n",
            "appending 0.9101796878916003 0.9970921796945996\n",
            "appending last 0.0 21.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.7926693750342726 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.7329260398343148 0.6502609748962082\n",
            "appending last 4.71238898038469 13.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.883368854178287 0.6693749518724097\n",
            "appending last 5.564355307557962 10.63014581273465\n",
            "appending 0.0 0.0\n",
            "appending 0.3947917120802828 0.10506822475748868\n",
            "appending 0.5 1.0\n",
            "appending last 3.141592653589793 18.0\n",
            "appending 0.0 0.0\n",
            "appending 0.5 0.1111111111111111\n",
            "appending last 3.171886413508568 66.03029607687671\n",
            "appending 0.0 0.0\n",
            "appending last 5.529026977212406 90.55385138137417\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.6125427610845983 0.7206705958660979\n",
            "appending last 3.9269908169872414 5.656854249492381\n",
            "appending 0.0 0.0\n",
            "appending last 4.522400692465974 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending 0.34667781042420337 0.9986354419371036\n",
            "appending last 1.5707963267948966 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 2.7840268020133623 97.14422267947796\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.7459199980155949 0.3839678626895184\n",
            "appending last 4.6867535718630124 39.01281840626232\n",
            "appending 0.0 0.0\n",
            "appending 0.10343009439326298 0.30707714076985015\n",
            "appending last 0.0 98.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.194607121772004 90.91754506144565\n",
            "appending 0.0 0.0\n",
            "appending 0.32923088501753345 0.518732933846805\n",
            "appending last 3.141592653589793 39.0\n",
            "appending 0.0 0.0\n",
            "appending 0.6125427610845983 0.7206705958660979\n",
            "appending last 3.9269908169872414 5.656854249492381\n",
            "appending 0.1431105604212694 0.9963570672388808\n",
            "appending last 1.5707963267948966 19.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 3.5598169831690223 78.79086241436883\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending 0.5414761588281598 0.6171383715660615\n",
            "appending last 3.402195045337134 15.524174696260024\n",
            "appending 0.7773364771100956 0.9945814259281986\n",
            "appending 0.75 0.32323232323232326\n",
            "appending last 4.903573439981704 31.575306807693888\n",
            "appending 0.0 0.0\n",
            "appending 0.7129465308239906 0.9968638182288164\n",
            "appending last 4.71238898038469 84.0\n",
            "appending 0.9050803148412486 0.9910094000260706\n",
            "appending last 5.592738850124894 59.665735560705194\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 5.3458148633538345 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 86.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.313472611823808 78.587530817554\n",
            "appending 0.0 0.0\n",
            "appending last 1.550798992821746 50.00999900019995\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.3798214016359122 0.2257094450490657\n",
            "appending last 3.141592653589793 23.0\n",
            "appending 0.0 0.0\n",
            "appending 0.8351407443251468 0.623933528342433\n",
            "appending last 4.71238898038469 70.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.3712350958749275 79.07591289387686\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 4.773053883748166 94.8411368593657\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7459199980155949 0.3839678626895184\n",
            "appending last 4.71238898038469 24.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.294241981985058 78.91767862779544\n",
            "appending 0.0 0.0\n",
            "appending last 3.3315809415085087 79.42921376924235\n",
            "appending last 4.696765251764213 32.00390601161052\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.7473027168581134 0.5859441814921992\n",
            "appending last 4.71238898038469 19.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7129465308239906 0.9968638182288164\n",
            "appending last 4.71238898038469 23.0\n",
            "appending 0.0 0.0\n",
            "appending last 6.2711376973254005 83.00602387778854\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.8650657378472295 0.44791046661634887\n",
            "appending last 5.081722638058315 33.24154027718932\n",
            "appending 0.0 0.0\n",
            "appending 0.7826896914778352 0.48515760291439447\n",
            "appending last 5.753938526347741 61.40032573203501\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 93.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.522400692465974 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 5.4887783784917215 78.49203781276162\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.8615444434025537 0.41281659425168327\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending 0.8304194311318522 0.532446424323062\n",
            "appending last 4.71238898038469 30.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending 0.6987918088252166 0.021841188486549288\n",
            "appending last 4.320983852259479 68.15423684555495\n",
            "appending 0.0 0.0\n",
            "appending 0.865188070600303 0.5695420903193362\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.8911842834154328 0.34169848014682824\n",
            "appending last 5.348227403908435 52.20153254455275\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.8507051048262355 0.5535679364971194\n",
            "appending 0.75 0.13131313131313133\n",
            "appending last 3.7223490071574634 76.55063683601855\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 3.7926693750342726 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.125 0.9898479733951178\n",
            "appending 0.25 0.5555555555555556\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.1542438503332321 0.8108197080112671\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.20203941806940393 0.7726458087296717\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.20400813506767598 0.7697074369946982\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.1351450632786287 0.9990399477987907\n",
            "appending 0.26442896918815223 0.10146829310290163\n",
            "appending 0.25 0.24242424242424243\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.6024163823495667 0.29292929292929293\n",
            "appending 0.625 0.9898479733951178\n",
            "appending last 3.5814352364055293 18.788294228055936\n",
            "appending last 4.427722366217265 91.69003490020057\n",
            "appending 0.0 0.0\n",
            "appending 0.21139673245829066 0.999242139938247\n",
            "appending last 1.5707963267948966 8.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.747137317194763 79.05694150420949\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.7195215548949677 0.998230773802461\n",
            "appending last 4.71238898038469 36.0\n",
            "appending 0.0 0.0\n",
            "appending 0.14758361765043326 0.3939393939393939\n",
            "appending last 0.7853981633974483 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending 0.15177093920258597 0.3738702587625901\n",
            "appending last 0.7853981633974483 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending 0.1564164790945006 0.354096088430706\n",
            "appending last 0.7853981633974483 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending 0.16159042617590805 0.3346676397146669\n",
            "appending last 0.7853981633974483 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending 0.16737532973071606 0.31564677770903227\n",
            "appending last 0.7853981633974483 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending 0.17386784600605998 0.2971092187019303\n",
            "appending last 0.7853981633974483 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending 0.15463828556804632 0.992904370691427\n",
            "appending 0.25 0.10101010101010101\n",
            "appending last 0.24497866312686414 4.123105625617661\n",
            "appending 0.0 0.0\n",
            "appending 0.16144556431382573 0.9653135311024225\n",
            "appending last 0.24497866312686414 4.123105625617661\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.2901952613890719 0.31328910290064893\n",
            "appending last 3.141592653589793 17.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 4.8404162171834555 90.07049203650888\n",
            "appending 0.0 0.0\n",
            "appending last 4.827265585801589 78.5175139698144\n",
            "appending 0.0 0.0\n",
            "appending last 4.6365851430235505 79.22752047110903\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 1.2610933822524404 78.74642849044012\n",
            "appending 0.0 0.0\n",
            "appending last 4.124386376837123 79.32212806020776\n",
            "appending 0.0 0.0\n",
            "appending 0.6024163823495667 0.7474747474747475\n",
            "appending last 3.9269908169872414 2.8284271247461903\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.6912187227310325 0.9972183922380603\n",
            "appending last 4.71238898038469 18.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.243123452958928 79.60527620704548\n",
            "appending 0.0 0.0\n",
            "appending 0.436904410130091 0.4607621018507743\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.522400692465974 79.42921376924235\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 4.7875161362954515 93.26306878931231\n",
            "appending 0.0 0.0\n",
            "appending last 4.661799271615305 79.1012010022604\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.17288056869597893 0.9982322019121446\n",
            "appending 0.25 0.46464646464646464\n",
            "appending last 0.0 10.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.3964412832184413 46.61544808322666\n",
            "appending 0.8856826125976626 0.9927013215888753\n",
            "appending last 0.0 7.0\n",
            "appending 0.8864693836042207 0.9984177392105481\n",
            "appending last 0.0 8.0\n",
            "appending 0.0 0.0\n",
            "appending 0.9560577945902774 0.6198166395017723\n",
            "appending last 6.004885648174475 14.560219778561036\n",
            "appending 0.8475540678790416 0.9819444918874568\n",
            "appending last 4.71238898038469 71.0\n",
            "appending 0.0 0.0\n",
            "appending last 6.01359622925866 78.84795495128583\n",
            "appending 0.0 0.0\n",
            "appending 0.17620819117478337 0.5319760753534843\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.17888281235710618 0.5275346821079299\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.18160120892732332 0.5232476275734984\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.1843628396370644 0.5191186625224136\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.1871670418109988 0.5151515151515151\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.19001302653064533 0.5113498787531437\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.19289987439004594 0.507717398706113\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.1958265319259383 0.504257658847435\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.19879180882521663 0.5009741672999402\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.20179437601038522 0.497870341845663\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.20483276469913345 0.494949494949495\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.15687646319839735 0.9592276236471428\n",
            "appending last 0.0 0.0\n",
            "appending 0.8879423877470778 0.99376050798282\n",
            "appending last 5.128453486108512 47.01063709417264\n",
            "appending 0.0 0.0\n",
            "appending last 3.5431731936986726 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.7842102130817503 0.9962223429783691\n",
            "appending last 4.626394689190449 58.215118311311535\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 5.785842590832764 79.64923100695951\n",
            "appending 0.921319482907001 0.664048955178934\n",
            "appending last 0.0 9.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.926981861875913 79.83107164506812\n",
            "appending 0.0 0.0\n",
            "appending 0.809920297753485 0.45695466754330877\n",
            "appending last 4.71238898038469 90.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.676260129871914 83.05419917138447\n",
            "appending 0.0 0.0\n",
            "appending last 3.891291704307917 79.2464510246358\n",
            "appending 0.0 0.0\n",
            "appending 0.0 1.0\n",
            "appending last 0.0 15.0\n",
            "appending 0.9086632145018506 0.7837410225387711\n",
            "appending last 6.1432606366054685 71.7007670809734\n",
            "appending 0.0 0.0\n",
            "appending 0.3968147591721617 0.40808568776736265\n",
            "appending last 3.141592653589793 4.0\n",
            "appending 0.0 0.0\n",
            "appending 0.5054859278080055 0.2830023864352911\n",
            "appending last 3.1823863364576583 49.040799340956916\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.125 0.9898479733951178\n",
            "appending 0.25 0.5555555555555556\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.25 0.0\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 0.7853981633974483 1.4142135623730951\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.8089739080387407 0.994079359476191\n",
            "appending 0.8274924195304101 0.18419579860274085\n",
            "appending last 5.329580371925052 38.01315561749642\n",
            "appending 0.8231043353858573 0.8613711395140451\n",
            "appending last 6.100074489917102 82.37718130647589\n",
            "appending 0.0 0.0\n",
            "appending 0.9213867895388711 0.13903861677003435\n",
            "appending last 5.783838585499456 62.64982043070834\n",
            "appending 0.9053120211605429 0.999169481800886\n",
            "appending last 0.0 46.0\n",
            "appending 0.9221145039363413 0.9998516305174573\n",
            "appending last 0.29544083714372 24.041630560342615\n",
            "appending 0.0 0.0\n",
            "appending 0.17620819117478337 0.05765862558080171\n",
            "appending last 0.24497866312686414 4.123105625617661\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.645075104591984 89.20201791439474\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.7849897526306162 0.9973116881819379\n",
            "appending last 4.71238898038469 56.0\n",
            "appending 0.0 0.0\n",
            "appending 0.28326703456723157 0.3306490463319798\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 3.141592653589793 79.0\n",
            "appending last 4.110873685823794 66.70878877629244\n",
            "appending 0.0 0.0\n",
            "appending 0.09637542647564992 0.3093209757745838\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 5.632108585735106 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending last 5.864960977600357 78.79086241436883\n",
            "appending 0.0 0.0\n",
            "appending last 3.9982982817725317 79.39773296511683\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending 0.19540604428318525 0.1400613004779647\n",
            "appending last 0.3089307439237416 49.33558553417604\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 6.263187973206436 50.00999900019995\n",
            "appending 0.0 0.0\n",
            "appending 0.19573151406075448 0.32215927683633383\n",
            "appending last 0.4636476090008061 2.23606797749979\n",
            "appending 0.0 0.0\n",
            "appending 0.2085238411718401 0.30351868073252575\n",
            "appending last 0.4636476090008061 2.23606797749979\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 79.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.6997314285506375 79.00632886041473\n",
            "appending 0.0 0.0\n",
            "appending last 3.7295952571373605 79.32212806020776\n",
            "appending 0.0 0.0\n",
            "appending 0.5 0.3838383838383838\n",
            "appending last 3.141592653589793 28.0\n",
            "appending 0.0 0.0\n",
            "appending 0.8605710308118477 0.6210302768409417\n",
            "appending 0.75 0.6161616161616161\n",
            "appending last 4.71238898038469 14.0\n",
            "appending 0.0 0.0\n",
            "appending last 5.586836726416636 79.51100552753688\n",
            "appending 0.0 0.0\n",
            "appending 0.826535587713105 0.776027582085223\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending 0.0 0.0\n",
            "appending last 3.491448255446891 78.77182237323191\n",
            "appending 0.0 0.0\n",
            "appending last 4.611467195717395 79.40403012442127\n",
            "appending last 4.773053883748166 94.8411368593657\n",
            "appending 0.0 0.0\n",
            "appending last 4.06131225894021 79.20227269466452\n",
            "appending 0.0 0.0\n",
            "appending 0.055508629227499946 0.9357333261187576\n",
            "appending last 0.0 32.0\n",
            "appending 0.0 0.9924242424242424\n",
            "appending last 0.0 6.0\n",
            "appending 0.0 0.0\n",
            "appending 0.7028458348113064 0.9932094983304256\n",
            "appending last 4.71238898038469 56.0\n",
            "appending 0.7691978531084018 0.9972183922380603\n",
            "appending last 4.71238898038469 38.0\n",
            "appending 0.0 0.0\n",
            "appending 0.07107920317032342 0.7850608728896222\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.6795939557168147 0.414622142255124\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending 0.6624881480022105 0.35716482752924933\n",
            "appending last 4.71238898038469 7.0\n",
            "appending 0.0 0.0\n",
            "appending 0.5 0.04040404040404041\n",
            "appending last 4.288194572480923 34.0147027033899\n",
            "appending 0.0 0.0\n",
            "appending last 4.674432535196376 79.05694150420949\n",
            "appending 0.0 0.0\n",
            "appending last 4.85249070478132 78.77182237323191\n",
            "appending 0.0 0.0\n",
            "appending last 4.674432535196376 79.05694150420949\n",
            "appending 0.0 0.0\n",
            "appending 0.7459199980155949 0.3839678626895184\n",
            "appending last 4.71238898038469 26.0\n",
            "appending 0.0 0.0\n",
            "appending 0.17620819117478337 0.5319760753534843\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending 0.8167895090815772 0.7088468545161312\n",
            "appending last 5.1888563998583965 34.88552708502482\n",
            "appending 0.0 0.0\n",
            "appending 0.8040000967449338 0.354096088430706\n",
            "appending last 5.1888563998583965 34.88552708502482\n",
            "appending 0.8254582881174723 0.9965612516673665\n",
            "appending last 4.71238898038469 49.0\n",
            "appending 0.0 0.0\n",
            "appending 0.8338978826526185 0.7729716138712851\n",
            "appending last 0.0 0.0\n",
            "appending 0.0 0.0\n",
            "appending last 4.624012194239841 79.30952023559341\n",
            "appending 0.0 0.0\n",
            "appending last 5.864960977600357 78.79086241436883\n",
            "appending 0.0 0.0\n",
            "appending last 6.212713962600791 85.21150157109074\n",
            "appending 0.0 0.0\n",
            "appending last 4.71238898038469 77.0\n",
            "appending 0.7917082381335026 0.9938734659167079\n",
            "appending last 4.71238898038469 67.0\n",
            "appending last 4.895071888635715 92.20091033581771\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-867e72c20c0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrobot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_robot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m480\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-93-e8a0fbcf896b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, buffer_size, init_sequences, max_episode_length, sequence_length, action_dim, env, test_env, env_width, env_height)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m#           print('terminal', terminal)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m            \u001b[0mmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m            \u001b[0mmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m84\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-d544f0913922>\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, index_map, do_shuffle)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         self.free_tree = spatial.KDTree(\n\u001b[0;32m---> 66\u001b[0;31m             self.free_points(self.global_map).tolist())\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobot_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, leafsize)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36m__build\u001b[0;34m(self, idx, maxes, mins)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mgreatermins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             return KDTree.innernode(d, split,\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mless_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlessmaxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                     self.__build(idx[greater_idx],maxes,greatermins))\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36m__build\u001b[0;34m(self, idx, maxes, mins)\u001b[0m\n\u001b[1;32m    323\u001b[0m             return KDTree.innernode(d, split,\n\u001b[1;32m    324\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mless_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlessmaxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                     self.__build(idx[greater_idx],maxes,greatermins))\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_upper_bound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36m__build\u001b[0;34m(self, idx, maxes, mins)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mgreatermins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             return KDTree.innernode(d, split,\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mless_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlessmaxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                     self.__build(idx[greater_idx],maxes,greatermins))\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36m__build\u001b[0;34m(self, idx, maxes, mins)\u001b[0m\n\u001b[1;32m    323\u001b[0m             return KDTree.innernode(d, split,\n\u001b[1;32m    324\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mless_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlessmaxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                     self.__build(idx[greater_idx],maxes,greatermins))\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_upper_bound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36m__build\u001b[0;34m(self, idx, maxes, mins)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mgreatermins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             return KDTree.innernode(d, split,\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mless_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlessmaxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                     self.__build(idx[greater_idx],maxes,greatermins))\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36m__build\u001b[0;34m(self, idx, maxes, mins)\u001b[0m\n\u001b[1;32m    323\u001b[0m             return KDTree.innernode(d, split,\n\u001b[1;32m    324\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mless_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlessmaxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                     self.__build(idx[greater_idx],maxes,greatermins))\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_upper_bound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36m__build\u001b[0;34m(self, idx, maxes, mins)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mgreatermins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             return KDTree.innernode(d, split,\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mless_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlessmaxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                     self.__build(idx[greater_idx],maxes,greatermins))\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36m__build\u001b[0;34m(self, idx, maxes, mins)\u001b[0m\n\u001b[1;32m    323\u001b[0m             return KDTree.innernode(d, split,\n\u001b[1;32m    324\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mless_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlessmaxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                     self.__build(idx[greater_idx],maxes,greatermins))\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_upper_bound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36m__build\u001b[0;34m(self, idx, maxes, mins)\u001b[0m\n\u001b[1;32m    323\u001b[0m             return KDTree.innernode(d, split,\n\u001b[1;32m    324\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mless_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlessmaxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                     self.__build(idx[greater_idx],maxes,greatermins))\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_upper_bound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36m__build\u001b[0;34m(self, idx, maxes, mins)\u001b[0m\n\u001b[1;32m    323\u001b[0m             return KDTree.innernode(d, split,\n\u001b[1;32m    324\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mless_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlessmaxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                     self.__build(idx[greater_idx],maxes,greatermins))\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_upper_bound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36m__build\u001b[0;34m(self, idx, maxes, mins)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mgreatermins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             return KDTree.innernode(d, split,\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mless_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlessmaxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                     self.__build(idx[greater_idx],maxes,greatermins))\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/spatial/kdtree.py\u001b[0m in \u001b[0;36m__build\u001b[0;34m(self, idx, maxes, mins)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mless_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             \u001b[0mgreater_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mless_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnonzero\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mnonzero\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0marray_function_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_nonzero_dispatcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m     \"\"\"\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieHIP9WFQ0t5"
      },
      "source": [
        "# linear_dims = [(256, 1)]\n",
        "# actor_linear_dims = [(512, 2)]\n",
        "# conv_dims = [(1, 64, 8), (2, 2), (64, 128, 8), (2, 2), (128, 256), (2, 2)]\n",
        "# lstm_hidden = 512\n",
        "# lstm_out = 2\n",
        "# train_length = 4\n",
        "\n",
        "# linear_dims = [(256, 128), (128, 1)]\n",
        "# actor_linear_dims = [(512,256), (256, 2)] \n",
        "# conv_dims = [(1, 128, 32), (2, 2), (128, 64, 6), (2, 2), (64, 16, 1)] \n",
        "# lstm_hidden = 512\n",
        "# lstm_out = 2\n",
        "# train_length = 8\n",
        "\n",
        "\n",
        "linear_dims = [(256, 128), (128, 1)]\n",
        "actor_linear_dims = [(512,256), (256, 2)] \n",
        "conv_dims = [(1, 256, 64), (256, 64, 8), (64, 8, 1)] \n",
        "lstm_hidden = 512\n",
        "lstm_out = 2\n",
        "train_length = 8\n",
        "\n",
        "td3.re\n",
        "td3 = TD3(robot, conv_dims, lstm_hidden, linear_dims, actor_linear_dims, train_length, replay, 1e-5, 1e-5, 0.99, 750)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsCYdcqISY73",
        "scrolled": true
      },
      "source": [
        "#os.mkdir('/content/drive/My Drive/models')\n",
        "td3.train(50000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KTBJZPEyDjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb28225-4c63-4819-f323-3fe44c2f19a2"
      },
      "source": [
        "for name, params in td3.critic2.named_parameters():\n",
        "\n",
        "  print(name)\n",
        "  print(params.abs().mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv_mod.0.weight\n",
            "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "conv_mod.0.bias\n",
            "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "conv_mod.2.weight\n",
            "tensor(0.9984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "conv_mod.2.bias\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "conv_mod.3.weight\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "conv_mod.3.bias\n",
            "tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "conv_mod.5.weight\n",
            "tensor(0.9994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "conv_mod.5.bias\n",
            "tensor(0.0207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "conv_mod.6.weight\n",
            "tensor(0.0628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "conv_mod.6.bias\n",
            "tensor(0.0600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "conv_mod.8.weight\n",
            "tensor(0.9593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "conv_mod.8.bias\n",
            "tensor(0.0114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "fc.weight\n",
            "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "fc.bias\n",
            "tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "fc2.weight\n",
            "tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "fc2.bias\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27EP7x3dHd8N",
        "outputId": "c191331a-9482-4100-e8a3-4295e6a60901"
      },
      "source": [
        "\n",
        "#  test_map, test_position = self.replay.test_env.reset()\n",
        "test_map, test_position = replay.test_env.reset(replay.test_env.index_map, False)\n",
        "test_map = resize(test_map, (84, 84))\n",
        "test_map = test_map / 255\n",
        "test_position = test_position.astype(np.float64)\n",
        "test_position[0] = test_position[0] / 480\n",
        "test_position[1] = test_position[1] / 640\n",
        "test_action = {'map':torch.from_numpy(test_map).float(), 'position':torch.from_numpy(test_position).float()}\n",
        "x = 0\n",
        "total_test_reward = 0\n",
        "while x < 300:\n",
        "    test_action, test_terminal = replay.generate_step(ActorPolicy(td3.actor), test_action, False, False, True)\n",
        "    print('action', test_action)\n",
        "    print('terminal', test_terminal)\n",
        "    total_test_reward += test_action['reward'].item()\n",
        "\n",
        "    test_map = resize(test_map, (84, 84))\n",
        "    test_map = test_map / 255\n",
        "    test_position = test_position.astype(np.float64)\n",
        "    test_position[0] = test_position[0] / 480\n",
        "    test_position[1] = test_position[1] / 640\n",
        "    test_action = {'map':torch.from_numpy(test_map).float(), 'position':torch.from_numpy(test_position).float()}\n",
        "    x += 1\n",
        "    \n",
        "    if test_terminal:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([1.0979, 0.2859]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([1.0979, 0.3016]), 'reward': tensor([0.1409]), 'action': tensor([0.9990, 0.0048])}\n",
            "terminal False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "action {'last_map': tensor([[0.0020, 0.0020, 0.0020,  ..., 0.0020, 0.0020, 0.0020],\n",
            "        [0.0020, 0.0020, 0.0020,  ..., 0.0020, 0.0020, 0.0020],\n",
            "        [0.0020, 0.0020, 0.0020,  ..., 0.0020, 0.0020, 0.0020],\n",
            "        ...,\n",
            "        [0.0020, 0.0020, 0.0020,  ..., 0.0020, 0.0020, 0.0020],\n",
            "        [0.0020, 0.0020, 0.0020,  ..., 0.0020, 0.0020, 0.0020],\n",
            "        [0.0020, 0.0020, 0.0020,  ..., 0.0020, 0.0020, 0.0020]]), 'last_position': tensor([0.0023, 0.0004]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([1.0938, 0.3219]), 'reward': tensor([0.2409]), 'action': tensor([0.9768, 0.0683])}\n",
            "terminal False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "action {'last_map': tensor([[7.6592e-06, 7.6592e-06, 7.6592e-06,  ..., 7.6592e-06, 7.6592e-06,\n",
            "         7.6592e-06],\n",
            "        [7.6592e-06, 7.6592e-06, 7.6592e-06,  ..., 7.6592e-06, 7.6592e-06,\n",
            "         7.6592e-06],\n",
            "        [7.6592e-06, 7.6592e-06, 7.6592e-06,  ..., 7.6592e-06, 7.6592e-06,\n",
            "         7.6592e-06],\n",
            "        ...,\n",
            "        [7.6592e-06, 7.6592e-06, 7.6592e-06,  ..., 7.6592e-06, 7.6592e-06,\n",
            "         7.6592e-06],\n",
            "        [7.6592e-06, 7.6592e-06, 7.6592e-06,  ..., 7.6592e-06, 7.6592e-06,\n",
            "         7.6592e-06],\n",
            "        [7.6592e-06, 7.6592e-06, 7.6592e-06,  ..., 7.6592e-06, 7.6592e-06,\n",
            "         7.6592e-06]]), 'last_position': tensor([4.7653e-06, 6.9809e-07]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([1.0396, 0.3281]), 'reward': tensor([0.3121]), 'action': tensor([0.7757, 0.3248])}\n",
            "terminal False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "action {'last_map': tensor([[3.0036e-08, 3.0036e-08, 3.0036e-08,  ..., 3.0036e-08, 3.0036e-08,\n",
            "         3.0036e-08],\n",
            "        [3.0036e-08, 3.0036e-08, 3.0036e-08,  ..., 3.0036e-08, 3.0036e-08,\n",
            "         3.0036e-08],\n",
            "        [3.0036e-08, 3.0036e-08, 3.0036e-08,  ..., 3.0036e-08, 3.0036e-08,\n",
            "         3.0036e-08],\n",
            "        ...,\n",
            "        [3.0036e-08, 3.0036e-08, 3.0036e-08,  ..., 3.0036e-08, 3.0036e-08,\n",
            "         3.0036e-08],\n",
            "        [3.0036e-08, 3.0036e-08, 3.0036e-08,  ..., 3.0036e-08, 3.0036e-08,\n",
            "         3.0036e-08],\n",
            "        [3.0036e-08, 3.0036e-08, 3.0036e-08,  ..., 3.0036e-08, 3.0036e-08,\n",
            "         3.0036e-08]]), 'last_position': tensor([9.9276e-09, 1.0908e-09]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([1.0354, 0.2734]), 'reward': tensor([0.0849]), 'action': tensor([0.5071, 0.5044])}\n",
            "terminal False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "action {'last_map': tensor([[1.1779e-10, 1.1779e-10, 1.1779e-10,  ..., 1.1779e-10, 1.1779e-10,\n",
            "         1.1779e-10],\n",
            "        [1.1779e-10, 1.1779e-10, 1.1779e-10,  ..., 1.1779e-10, 1.1779e-10,\n",
            "         1.1779e-10],\n",
            "        [1.1779e-10, 1.1779e-10, 1.1779e-10,  ..., 1.1779e-10, 1.1779e-10,\n",
            "         1.1779e-10],\n",
            "        ...,\n",
            "        [1.1779e-10, 1.1779e-10, 1.1779e-10,  ..., 1.1779e-10, 1.1779e-10,\n",
            "         1.1779e-10],\n",
            "        [1.1779e-10, 1.1779e-10, 1.1779e-10,  ..., 1.1779e-10, 1.1779e-10,\n",
            "         1.1779e-10],\n",
            "        [1.1779e-10, 1.1779e-10, 1.1779e-10,  ..., 1.1779e-10, 1.1779e-10,\n",
            "         1.1779e-10]]), 'last_position': tensor([2.0683e-11, 1.7043e-12]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([1.0333, 0.2188]), 'reward': tensor([-0.8000]), 'action': tensor([0.5042, 0.5091])}\n",
            "terminal False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "action {'last_map': tensor([[4.6192e-13, 4.6192e-13, 4.6192e-13,  ..., 4.6192e-13, 4.6192e-13,\n",
            "         4.6192e-13],\n",
            "        [4.6192e-13, 4.6192e-13, 4.6192e-13,  ..., 4.6192e-13, 4.6192e-13,\n",
            "         4.6192e-13],\n",
            "        [4.6192e-13, 4.6192e-13, 4.6192e-13,  ..., 4.6192e-13, 4.6192e-13,\n",
            "         4.6192e-13],\n",
            "        ...,\n",
            "        [4.6192e-13, 4.6192e-13, 4.6192e-13,  ..., 4.6192e-13, 4.6192e-13,\n",
            "         4.6192e-13],\n",
            "        [4.6192e-13, 4.6192e-13, 4.6192e-13,  ..., 4.6192e-13, 4.6192e-13,\n",
            "         4.6192e-13],\n",
            "        [4.6192e-13, 4.6192e-13, 4.6192e-13,  ..., 4.6192e-13, 4.6192e-13,\n",
            "         4.6192e-13]]), 'last_position': tensor([4.3089e-14, 2.6630e-15]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([1.0333, 0.2188]), 'reward': tensor([-1.]), 'action': tensor([0.5050, 0.5093])}\n",
            "terminal True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XTS8wPa4ubxS",
        "scrolled": true,
        "outputId": "f51f1cf2-0b2f-406c-ff47-d81cd0ed38a4"
      },
      "source": [
        "reward = 0\n",
        "\n",
        "# test_map, test_position = replay.test_env.reset()\n",
        "test_map, test_position = replay.test_env.reset(replay.test_env.index_map, False)\n",
        "test_map = resize(test_map, (84, 84))\n",
        "test_map = test_map / 255\n",
        "test_position = test_position.astype(np.float64)\n",
        "test_position[0] = test_position[0] / 480\n",
        "test_position[1] = test_position[1] / 640\n",
        "test_action = {'map':torch.from_numpy(test_map).float(), 'position':torch.from_numpy(test_position).float()}\n",
        "x = 0\n",
        "total_reward = 0\n",
        "while x < 300:\n",
        "    test_action, test_terminal = replay.generate_step(ActorPolicy(td3.actor), test_action, add_noise=False, store=False, test=True)\n",
        "    print('action', test_action)\n",
        "    print('terminal', test_terminal)\n",
        "    total_reward += test_action['reward'].item()\n",
        "    test_map = resize(test_map, (84, 84))\n",
        "    test_map = test_map / 255\n",
        "    test_position = test_position.astype(np.float64)\n",
        "    test_position[0] = test_position[0] / 480\n",
        "    test_position[1] = test_position[1] / 640\n",
        "    test_action = {'map':torch.from_numpy(test_map).float(), 'position':torch.from_numpy(test_position).float()}\n",
        "    if test_terminal:\n",
        "        break\n",
        "    x += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "action {'last_map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'last_position': tensor([1.0979, 0.2859]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([1.0917, 0.3063]), 'reward': tensor([0.2196]), 'action': tensor([0.9651, 0.0618])}\n",
            "terminal False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "action {'last_map': tensor([[0.0020, 0.0020, 0.0020,  ..., 0.0020, 0.0020, 0.0020],\n",
            "        [0.0020, 0.0020, 0.0020,  ..., 0.0020, 0.0020, 0.0020],\n",
            "        [0.0020, 0.0020, 0.0020,  ..., 0.0020, 0.0020, 0.0020],\n",
            "        ...,\n",
            "        [0.0020, 0.0020, 0.0020,  ..., 0.0020, 0.0020, 0.0020],\n",
            "        [0.0020, 0.0020, 0.0020,  ..., 0.0020, 0.0020, 0.0020],\n",
            "        [0.0020, 0.0020, 0.0020,  ..., 0.0020, 0.0020, 0.0020]]), 'last_position': tensor([0.0023, 0.0004]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([1.0604, 0.3250]), 'reward': tensor([0.3197]), 'action': tensor([0.8595, 0.1831])}\n",
            "terminal False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "action {'last_map': tensor([[7.6592e-06, 7.6592e-06, 7.6592e-06,  ..., 7.6592e-06, 7.6592e-06,\n",
            "         7.6592e-06],\n",
            "        [7.6592e-06, 7.6592e-06, 7.6592e-06,  ..., 7.6592e-06, 7.6592e-06,\n",
            "         7.6592e-06],\n",
            "        [7.6592e-06, 7.6592e-06, 7.6592e-06,  ..., 7.6592e-06, 7.6592e-06,\n",
            "         7.6592e-06],\n",
            "        ...,\n",
            "        [7.6592e-06, 7.6592e-06, 7.6592e-06,  ..., 7.6592e-06, 7.6592e-06,\n",
            "         7.6592e-06],\n",
            "        [7.6592e-06, 7.6592e-06, 7.6592e-06,  ..., 7.6592e-06, 7.6592e-06,\n",
            "         7.6592e-06],\n",
            "        [7.6592e-06, 7.6592e-06, 7.6592e-06,  ..., 7.6592e-06, 7.6592e-06,\n",
            "         7.6592e-06]]), 'last_position': tensor([4.7653e-06, 6.9809e-07]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([1.0104, 0.2922]), 'reward': tensor([0.2819]), 'action': tensor([0.6338, 0.4427])}\n",
            "terminal False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAD8CAYAAAARze3ZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYcklEQVR4nO3dfWxc9Z3v8ffXHttjx75x4tCsHZsmLFFNeLhJmkJKdhEt6i2QaqEtu6JCW9TNbSRopVZd0dK921uBrlYtqMsuUsMuKmWzV91tKXSXiLZqUxJCLtngBJLw4DzZebLjxMaOH+IYxzOe3/1jfjZOYnP8MDPnjPN5Sdac8ztnzvlOMv74PPzOOeacQ0REJlYQdgEiIlGnoBQRCaCgFBEJoKAUEQmgoBQRCaCgFBEJkJWgNLPbzeygmTWZ2cPZWIeISK5YpvtRmlkhcAj4DNAK7AK+5JxrzOiKRERyJBtblDcCTc65I865IeDnwF1ZWI+ISE7EsrDMRUDLmPFW4KaLZzKz9cB6gKKioo8vWLAgC6WIiEzOqVOnOp1zV4w3LRtBOSnOuaeBpwFqamrcV7/61bBKERHh0UcfPT7RtGzsep8E6saM1/o2EZG8lI2g3AUsNbMlZlYM3AtsysJ6RERyIuO73s65pJl9HfgdUAj81Dn3bqbXIyKSK1k5Rumc+w3wm2wsW0Qk13RljohIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIgMCgNLOfmlmHmb0zpm2+mW02s8P+dZ5vNzN70syazOwtM1uZzeJFRHJhMluU/wLcflHbw8DLzrmlwMt+HOAOYKn/WQ88lZkyRUTCExiUzrlXgTMXNd8FbPTDG4G7x7T/q0vbCVSaWXWGahURCcV0j1EudM6d8sOngYV+eBHQMma+Vt92CTNbb2a7zWz3wMDANMsQEcm+GZ/Mcc45wE3jfU8751Y551aVlZXNtAwRkayZblC2j+xS+9cO334SqBszX61vExHJW9MNyk3A/X74fuDFMe1f9me/VwO9Y3bRRUTyUixoBjP7d+BWYIGZtQLfB34APGdm64DjwF/42X8D3Ak0AQPAV7JQs4hITgUGpXPuSxNMum2ceR3wtZkWJSISJboyR0QkQOAWpYjkp76+Ps6fPw/A4OAgb7/9NgDz58/n/Pnz1NfXU1CQ3laKx+NUVFRcsoxUKkV3dzepVGp0fN++fSSTydF5Fi5cSGlpKQsWLMDMiMfjFBcXU1xcjJll+2PmhIJSJA8MDAwQj8fp6enh3Llzl0zv6elh//79F7S1trYyto/ySNiN2L59++jw3LlzWbhwIRdLJpMcO3bsgvdevJyRMBx5raioYM6cOZSVlXH99ddz/fXXT/ZjRpaCUiTiUqkUO3bs4Pjx4xMG5XSXO6K7u5vu7u5pLSd9auKD197eXnp7ewGoq6ub8H35REEpEmGpVIrnn3+ew4cPMzw8HHY5U9bY2EhZWRlVVVUsXrw47HKmTUEpEmEdHR00NzczPDxMYWEhH/nIR/LmuF9fXx/t7e38+te/5rrrrlNQikh2FBYWEovFSCQSVFdX09DQwJw5c8Iua1K+973v8eSTTwIwNDREKpUaPXmUbxSUIhE2MDDA+++/D0BBQQEVFRWUl5eHXNXklJSUjA4fPXqUvr4+KisrwytoBvIz3kUkr4yc6MlXCkqRCOvs7Ay7BEFBKRJpI91sJFwKSpEIO336dNglZMTw8DDHjx8Pu4xpU1CKSNY552hvbw+7jGnTWW+RiOrp6aGtrW3Gy0n2J2l5vIW2DW0kuhIUVRVR82ANdQ/VEStXBEyG/pVEImpoaIjBwcEZLSPZn+TN1W8y2DxIajB9yWKiM0HLYy2898J7rNy5Mmdhmc9nvrXrLRJRJ0+enHG4tDzeckFIjkgNphhsHqTl8ZYJ3pl5zc3No3czyjcKSpGIamlpmXFQtm1ouyQkR6QGU7Q9NfNd+8nK59uuKShFZrFEV2JG0zNpaGgob3e/dYxSJIdGbm029ma4fX19lJeX09vbS2Vl5ejtzvr6+ma8vqKqIhKdE4dhUVXRjNcxWfl6nTcoKEVyZtu2bTQ2NgKM3lDXOcfg4CAlJSW8//77lJaWjl7bnQk1D9bQ8ljLuLvfBfECah6oydi6AmupqaG4uDhn68skBaVIDsRiMT71qU9xyy23THsZlZWVF9xoYjLqHqrjvRfeu+SETkG8gPgfx6l7KHc31o3H43l7jFJBKZIDS5Ys4b777st5UMTKY6zcuZKWx1s49HgbRe8nGJ5TxNV/rX6UU5G/Bw1E8oSZsWzZstC2pmLlMZY8soRt31zDbdzKrr9Zw5JHluQ0JM1s3IeX5QsFpUgOLFiwIOwSGNlrD6MrY2FhIddcc03uV5whCkqRLLvhhhuorq4Ou4zRoJzhxT6XJQWlSJbV19dTVJS7bjgTicfTr2FdHJNI5K7PZqYpKEUuE2Hueg8PD9PU1JT7FWeITnmJXCYytevdn0zyeEsLG9ra6EokqCoq4sGaGh6qq6M8Nn6kFBQUUFtbO7MVh0hblCJZFKV+g5nY9e5PJln95ps81tJCZyKBAzoTCR5raWH1m2/Sn0yO+77h4WH2798//RWHTEEpkkVz586NzPOsM7Hr/XhLC82DgwymLrzSZzCVonlwkMdbcnc3olxSUIpkUSwWm/LVNNmSiaDc0NZ2SUiOGEyleOpDbjTc0dGRtyd0FJQil4lMHKPsCgi6D5ve3d3N8PDw9FceIgWlyGVi5BjlqVMwNDS9ZVQFdHP6sOklJSV5eweh/KxaRKZs2TIoL4fGRli7FqbzJNwHa2qITxB28YICHqiZ+G5E+XovSlBQilw2qqpg61ZYuBD+8Af40z+F1tapLeOhujquisfh/IXRES8o4I/jcR6qm/huRMPDw3kblgpKkcvIqlXwX/8F9fXw9ttw002wb9/k318ei/GUrYSf11F4togC4IqiIr5dV8fOlSsn7EcJsGjRokhcoTQdgUFpZnVmttXMGs3sXTP7hm+fb2abzeywf53n283MnjSzJjN7y8xWZvtDiETV8PAwQ9M9IJglS5bAa6/BLbdAW1t6y/L3v5/8+3/3nzH4lyX85a/WMHzrrXSsWcMjS5Z8aEgCHDlyZFY/XCwJ/LVzbhmwGviamS0DHgZeds4tBV724wB3AEv9z3rgqYxXLZInenp6OHbsWNhlXGL+/HQ43nsvnD2bPmb57LMf/p5EAr7+dfi7v0uP33XX1NaZr2e8YRJB6Zw75Zx70w+fBfYDi4C7gI1+to3A3X74LuBfXdpOoNLMwr91ikgInHORPS5XUgI/+xl85zuQTMJf/RV8//swXrnt7XDbbfDjH0NxMfzkJ3D33VNb39VXXx2ZPqVTNaVjlGa2GFgBvA4sdM6d8pNOAwv98CJgbPf8Vt928bLWm9luM9s98vwQkdkoyltSBQXwgx/Ahg3p4Ucfha985cLuQw0N8PGPw/btUFMDr74K69ZNfV1lZWWzv3uQmZUDLwDfdM5d8Hg4l/6TOaU/m865p51zq5xzq8rKyqbyVpG8smfPnrBLCPTAA/Dii1BWBhs3ftB96Nln08cyT56ENWvgjTfSJ4CmIznBdeD5YFJBaWZFpEPyZ865X/nm9pFdav/a4dtPAmP7CNT6NpHL0rlz5/Li0r3PfQ62bfug+9DHPpbeHT9/Ph2kW7bAH/3R9Jd/8ODBjD5hMpcmc9bbgGeA/c65vx8zaRNwvx++H3hxTPuX/dnv1UDvmF10kctOe3s7p07lx6/A2O5D7e0fHI/csCE9PBNRPgQRZDL3o1wD/CXwtpnt9W1/A/wAeM7M1gHHgb/w034D3Ak0AQPAVzJZsEg+6urq4sorrwy7jEkZ6T60YQPccUf6+GQmROmWc1MVGJTOuf8HTPQJbxtnfgd8bYZ1icwazjneffddli9fnjdhMX8+/O3fZnaZS5cuJT5ywXmeyc9TUCJ55sSJE5w5cybsMkIVj8fz5g/FxRSUIjkwNDREc3Nz2GWEqrS0NOwSpk1BKZIDzjkaGhry9qzvTMViMa699tqwy5g2BaVIjvT09NDZ2Rl2GaHJ187moKcwiuRMIpFgy5YtOOdy3lXmpptu4rrrrsvpOm+88UY++9nP0t3dTSqVonim/YtCpKAUyaEDBw7w3HPPceTIkZyu94knnsh5UN5zzz2sXbuWrq4udu7cyaFDh/L27kEKSpEcKi4u5vOf/zyNjY2jbYlEgo6ODsrLyxkYGKCzs/OSY5nOOYaGhkgkEnkVNqWlpdTW1vKFL3yBtrY2du7cSUtLC729vZG9Wch4FJQiOTZnzhw+8YlPXNDmnMPMRu82dHGIpFIp+vv7GRgYoK/vg1stnD9/nkOHDlFYWEivf7ZDf38/58+fj9SJo4KCAmpra/niF7/IuXPneOutt9i9ezdnzpzJi8BUUIpEwEj/QjMbt69hYWEh8+bNY968eSxadOHNuJYvX37B+NmzZxkcHKSpqYnNmzdnrebpMDPKy8u5+eabueGGG0YDs7u7O9K3pFNQiswyFRUVVFRUXLDlGUVjA7Ojo4MdO3Zw9OjRSN5lSEEpIqEqLy+nvLycK6+8khMnTrBjxw4OHDhAYWFh2KWNUlCKSCTEYjGuuuoq4vE4P/rRj5g3bx7Lly+noqIi7NLU4VxktorH43n51MPCwkKOHTvG1q1b+e1vfxt2OYCCUmTWqqmpYf78+WGXMSPXXHNN2CUACkoRiajq6mrq6+vDLgNQUIpIBJWWlnL77bdH5tCBglJEIsXMWL58ObW1tWGXMkpBKSKR4pzj5ptvjtRNfhWUIhIZqVSKhoaGyHU6V1CKSGRs376dPXv2RO5SRgWlyCxlZpdcFx5lZ86cYdeuXZF8rK2CUmQWy5dH5CaTSY4ePcrZs2fDLmVcuoRRREKVTCbZvHkzu3btCruUCSkoRSQ0IyHZ0NBAKpUKu5wJKShFJBTt7e1s2rSJtra2SIckKChFJMdSqRSnT5/mhRdeyJunUiooRWaxRYsWsXbt2shcM51Kpdi+fTuvvfZaXj37R0EpMotVVVVRX1/PrbfeGmodzjlaW1vZsWMHBw8ejGQXoA+joBSZxcyM+vp64vF4aDX09/ezd+9eXnnlFZLJZOQ6k0+GglJkFisuLs7587xHDA8Pc+LECbZt28bRo0dDqSFTFJQis1hFRQU9PT1UVVXl7JZl/f39NDY20tTUxJEjR0gkEjlZbzYpKEVmsc7OTn75y1/y0Y9+lMWLF3PttddSWVmZ8Qd3DQwM0NXVxTvvvMOhQ4fo6emJfJefqVBQisxyyWSS5uZmjhw5wquvvsrixYspLy9nxYoVlJWVccUVV0xrmadPn6arq4tDhw7x3nvv0dnZSSqVystjkEEUlCKXCecciUSCw4cPY2bs3buXkpISqqurgfTxzBUrVhCLjR8LXV1dHDhwAIChoSFOnTqFc25WBuPFFJQil6GRcBscHLzgRMvBgwfDKinSdPcgEZEAgUFpZnEzazCzfWb2rpk94tuXmNnrZtZkZr8ws2LfXuLHm/z0xVn+DCIiWTWZLcrzwKedc/8dWA7cbmargR8CTzjnrga6gXV+/nVAt29/ws8nIpK3AoPSpfX70SL/44BPA8/79o3A3X74Lj+On36bRekpQSIiUzSpY5RmVmhme4EOYDPQDPQ450aeANQKjNxzfhHQAuCn9wJV4yxzvZntNrPdAwMDM/oQIiLZNKmgdM4NO+eWA7XAjcCMb0XinHvaObfKObeqrKxsposTEcmaKZ31ds71AFuBTwKVZjbSvagWOOmHTwJ1AH76XKArE8WKiIRhMme9rzCzSj9cCnwG2E86MO/xs90PvOiHN/lx/PQt7nLokSois9ZkOpxXAxvNrJB0sD7nnHvJzBqBn5vZ/wH2AM/4+Z8B/q+ZNQFngHuzULeISM4EBqVz7i1gxTjtR0gfr7y4fRD484xUJyISAboyR0QkgIJSRCSAglJEJICCUkQkgIJSRCSAglJEJICCUkQkgIJSRCSAglJEJICCUkQkgIJSRCSAglJEJICCUkQkgIJSRCSAglJEJICCUkQkgIJSRCSAglJEJICCUkQkgIJSRCSAglJEJICCUkQkgIJSRCSAglJEJICCUkQkgIJSRCSAglJEJICCUkQkgIJSRCSAglJEJICCUkQkgIJSRCSAglJEJICCUkQkgIJSRCSAglJEJMCkg9LMCs1sj5m95MeXmNnrZtZkZr8ws2LfXuLHm/z0xVmqXUQkJ6ayRfkNYP+Y8R8CTzjnrga6gXW+fR3Q7duf8POJiOStSQWlmdUCa4Gf+HEDPg0872fZCNzth+/y4/jpt/n5RUTy0mS3KP8B+DaQ8uNVQI9zLunHW4FFfngR0ALgp/f6+UVE8lJgUJrZ54AO59wbmVyxma03s91mtntgYCCTixYRyajYJOZZA/yZmd0JxIH/BvwjUGlmMb/VWAuc9POfBOqAVjOLAXOBrosX6px7GngaoKamxs30g4iIZEvgFqVz7rvOuVrn3GLgXmCLc+4+YCtwj5/tfuBFP7zJj+Onb3HOKQhFJG/NpB/ld4BvmVkT6WOQz/j2Z4Aq3/4t4OGZlSgiEq7J7HqPcs69Arzih48AN44zzyDw5xmoTUQkEnRljohIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAAWliEgABaWISAAFpYhIAHPOhV0DZnYWOBh2HVO0AOgMu4hpyMe6VXPu5GPdmar5o865K8abEMvAwjPhoHNuVdhFTIWZ7c63miE/61bNuZOPdeeiZu16i4gEUFCKiASISlA+HXYB05CPNUN+1q2acycf6856zZE4mSMiEmVR2aIUEYksBaWISIDQg9LMbjezg2bWZGYPh13PCDP7qZl1mNk7Y9rmm9lmMzvsX+f5djOzJ/1neMvMVoZUc52ZbTWzRjN718y+EfW6zSxuZg1mts/X/IhvX2Jmr/vafmFmxb69xI83+emLc13zmNoLzWyPmb2URzUfM7O3zWyvme32bZH9fvg6Ks3seTM7YGb7zeyTOa/ZORfaD1AINANXAcXAPmBZmDWNqe0WYCXwzpi2x4CH/fDDwA/98J3AbwEDVgOvh1RzNbDSD1cAh4BlUa7br7vcDxcBr/tangPu9e3/BDzghx8E/skP3wv8IsTvyLeAfwNe8uP5UPMxYMFFbZH9fvg6NgL/0w8XA5W5rjmU/6wx/wCfBH43Zvy7wHfDrOmi+hZfFJQHgWo/XE26ozzAPwNfGm++kOt/EfhMvtQNlAFvAjeRvtIidvH3BPgd8Ek/HPPzWQi11gIvA58GXvK/mJGu2a9/vKCM7PcDmAscvfjfK9c1h73rvQhoGTPe6tuiaqFz7pQfPg0s9MOR+xx+924F6S20SNftd2H3Ah3AZtJ7GT3OueQ4dY3W7Kf3AlU5LTjtH4BvAyk/XkX0awZwwO/N7A0zW+/bovz9WAK8BzzrD3P8xMzmkOOaww7KvOXSf64i2bfKzMqBF4BvOuf6xk6LYt3OuWHn3HLSW2k3AvXhVvThzOxzQIdz7o2wa5mGP3HOrQTuAL5mZreMnRjB70eM9CGwp5xzK4BzpHe1R+Wi5rCD8iRQN2a81rdFVbuZVQP41w7fHpnPYWZFpEPyZ865X/nmyNcN4JzrAbaS3m2tNLORexGMrWu0Zj99LtCV20pZA/yZmR0Dfk569/sfiXbNADjnTvrXDuA/SP9hivL3oxVodc697sefJx2cOa057KDcBSz1ZwuLSR/o3hRyTR9mE3C/H76f9DHAkfYv+zNuq4HeMbsFOWNmBjwD7HfO/f2YSZGt28yuMLNKP1xK+pjqftKBec8ENY98lnuALX6LImecc991ztU65xaT/s5ucc7dR4RrBjCzOWZWMTIM/A/gHSL8/XDOnQZazOxjvuk2oDHnNYdxQPmig7J3kj472wz8r7DrGVPXvwOngATpv2rrSB9Xehk4DPwBmO/nNeDH/jO8DawKqeY/Ib0L8haw1//cGeW6gRuAPb7md4D/7duvAhqAJuCXQIlvj/vxJj/9qpC/J7fywVnvSNfs69vnf94d+X2L8vfD17Ec2O2/I/8JzMt1zbqEUUQkQNi73iIikaegFBEJoKAUEQmgoBQRCaCgFBEJoKAUEQmgoBQRCfD/ARN83jcCMU7CAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "action {'last_map': tensor([[3.0036e-08, 3.0036e-08, 3.0036e-08,  ..., 3.0036e-08, 3.0036e-08,\n",
            "         3.0036e-08],\n",
            "        [3.0036e-08, 3.0036e-08, 3.0036e-08,  ..., 3.0036e-08, 3.0036e-08,\n",
            "         3.0036e-08],\n",
            "        [3.0036e-08, 3.0036e-08, 3.0036e-08,  ..., 3.0036e-08, 3.0036e-08,\n",
            "         3.0036e-08],\n",
            "        ...,\n",
            "        [3.0036e-08, 3.0036e-08, 3.0036e-08,  ..., 3.0036e-08, 3.0036e-08,\n",
            "         3.0036e-08],\n",
            "        [3.0036e-08, 3.0036e-08, 3.0036e-08,  ..., 3.0036e-08, 3.0036e-08,\n",
            "         3.0036e-08],\n",
            "        [3.0036e-08, 3.0036e-08, 3.0036e-08,  ..., 3.0036e-08, 3.0036e-08,\n",
            "         3.0036e-08]]), 'last_position': tensor([9.9276e-09, 1.0908e-09]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([1.0083, 0.2375]), 'reward': tensor([-0.8000]), 'action': tensor([0.5066, 0.5057])}\n",
            "terminal False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "action {'last_map': tensor([[1.1779e-10, 1.1779e-10, 1.1779e-10,  ..., 1.1779e-10, 1.1779e-10,\n",
            "         1.1779e-10],\n",
            "        [1.1779e-10, 1.1779e-10, 1.1779e-10,  ..., 1.1779e-10, 1.1779e-10,\n",
            "         1.1779e-10],\n",
            "        [1.1779e-10, 1.1779e-10, 1.1779e-10,  ..., 1.1779e-10, 1.1779e-10,\n",
            "         1.1779e-10],\n",
            "        ...,\n",
            "        [1.1779e-10, 1.1779e-10, 1.1779e-10,  ..., 1.1779e-10, 1.1779e-10,\n",
            "         1.1779e-10],\n",
            "        [1.1779e-10, 1.1779e-10, 1.1779e-10,  ..., 1.1779e-10, 1.1779e-10,\n",
            "         1.1779e-10],\n",
            "        [1.1779e-10, 1.1779e-10, 1.1779e-10,  ..., 1.1779e-10, 1.1779e-10,\n",
            "         1.1779e-10]]), 'last_position': tensor([2.0683e-11, 1.7043e-12]), 'map': tensor([[0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        ...,\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980],\n",
            "        [0.4980, 0.4980, 0.4980,  ..., 0.4980, 0.4980, 0.4980]]), 'position': tensor([1.0083, 0.2375]), 'reward': tensor([-1.]), 'action': tensor([0.5032, 0.5078])}\n",
            "terminal True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3891vvehUcKZ"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/ddpg_nets')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVmvfOePUcKa",
        "outputId": "0b582f9f-efde-42d1-c33f-25bcea0ca682"
      },
      "source": [
        "td3.critic1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNCriticNoSeq(\n",
              "  (conv_mod): Sequential(\n",
              "    (0): Conv2d(1, 256, kernel_size=(64, 64), stride=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.01)\n",
              "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv2d(256, 64, kernel_size=(8, 8), stride=(1, 1))\n",
              "    (4): LeakyReLU(negative_slope=0.01)\n",
              "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (7): LeakyReLU(negative_slope=0.01)\n",
              "    (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (fc): Linear(in_features=3140, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1m12fo-UcKb",
        "outputId": "133c9452-fe08-494c-a239-28368df93fef"
      },
      "source": [
        "maps, positions, rewards, actions, last_positions, last_maps = td3.replay.sample_transitions(10)\n",
        "maps=maps.unsqueeze(1)\n",
        "last_maps=last_maps.unsqueeze(1)\n",
        "# target_action = td3.actor_target(last_maps, last_positions)\n",
        "crit1 = td3.critic1_target(maps, positions, target_action)\n",
        "# writer.add_graph(td3.actor, (last_maps, last_positions))\n",
        "writer.add_graph(td3.critic1, (maps, positions, target_action))\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/justinzsun/ece_276c/276cproj/lib/python3.7/site-packages/torch/jit/_trace.py:152: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  if a.grad is not None:\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}