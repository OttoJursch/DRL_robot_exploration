{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJBqQwnOM5hX",
    "outputId": "7d65243b-cd89-45ed-f344-0985be2ebd50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pybind11'...\n",
      "remote: Enumerating objects: 13933, done.\u001b[K\n",
      "remote: Total 13933 (delta 0), reused 0 (delta 0), pack-reused 13933\u001b[K\n",
      "Receiving objects: 100% (13933/13933), 5.39 MiB | 24.76 MiB/s, done.\n",
      "Resolving deltas: 100% (9485/9485), done.\n",
      "-- The CXX compiler identification is GNU 7.5.0\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- pybind11 v2.6.2 dev1\n",
      "-- CMake 3.12.0\n",
      "-- Found PythonInterp: /usr/bin/python3.6 (found version \"3.6.9\") \n",
      "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so\n",
      "-- PYTHON 3.6.9\n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- pybind11::lto enabled\n",
      "-- pybind11::thin_lto enabled\n",
      "-- Setting tests build type to MinSizeRel as none was specified\n",
      "-- Building tests WITHOUT Eigen, use -DDOWNLOAD_EIGEN on CMake 3.11+ to download\n",
      "-- Boost version: 1.65.1\n",
      "-- Found pytest 3.6.4\n",
      "-- Catch not detected. Interpreter tests will be skipped. Install Catch headers manually or use `cmake -DDOWNLOAD_CATCH=ON` to fetch them automatically.\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /content/pybind11/build\n",
      "\u001b[35m\u001b[1mScanning dependencies of target pybind11_cross_module_tests\u001b[0m\n",
      "[  2%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_cross_module_tests.dir/pybind11_cross_module_tests.cpp.o\u001b[0m\n",
      "[  4%] \u001b[32m\u001b[1mLinking CXX shared module pybind11_cross_module_tests.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
      "[  4%] Built target pybind11_cross_module_tests\n",
      "\u001b[35m\u001b[1mScanning dependencies of target pybind11_tests\u001b[0m\n",
      "[  7%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/pybind11_tests.cpp.o\u001b[0m\n",
      "[  9%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_async.cpp.o\u001b[0m\n",
      "[ 11%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_buffers.cpp.o\u001b[0m\n",
      "[ 14%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_builtin_casters.cpp.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_call_policies.cpp.o\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_callbacks.cpp.o\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_chrono.cpp.o\u001b[0m\n",
      "[ 23%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_class.cpp.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_constants_and_functions.cpp.o\u001b[0m\n",
      "[ 28%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_copy_move.cpp.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_custom_type_casters.cpp.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_docstring_options.cpp.o\u001b[0m\n",
      "[ 35%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_enum.cpp.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_eval.cpp.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_exceptions.cpp.o\u001b[0m\n",
      "[ 42%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_factory_constructors.cpp.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_gil_scoped.cpp.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_iostream.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_kwargs_and_defaults.cpp.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_local_bindings.cpp.o\u001b[0m\n",
      "[ 54%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_methods_and_attributes.cpp.o\u001b[0m\n",
      "[ 57%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_modules.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_multiple_inheritance.cpp.o\u001b[0m\n",
      "[ 61%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_array.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_dtypes.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_vectorize.cpp.o\u001b[0m\n",
      "[ 69%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_opaque_types.cpp.o\u001b[0m\n",
      "[ 71%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_operator_overloading.cpp.o\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_pickling.cpp.o\u001b[0m\n",
      "[ 76%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_pytypes.cpp.o\u001b[0m\n",
      "[ 78%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_sequences_and_iterators.cpp.o\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_smart_ptr.cpp.o\u001b[0m\n",
      "[ 83%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_stl.cpp.o\u001b[0m\n",
      "[ 85%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_stl_binders.cpp.o\u001b[0m\n",
      "[ 88%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_tagbased_polymorphic.cpp.o\u001b[0m\n",
      "[ 90%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_union.cpp.o\u001b[0m\n",
      "[ 92%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_virtual_functions.cpp.o\u001b[0m\n",
      "[ 95%] \u001b[32m\u001b[1mLinking CXX shared module pybind11_tests.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
      "------ pybind11_tests.cpython-36m-x86_64-linux-gnu.so file size: 2032248\n",
      "[ 95%] Built target pybind11_tests\n",
      "\u001b[35m\u001b[1mScanning dependencies of target cross_module_gil_utils\u001b[0m\n",
      "[ 97%] \u001b[32mBuilding CXX object tests/CMakeFiles/cross_module_gil_utils.dir/cross_module_gil_utils.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared module cross_module_gil_utils.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
      "[100%] Built target cross_module_gil_utils\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"MinSizeRel\"\n",
      "-- Installing: /usr/local/include/pybind11\n",
      "-- Installing: /usr/local/include/pybind11/eval.h\n",
      "-- Installing: /usr/local/include/pybind11/attr.h\n",
      "-- Installing: /usr/local/include/pybind11/chrono.h\n",
      "-- Installing: /usr/local/include/pybind11/common.h\n",
      "-- Installing: /usr/local/include/pybind11/functional.h\n",
      "-- Installing: /usr/local/include/pybind11/detail\n",
      "-- Installing: /usr/local/include/pybind11/detail/common.h\n",
      "-- Installing: /usr/local/include/pybind11/detail/internals.h\n",
      "-- Installing: /usr/local/include/pybind11/detail/descr.h\n",
      "-- Installing: /usr/local/include/pybind11/detail/class.h\n",
      "-- Installing: /usr/local/include/pybind11/detail/init.h\n",
      "-- Installing: /usr/local/include/pybind11/detail/typeid.h\n",
      "-- Installing: /usr/local/include/pybind11/stl.h\n",
      "-- Installing: /usr/local/include/pybind11/cast.h\n",
      "-- Installing: /usr/local/include/pybind11/embed.h\n",
      "-- Installing: /usr/local/include/pybind11/operators.h\n",
      "-- Installing: /usr/local/include/pybind11/stl_bind.h\n",
      "-- Installing: /usr/local/include/pybind11/complex.h\n",
      "-- Installing: /usr/local/include/pybind11/pytypes.h\n",
      "-- Installing: /usr/local/include/pybind11/numpy.h\n",
      "-- Installing: /usr/local/include/pybind11/eigen.h\n",
      "-- Installing: /usr/local/include/pybind11/iostream.h\n",
      "-- Installing: /usr/local/include/pybind11/options.h\n",
      "-- Installing: /usr/local/include/pybind11/pybind11.h\n",
      "-- Installing: /usr/local/include/pybind11/buffer_info.h\n",
      "-- Installing: /usr/local/share/cmake/pybind11/pybind11Config.cmake\n",
      "-- Installing: /usr/local/share/cmake/pybind11/pybind11ConfigVersion.cmake\n",
      "-- Installing: /usr/local/share/cmake/pybind11/FindPythonLibsNew.cmake\n",
      "-- Installing: /usr/local/share/cmake/pybind11/pybind11Common.cmake\n",
      "-- Installing: /usr/local/share/cmake/pybind11/pybind11Tools.cmake\n",
      "-- Installing: /usr/local/share/cmake/pybind11/pybind11NewTools.cmake\n",
      "-- Installing: /usr/local/share/cmake/pybind11/pybind11Targets.cmake\n"
     ]
    }
   ],
   "source": [
    "#Install pybind11\n",
    "!git clone https://github.com/pybind/pybind11.git\n",
    "!cd pybind11 && mkdir build && cd build && cmake .. && make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwAQeZFoM8IL",
    "outputId": "033d8f94-39b5-4fe6-f70d-cbfabcf3bea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  libeigen3-doc libmrpt-dev\n",
      "The following NEW packages will be installed:\n",
      "  libeigen3-dev\n",
      "0 upgraded, 1 newly installed, 0 to remove and 14 not upgraded.\n",
      "Need to get 810 kB of archives.\n",
      "After this operation, 7,128 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libeigen3-dev all 3.3.4-4 [810 kB]\n",
      "Fetched 810 kB in 1s (644 kB/s)\n",
      "Selecting previously unselected package libeigen3-dev.\n",
      "(Reading database ... 144865 files and directories currently installed.)\n",
      "Preparing to unpack .../libeigen3-dev_3.3.4-4_all.deb ...\n",
      "Unpacking libeigen3-dev (3.3.4-4) ...\n",
      "Setting up libeigen3-dev (3.3.4-4) ...\n"
     ]
    }
   ],
   "source": [
    "#Install Eigen\n",
    "!apt install libeigen3-dev\n",
    "!ln -sf /usr/include/eigen3/Eigen /usr/include/Eigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wohYNJjVNAs3",
    "outputId": "1a171c5e-0eae-43c3-f4f5-d973097e3ae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'DRL_robot_exploration'...\n",
      "remote: Enumerating objects: 179, done.\u001b[K\n",
      "remote: Counting objects: 100% (179/179), done.\u001b[K\n",
      "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
      "remote: Total 11228 (delta 107), reused 70 (delta 34), pack-reused 11049\u001b[K\n",
      "Receiving objects: 100% (11228/11228), 286.92 MiB | 34.20 MiB/s, done.\n",
      "Resolving deltas: 100% (200/200), done.\n",
      "Checking out files: 100% (10922/10922), done.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies on colab\n",
    "!git clone https://github.com/OttoJursch/DRL_robot_exploration.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tdbx9dj_zRQ_",
    "outputId": "b214c2f4-1889-49d4-cd57-84a22d4c92ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is GNU 7.5.0\n",
      "-- The CXX compiler identification is GNU 7.5.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Found PythonInterp: /usr/bin/python3 (found version \"3.6.9\") \n",
      "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so\n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- Found pybind11: /usr/local/include (found version \"2.6.2\" dev1)\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /content/DRL_robot_exploration/build\n",
      "\u001b[35m\u001b[1mScanning dependencies of target astar\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/astar.dir/src/astar.cpp.o\u001b[0m\n",
      "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/astar.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* pybind11_init()\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/astar.cpp:140:32:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kpybind11::module_::module_(const char*, const char*)\u001b[m\u001b[K’ is deprecated: Use PYBIND11_MODULE or module_::create_extension_module instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   py::module m(\"astar\", \"astar\"\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
      "                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/include/pybind11/numpy.h:12:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/include/pybind11/eigen.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/DRL_robot_exploration/src/astar.cpp:4\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/include/pybind11/pybind11.h:897:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "     explicit \u001b[01;36m\u001b[Kmodule_\u001b[m\u001b[K(const char *name, const char *doc = nullptr) {\n",
      "              \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module astar.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
      "[ 50%] Built target astar\n",
      "\u001b[35m\u001b[1mScanning dependencies of target inverse_sensor_model\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/inverse_sensor_model.dir/src/inverse_sensor_model.cpp.o\u001b[0m\n",
      "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/inverse_sensor_model.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* pybind11_init()\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/inverse_sensor_model.cpp:64:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kpybind11::module_::module_(const char*, const char*)\u001b[m\u001b[K’ is deprecated: Use PYBIND11_MODULE or module_::create_extension_module instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   py::module m(\"inverse_sensor_model\", \"inverse_sensor_model\"\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
      "                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/include/pybind11/numpy.h:12:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/include/pybind11/eigen.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/DRL_robot_exploration/src/inverse_sensor_model.cpp:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/include/pybind11/pybind11.h:897:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      "     explicit \u001b[01;36m\u001b[Kmodule_\u001b[m\u001b[K(const char *name, const char *doc = nullptr) {\n",
      "              \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared module inverse_sensor_model.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
      "[100%] Built target inverse_sensor_model\n"
     ]
    }
   ],
   "source": [
    "!#Build the C++/pybind stuff\n",
    "!rm -rf DRL_robot_exploration/build\n",
    "!cd DRL_robot_exploration && mkdir build && cd build && cmake .. && make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iH4Hccvf4Pdh",
    "outputId": "d4051532-3d7e-4165-859d-41820d206fba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!cd DRL_robot_exploration && git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop=True\n",
    "# laptop=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_5BsFx_f9ONI"
   },
   "outputs": [],
   "source": [
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "class PaperRewardFunction:\n",
    "    '''\n",
    "    Reward function from the paper\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_reward(self, robot_position, old_op_map, op_map, coll_index):\n",
    "        '''\n",
    "        Takes in map before step and map after step. Measures effect of sensor\n",
    "        input from last step\n",
    "        '''\n",
    "        if not coll_index:\n",
    "            reward = float(\n",
    "                np.size(np.where(op_map == 255)) -\n",
    "                np.size(np.where(old_op_map == 255))) / 14000\n",
    "            if reward > 1:\n",
    "                reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "        return reward\n",
    "\n",
    "\n",
    "class FrontierRewardFunction:\n",
    "    def __init__(self, reward_scale):\n",
    "        self.reward_scale = reward_scale\n",
    "        self.paper_reward = PaperRewardFunction()\n",
    "\n",
    "    def frontiers(self, op_map, map_size, points):\n",
    "        y_len = map_size[0]\n",
    "        x_len = map_size[1]\n",
    "        mapping = op_map.copy()\n",
    "        # 0-1 unknown area map\n",
    "        mapping = (mapping == 127) * 1\n",
    "        mapping = np.lib.pad(mapping, ((1, 1), (1, 1)),\n",
    "                             'constant',\n",
    "                             constant_values=0)\n",
    "        fro_map = mapping[2:][:, 1:x_len + 1] + mapping[:y_len][:, 1:x_len + 1] + mapping[1:y_len + 1][:, 2:] + \\\n",
    "                  mapping[1:y_len + 1][:, :x_len] + mapping[:y_len][:, 2:] + mapping[2:][:, :x_len] + mapping[2:][:,\n",
    "                                                                                                      2:] + \\\n",
    "                  mapping[:y_len][:, :x_len]\n",
    "\n",
    "        ind_free = np.where(op_map.ravel(order='F') == 255)[0]\n",
    "        ind_fron_1 = np.where(1 < fro_map.ravel(order='F'))[0]\n",
    "        ind_fron_2 = np.where(fro_map.ravel(order='F') < 8)[0]\n",
    "        ind_fron = np.intersect1d(ind_fron_1, ind_fron_2)\n",
    "        ind_to = np.intersect1d(ind_free, ind_fron)\n",
    "        f = points[ind_to]\n",
    "        f = f.astype(int)\n",
    "        return f\n",
    "\n",
    "    def map_points(self, map_glo):\n",
    "        map_x = map_glo.shape[1]\n",
    "        map_y = map_glo.shape[0]\n",
    "        x = np.linspace(0, map_x - 1, map_x)\n",
    "        y = np.linspace(0, map_y - 1, map_y)\n",
    "        t1, t2 = np.meshgrid(x, y)\n",
    "        points = np.vstack([t1.T.ravel(), t2.T.ravel()]).T\n",
    "        return points\n",
    "\n",
    "    def get_reward(self, robot_pos, old_op_map, op_map, coll_index):\n",
    "        paper_reward = self.paper_reward.get_reward(robot_pos, old_op_map,\n",
    "                                                    op_map, coll_index)\n",
    "\n",
    "        #If there was a collision return the collision reward\n",
    "        if coll_index:\n",
    "            print('collided??')\n",
    "            return paper_reward\n",
    "\n",
    "        frontiers = np.array(\n",
    "            self.frontiers(op_map, op_map.shape, self.map_points(op_map)))\n",
    "\n",
    "        min_frontier_dist = -np.min(np.linalg.norm(robot_pos - frontiers, axis=1))\n",
    "        return self.reward_scale * min_frontier_dist + paper_reward\n",
    "\n",
    "\n",
    "class PolarActionSpace:\n",
    "    '''\n",
    "    Action space is polar representation of vector robot should take from its\n",
    "    current position\n",
    "\n",
    "    This class will take that and add it to the current robot position to get \n",
    "    '''\n",
    "    def __init__(self, max_travel):\n",
    "        self.max_distance = max_travel\n",
    "\n",
    "    def get_action(self, action_polar_coords, robot_position):\n",
    "        angle = action_polar_coords[0] * (2 * np.pi)\n",
    "        dist = action_polar_coords[1] * self.max_distance\n",
    "        dx = dist * np.sin(angle)\n",
    "        dy = dist * np.cos(angle)\n",
    "\n",
    "        return np.array([dx, dy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "l08KzoEf_xt3"
   },
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import time\n",
    "import sys\n",
    "from scipy import ndimage\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('DRL_robot_exploration')\n",
    "if laptop:\n",
    "    from build.inverse_sensor_model import *\n",
    "    from build.astar import *\n",
    "else:\n",
    "    from DRL_robot_exploration.build.inverse_sensor_model import *\n",
    "    from DRL_robot_exploration.build.astar import *\n",
    "from random import shuffle\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "class Robot:\n",
    "    def __init__(self,\n",
    "                 index_map,\n",
    "                 train,\n",
    "                 plot,\n",
    "                 root_dir,\n",
    "                 action_space,\n",
    "                 reward_function,\n",
    "                 do_rescue,\n",
    "                 shuffle=True):\n",
    "        self.mode = train\n",
    "        self.action_space = action_space\n",
    "        self.plot = plot\n",
    "        self.root_dir = root_dir\n",
    "        self.index_map = index_map\n",
    "        self.do_rescue = do_rescue\n",
    "        self.reward_function = reward_function\n",
    "        self.reset(index_map, shuffle)\n",
    "\n",
    "    def reset(self, index_map=None, do_shuffle=True):\n",
    "        if self.mode:\n",
    "            self.map_dir = os.path.join(self.root_dir, 'train')\n",
    "        else:\n",
    "            self.map_dir = os.path.join(self.root_dir, 'test')\n",
    "        self.map_list = os.listdir(self.map_dir)\n",
    "        self.map_number = np.size(self.map_list)\n",
    "        if self.mode and do_shuffle:\n",
    "            shuffle(self.map_list)\n",
    "        if index_map is None:\n",
    "            index_map = random.choice(range(len(self.map_list)))\n",
    "        self.li_map = index_map\n",
    "        self.global_map, self.robot_position = self.map_setup(\n",
    "            self.map_dir + '/' + self.map_list[self.li_map])\n",
    "        # print('robot after map load', self.robot_position)\n",
    "        self.op_map = np.ones(self.global_map.shape) * 127\n",
    "        self.map_size = np.shape(self.global_map)\n",
    "        self.finish_percent = 0.985\n",
    "        self.resolution = 1\n",
    "        self.sensor_range = 80\n",
    "        self.old_position = np.zeros([2])\n",
    "        self.old_op_map = np.empty([0])\n",
    "        #current_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "        self.t = self.map_points(self.global_map)\n",
    "        self.free_tree = spatial.KDTree(\n",
    "            self.free_points(self.global_map).tolist())\n",
    "        self.robot_size = 6\n",
    "        self.local_size = 40\n",
    "        if self.plot:\n",
    "            self.xPoint = np.array([self.robot_position[0]])\n",
    "            self.yPoint = np.array([self.robot_position[1]])\n",
    "            self.x2frontier = np.empty([0])\n",
    "            self.y2frontier = np.empty([0])\n",
    "\n",
    "        # print('robot pos returned', self.robot_position)\n",
    "\n",
    "        return self.begin(), self.robot_position\n",
    "\n",
    "    def begin(self):\n",
    "        self.op_map = self.inverse_sensor(self.robot_position,\n",
    "                                          self.sensor_range, self.op_map,\n",
    "                                          self.global_map)\n",
    "        step_map = self.robot_model(self.robot_position, self.robot_size,\n",
    "                                    self.t, self.op_map)\n",
    "        map_local = self.local_map(self.robot_position, step_map,\n",
    "                                   self.map_size,\n",
    "                                   self.sensor_range + self.local_size)\n",
    "        if self.plot:\n",
    "            self.plot_env()\n",
    "        return self.op_map\n",
    "\n",
    "    def step(self, action_index):\n",
    "        terminal = False\n",
    "        complete = False\n",
    "        new_location = False\n",
    "        all_map = False\n",
    "        self.old_position = self.robot_position.copy()\n",
    "        self.old_op_map = self.op_map.copy()\n",
    "\n",
    "        # take action\n",
    "        self.take_action(action_index, self.robot_position)\n",
    "\n",
    "        # collision check\n",
    "        collision_points, collision_index = self.collision_check(\n",
    "            self.old_position, self.robot_position, self.map_size,\n",
    "            self.global_map)\n",
    "\n",
    "        if collision_index:\n",
    "            self.robot_position = self.nearest_free(self.free_tree,\n",
    "                                                    collision_points)\n",
    "            self.op_map = self.inverse_sensor(self.robot_position,\n",
    "                                              self.sensor_range, self.op_map,\n",
    "                                              self.global_map)\n",
    "            step_map = self.robot_model(self.robot_position, self.robot_size,\n",
    "                                        self.t, self.op_map)\n",
    "        else:\n",
    "            self.op_map = self.inverse_sensor(self.robot_position,\n",
    "                                              self.sensor_range, self.op_map,\n",
    "                                              self.global_map)\n",
    "            step_map = self.robot_model(self.robot_position, self.robot_size,\n",
    "                                        self.t, self.op_map)\n",
    "\n",
    "        map_local = self.local_map(self.robot_position, step_map,\n",
    "                                   self.map_size,\n",
    "                                   self.sensor_range + self.local_size)\n",
    "        reward = self.reward_function.get_reward(self.robot_position,\n",
    "                                                 self.old_op_map, self.op_map,\n",
    "                                                 collision_index)\n",
    "\n",
    "        if reward <= 0.02 and not collision_index:\n",
    "            reward = -0.8\n",
    "            new_location = True\n",
    "            #terminal = True\n",
    "\n",
    "        # during training, the robot is relocated if it has a collision\n",
    "        # during testing, the robot will use collision check to avoid the collision\n",
    "        if collision_index:\n",
    "            if not self.mode:\n",
    "                new_location = False\n",
    "                terminal = False\n",
    "            else:\n",
    "                new_location = True\n",
    "                terminal = True\n",
    "            if self.plot and self.mode:\n",
    "                self.xPoint = ma.append(self.xPoint, self.robot_position[0])\n",
    "                self.yPoint = ma.append(self.yPoint, self.robot_position[1])\n",
    "                self.plot_env()\n",
    "            self.robot_position = self.old_position.copy()\n",
    "            self.op_map = self.old_op_map.copy()\n",
    "            if self.plot and self.mode:\n",
    "                self.xPoint[self.xPoint.size - 1] = ma.masked\n",
    "                self.yPoint[self.yPoint.size - 1] = ma.masked\n",
    "        else:\n",
    "            if self.plot:\n",
    "                self.xPoint = ma.append(self.xPoint, self.robot_position[0])\n",
    "                self.yPoint = ma.append(self.yPoint, self.robot_position[1])\n",
    "                self.plot_env()\n",
    "\n",
    "        # check if exploration is finished\n",
    "        if np.size(np.where(self.op_map == 255)) / np.size(\n",
    "                np.where(self.global_map == 255)) > self.finish_percent:\n",
    "            self.li_map += 1\n",
    "            if self.li_map == self.map_number:\n",
    "                self.li_map = 0\n",
    "                all_map = True\n",
    "            self.__init__(self.li_map, self.mode, self.plot)\n",
    "            complete = True\n",
    "            new_location = False\n",
    "            terminal = True\n",
    "\n",
    "        return (\n",
    "            self.op_map, self.robot_position\n",
    "        ), reward, terminal, complete, new_location, collision_index, all_map\n",
    "\n",
    "    def rescuer(self):\n",
    "        complete = False\n",
    "        all_map = False\n",
    "        pre_position = self.robot_position.copy()\n",
    "        self.robot_position = self.frontier(self.op_map, self.map_size, self.t)\n",
    "        self.op_map = self.inverse_sensor(self.robot_position,\n",
    "                                          self.sensor_range, self.op_map,\n",
    "                                          self.global_map)\n",
    "        step_map = self.robot_model(self.robot_position, self.robot_size,\n",
    "                                    self.t, self.op_map)\n",
    "        map_local = self.local_map(self.robot_position, step_map,\n",
    "                                   self.map_size,\n",
    "                                   self.sensor_range + self.local_size)\n",
    "\n",
    "        if self.plot:\n",
    "            path = self.astar_path(self.op_map, pre_position.tolist(),\n",
    "                                   self.robot_position.tolist())\n",
    "            self.x2frontier = ma.append(self.x2frontier, ma.masked)\n",
    "            self.y2frontier = ma.append(self.y2frontier, ma.masked)\n",
    "            self.x2frontier = ma.append(self.x2frontier, path[1, :])\n",
    "            self.y2frontier = ma.append(self.y2frontier, path[0, :])\n",
    "            self.xPoint = ma.append(self.xPoint, ma.masked)\n",
    "            self.yPoint = ma.append(self.yPoint, ma.masked)\n",
    "            self.xPoint = ma.append(self.xPoint, self.robot_position[0])\n",
    "            self.yPoint = ma.append(self.yPoint, self.robot_position[1])\n",
    "            self.plot_env()\n",
    "\n",
    "        if np.size(np.where(self.op_map == 255)) / np.size(\n",
    "                np.where(self.global_map == 255)) > self.finish_percent:\n",
    "            self.li_map += 1\n",
    "            if self.li_map == self.map_number:\n",
    "                self.li_map = 0\n",
    "                all_map = True\n",
    "            self.__init__(self.li_map, self.mode, self.plot)\n",
    "            complete = True\n",
    "            new_location = False\n",
    "            terminal = True\n",
    "        return map_local, complete, all_map\n",
    "\n",
    "    def take_action(self, action_index, robot_position):\n",
    "        move_action = self.action_space.get_action(action_index,\n",
    "                                                   robot_position)\n",
    "        # print('move action', move_action)\n",
    "        # print('robot position', robot_position)\n",
    "        robot_position[0] = np.round(robot_position[0] + move_action[0])\n",
    "        robot_position[1] = np.round(robot_position[1] + move_action[1])\n",
    "\n",
    "    def map_setup(self, location):\n",
    "        global_map = (io.imread(location, 1) * 255).astype(int)\n",
    "        robot_location = np.nonzero(global_map == 208)\n",
    "        robot_location = np.array([\n",
    "            np.array(robot_location)[1, 127],\n",
    "            np.array(robot_location)[0, 127]\n",
    "        ])\n",
    "        global_map = (global_map > 150)\n",
    "        global_map = global_map * 254 + 1\n",
    "        return global_map, robot_location\n",
    "\n",
    "    def map_points(self, map_glo):\n",
    "        map_x = map_glo.shape[1]\n",
    "        map_y = map_glo.shape[0]\n",
    "        x = np.linspace(0, map_x - 1, map_x)\n",
    "        y = np.linspace(0, map_y - 1, map_y)\n",
    "        t1, t2 = np.meshgrid(x, y)\n",
    "        points = np.vstack([t1.T.ravel(), t2.T.ravel()]).T\n",
    "        return points\n",
    "\n",
    "    def local_map(self, robot_location, map_glo, map_size, local_size):\n",
    "        minX = robot_location[0] - local_size\n",
    "        maxX = robot_location[0] + local_size\n",
    "        minY = robot_location[1] - local_size\n",
    "        maxY = robot_location[1] + local_size\n",
    "\n",
    "        if minX < 0:\n",
    "            maxX = abs(minX) + maxX\n",
    "            minX = 0\n",
    "        if maxX > map_size[1]:\n",
    "            minX = minX - (maxX - map_size[1])\n",
    "            maxX = map_size[1]\n",
    "        if minY < 0:\n",
    "            maxY = abs(minY) + maxY\n",
    "            minY = 0\n",
    "        if maxY > map_size[0]:\n",
    "            minY = minY - (maxY - map_size[0])\n",
    "            maxY = map_size[0]\n",
    "\n",
    "        map_loc = map_glo[minY:maxY][:, minX:maxX]\n",
    "        return map_loc\n",
    "\n",
    "    def free_points(self, op_map):\n",
    "        index = np.where(op_map == 255)\n",
    "        free = np.asarray([index[1], index[0]]).T\n",
    "        return free\n",
    "\n",
    "    def nearest_free(self, tree, point):\n",
    "        pts = np.atleast_2d(point)\n",
    "        index = tuple(tree.query(pts)[1])\n",
    "        nearest = tree.data[index]\n",
    "        return nearest\n",
    "\n",
    "    def robot_model(self, position, robot_size, points, map_glo):\n",
    "        map_copy = map_glo.copy()\n",
    "        robot_points = self.range_search(position, robot_size, points)\n",
    "        for i in range(0, robot_points.shape[0]):\n",
    "            rob_loc = np.int32(robot_points[i, :])\n",
    "            rob_loc = np.flipud(rob_loc)\n",
    "            map_copy[tuple(rob_loc)] = 76\n",
    "        map_with_robot = map_copy\n",
    "        return map_with_robot\n",
    "\n",
    "    def range_search(self, position, r, points):\n",
    "        nvar = position.shape[0]\n",
    "        r2 = r**2\n",
    "        s = 0\n",
    "        for d in range(0, nvar):\n",
    "            s += (points[:, d] - position[d])**2\n",
    "        idx = np.nonzero(s <= r2)\n",
    "        idx = np.asarray(idx).ravel()\n",
    "        inrange_points = points[idx, :]\n",
    "        return inrange_points\n",
    "\n",
    "    def collision_check(self, start_point, end_point, map_size, map_glo):\n",
    "        x0, y0 = start_point.round()\n",
    "        x1, y1 = end_point.round()\n",
    "        dx, dy = abs(x1 - x0), abs(y1 - y0)\n",
    "        x, y = x0, y0\n",
    "        error = dx - dy\n",
    "        # print('coll dx', dx)\n",
    "        # print('coll dy', dy)\n",
    "        x_inc = 1 if x1 > x0 else -1\n",
    "        y_inc = 1 if y1 > y0 else -1\n",
    "        dx *= 2\n",
    "        dy *= 2\n",
    "\n",
    "        coll_points = np.ones((1, 2), np.uint8) * -1\n",
    "\n",
    "        while 0 <= x < map_size[1] and 0 <= y < map_size[0]:\n",
    "            k = map_glo.item(y, x)\n",
    "            if k == 1:\n",
    "                coll_points.itemset((0, 0), x)\n",
    "                coll_points.itemset((0, 1), y)\n",
    "                break\n",
    "\n",
    "            if x == end_point[0] and y == end_point[1]:\n",
    "                break\n",
    "\n",
    "            if error > 0:\n",
    "                x += x_inc\n",
    "                error -= dy\n",
    "            else:\n",
    "                y += y_inc\n",
    "                error += dx\n",
    "        if np.sum(coll_points) == -2:\n",
    "            coll_index = False\n",
    "        else:\n",
    "            coll_index = True\n",
    "\n",
    "        return coll_points, coll_index\n",
    "\n",
    "    def inverse_sensor(self, robot_position, sensor_range, op_map, map_glo):\n",
    "        op_map = inverse_sensor_model(robot_position[0], robot_position[1],\n",
    "                                      sensor_range, op_map, map_glo)\n",
    "        return op_map\n",
    "\n",
    "    def frontier(self, op_map, map_size, points):\n",
    "        y_len = map_size[0]\n",
    "        x_len = map_size[1]\n",
    "        mapping = op_map.copy()\n",
    "        # 0-1 unknown area map\n",
    "        mapping = (mapping == 127) * 1\n",
    "        mapping = np.lib.pad(mapping, ((1, 1), (1, 1)),\n",
    "                             'constant',\n",
    "                             constant_values=0)\n",
    "        fro_map = mapping[2:][:, 1:x_len + 1] + mapping[:y_len][:, 1:x_len + 1] + mapping[1:y_len + 1][:, 2:] + \\\n",
    "                  mapping[1:y_len + 1][:, :x_len] + mapping[:y_len][:, 2:] + mapping[2:][:, :x_len] + mapping[2:][:,\n",
    "                                                                                                      2:] + \\\n",
    "                  mapping[:y_len][:, :x_len]\n",
    "        ind_free = np.where(op_map.ravel(order='F') == 255)[0]\n",
    "        ind_fron_1 = np.where(1 < fro_map.ravel(order='F'))[0]\n",
    "        ind_fron_2 = np.where(fro_map.ravel(order='F') < 8)[0]\n",
    "        ind_fron = np.intersect1d(ind_fron_1, ind_fron_2)\n",
    "        ind_to = np.intersect1d(ind_free, ind_fron)\n",
    "        f = points[ind_to]\n",
    "        f = f.astype(int)\n",
    "        return f[0]\n",
    "\n",
    "    def unique_rows(self, a):\n",
    "        a = np.ascontiguousarray(a)\n",
    "        unique_a = np.unique(a.view([('', a.dtype)] * a.shape[1]))\n",
    "        result = unique_a.view(a.dtype).reshape(\n",
    "            (unique_a.shape[0], a.shape[1]))\n",
    "        result = result[~np.isnan(result).any(axis=1)]\n",
    "        return result\n",
    "\n",
    "    def astar_path(self, weights, start, goal, allow_diagonal=True):\n",
    "        temp_start = [start[1], start[0]]\n",
    "        temp_goal = [goal[1], goal[0]]\n",
    "        temp_weight = (weights < 150) * 254 + 1\n",
    "        # For the heuristic to be valid, each move must cost at least 1.\n",
    "        if temp_weight.min(axis=None) < 1.:\n",
    "            raise ValueError(\"Minimum cost to move must be 1, but got %f\" %\n",
    "                             (temp_weight.min(axis=None)))\n",
    "        # Ensure start is within bounds.\n",
    "        if (temp_start[0] < 0 or temp_start[0] >= temp_weight.shape[0]\n",
    "                or temp_start[1] < 0 or temp_start[1] >= temp_weight.shape[1]):\n",
    "            raise ValueError(\"Start lies outside grid.\")\n",
    "        # Ensure goal is within bounds.\n",
    "        if (temp_goal[0] < 0 or temp_goal[0] >= temp_weight.shape[0]\n",
    "                or temp_goal[1] < 0 or temp_goal[1] >= temp_weight.shape[1]):\n",
    "            raise ValueError(\"Goal of lies outside grid.\")\n",
    "\n",
    "        height, width = temp_weight.shape\n",
    "        start_idx = np.ravel_multi_index(temp_start, (height, width))\n",
    "        goal_idx = np.ravel_multi_index(temp_goal, (height, width))\n",
    "\n",
    "        path = astar(\n",
    "            temp_weight.flatten(),\n",
    "            height,\n",
    "            width,\n",
    "            start_idx,\n",
    "            goal_idx,\n",
    "            allow_diagonal,\n",
    "        )\n",
    "        return path\n",
    "\n",
    "    def plot_env(self):\n",
    "        print('plotting?')\n",
    "        plt.cla()\n",
    "        plt.imshow(self.op_map, cmap='gray')\n",
    "        plt.axis((0, self.map_size[1], self.map_size[0], 0))\n",
    "        plt.plot(self.xPoint, self.yPoint, 'b', linewidth=2)\n",
    "        plt.plot(self.x2frontier, self.y2frontier, 'r', linewidth=2)\n",
    "        plt.plot(self.robot_position[0],\n",
    "                 self.robot_position[1],\n",
    "                 'mo',\n",
    "                 markersize=8)\n",
    "        plt.plot(self.xPoint[0], self.yPoint[0], 'co', markersize=8)\n",
    "        plt.pause(0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edUqbZxCxIKW",
    "outputId": "95aca8ac-6479-475a-c15c-838155343484",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "[399 295]\n",
      "coll dx 15\n",
      "coll dy 0\n",
      "min_frontier_dist -66.73080248281148\n",
      "paper reward 0.03428571428571429\n",
      "reward -0.8\n",
      "robot loc [384 295]\n",
      "False\n",
      "coll dx 15\n",
      "coll dy 0\n",
      "min_frontier_dist -61.032778078668514\n",
      "paper reward 0.013285714285714286\n",
      "reward -0.8\n",
      "robot loc [369 295]\n",
      "False\n",
      "coll dx 15\n",
      "coll dy 0\n",
      "min_frontier_dist -58.137767414994535\n",
      "paper reward 0.0018571428571428571\n",
      "reward -0.8\n",
      "robot loc [354 295]\n",
      "False\n",
      "coll dx 15\n",
      "coll dy 0\n",
      "collided??\n",
      "reward -1\n",
      "robot loc [354 295]\n",
      "True\n",
      "coll dx 15\n",
      "coll dy 0\n",
      "collided??\n",
      "reward -1\n",
      "robot loc [354 295]\n",
      "True\n",
      "coll dx 15\n",
      "coll dy 0\n",
      "collided??\n",
      "reward -1\n",
      "robot loc [354 295]\n",
      "True\n",
      "coll dx 15\n",
      "coll dy 0\n",
      "collided??\n",
      "reward -1\n",
      "robot loc [354 295]\n",
      "True\n",
      "coll dx 15\n",
      "coll dy 0\n",
      "collided??\n",
      "reward -1\n",
      "robot loc [354 295]\n",
      "True\n",
      "coll dx 15\n",
      "coll dy 0\n",
      "collided??\n",
      "reward -1\n",
      "robot loc [354 295]\n",
      "True\n",
      "coll dx 15\n",
      "coll dy 0\n",
      "collided??\n",
      "reward -1\n",
      "robot loc [354 295]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "np.random.seed(1000)\n",
    "random.seed(10)\n",
    "\n",
    "reward_func = FrontierRewardFunction(1 / 80)\n",
    "action_space = PolarActionSpace(30)\n",
    "\n",
    "robot = Robot(0, True, False, 'DRL_robot_exploration/DungeonMaps',action_space,reward_func, False)\n",
    "\n",
    "test_action = np.array([0.75, 0.5])\n",
    "print('start')\n",
    "print(robot.robot_position)\n",
    "\n",
    "for i in range(10):\n",
    "  (map, loc), reward, terminal, complete, new_loc, collision, all_map = robot.step(test_action)\n",
    "  print('reward', reward)\n",
    "  print('robot loc', loc)\n",
    "  print(collision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YO_EJKEoNC6T"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchsummary\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "\n",
    "def build_conv_feature_extractor(conv_dims, act):\n",
    "  #Create Conv2D + MaxPool layers\n",
    "  conv_layers = [nn.Conv2d(*conv_dim) if len(conv_dim) == 3 else nn.MaxPool2d(conv_dim) for conv_dim in conv_dims]\n",
    "  total_layers = []\n",
    "\n",
    "  #Add ReLU activations after each conv layer\n",
    "  for layer in conv_layers:\n",
    "    total_layers.append(layer)\n",
    "    if type(layer) == nn.Conv2d:\n",
    "      total_layers.append(act())\n",
    "  return nn.Sequential(*total_layers)\n",
    "  \n",
    "\n",
    "def get_output_shape(model, image_dim):\n",
    "    return model(torch.rand(*(image_dim))).data.shape\n",
    "\n",
    "class RNNActor(nn.Module):\n",
    "  #TODO Determine if the action space allows negative numbers\n",
    "  #Potentially replace tanh with sigmoid\n",
    "  def __init__(self, conv_dims, lstm_hidden, train_length, input_size=(1, 1,84,84), act=nn.ReLU, final_act=nn.Sigmoid):\n",
    "    super(RNNActor, self).__init__()\n",
    "\n",
    "    self.conv_mod = build_conv_feature_extractor(conv_dims, act)\n",
    "    \n",
    "    #Silly way to determine the size going into the RNN\n",
    "    with torch.no_grad():\n",
    "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
    "\n",
    "#     print('LSTM Input Size', feature_size)\n",
    "\n",
    "    #Construct LSTM\n",
    "    self.lstm_hidden = lstm_hidden\n",
    "    self.lstm_input = np.prod(list(feature_size)) + 2\n",
    "    self.lstm = nn.LSTM(self.lstm_input, lstm_hidden)\n",
    "    self.linear = nn.Linear(lstm_hidden, 2)\n",
    "    self.train_length = train_length\n",
    "    self.final_act = final_act()\n",
    "\n",
    "  def forward(self, image, positions, lengths, hidden_state=None):\n",
    "#     print('sizes')\n",
    "#     print(image.size())\n",
    "#     print(positions.size())\n",
    "    batch_size = image.size()[1]\n",
    "    seq_length = image.size()[0]\n",
    "    conv = self.conv_mod(image.view((seq_length * batch_size, 1, 84, 84)))\n",
    "#     print('COnv out', conv.size())\n",
    "\n",
    "    flat = conv.view(-1).view(seq_length, batch_size, self.lstm_input - 2)\n",
    "#     print('sizes')\n",
    "#     print(flat.size())\n",
    "#     print(positions.size())\n",
    "    state = torch.cat((flat, positions), 2)\n",
    "#     print('state size')\n",
    "#     print(state.size())\n",
    "    packed = pack_padded_sequence(state, lengths, enforce_sorted=False)\n",
    "    if hidden_state is not None:\n",
    "      states, final_state = self.lstm(packed, hidden_state)\n",
    "    else:\n",
    "      states, final_state = self.lstm(packed)\n",
    "\n",
    "    unpacked, lengths = pad_packed_sequence(states)\n",
    "\n",
    "    final = self.linear(unpacked)\n",
    "    return self.final_act(final), final_state, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMUxifkjVCJE",
    "outputId": "5618c7dc-e3d6-4784-fbae-c5a56cc118c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Input Size torch.Size([1, 64, 49, 49])\n"
     ]
    }
   ],
   "source": [
    "conv_dims = [(1, 32, 8), (32, 64, 4), (2, 2), (64, 64, 3), (64, 512, 7), (2, 2), (512, 64, 1)]\n",
    "\n",
    "lstm_hidden = 512\n",
    "lstm_out = 2\n",
    "train_length = 8\n",
    "\n",
    "rnn = RNNActor(conv_dims, lstm_hidden, train_length).to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8RtwJ4Hhk65",
    "outputId": "bde5e4f7-cbec-4344-a075-037ac345948c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512])\n",
      "COnv out torch.Size([80, 64, 49, 49])\n",
      "Flattened COnv Feats torch.Size([8, 10, 153664])\n",
      "Conv Feats w/ Position Size torch.Size([8, 10, 153666])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch = torch.rand((train_length, 10, 1, 84, 84)).to(device='cuda')\n",
    "test_positions = torch.rand((train_length, 10, 2)).to(device='cuda')\n",
    "hidden = (torch.zeros((1, 10, lstm_hidden)).to(device='cuda'), torch.zeros((1, train_length, lstm_hidden)).to(device='cuda'))\n",
    "print(hidden[0].size())\n",
    "\n",
    "test, _ = rnn(test_batch, test_positions, [train_length] * 10)\n",
    "test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UgxUtoeMJ8Pa"
   },
   "outputs": [],
   "source": [
    "def build_dense_regression(linear_dims, act, final_act=None):\n",
    "  linear_layers = [nn.Linear(*linear_dim)  for linear_dim in linear_dims]\n",
    "  activations = [act() for layer in range(len(linear_layers) - 1)]\n",
    "  if final_act is not None:\n",
    "    activations.append(final_act)\n",
    "  else:\n",
    "    activations.append(nn.Identity())\n",
    "  return nn.Sequential(*[val for tup in zip(*[linear_layers, activations]) for val in tup]\n",
    ")\n",
    "\n",
    "class CNNCritic(nn.Module):\n",
    "  def __init__(self, conv_dims, fc_dims, input_size=(1, 1,84,84), conv_act=nn.ReLU, fc_act=nn.ReLU):\n",
    "    super(CNNCritic, self).__init__()\n",
    "    self.conv_mod = build_conv_feature_extractor(conv_dims, conv_act)\n",
    "\n",
    "    #Silly way to determine the size going into the RNN\n",
    "    with torch.no_grad():\n",
    "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
    "\n",
    "    #Add 4 for action + position\n",
    "    feature_size = np.prod(list(feature_size)) + 4\n",
    "    first_output = fc_dims[0][0]\n",
    "    fc_dims.insert(0, (feature_size, first_output))\n",
    "\n",
    "    self.fc = build_dense_regression(fc_dims, fc_act)\n",
    "#     print('regressor extract critic', self.fc)\n",
    "    self.fc_dims = feature_size\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "  def forward(self, map, positions, action):\n",
    "#     print('sizes')\n",
    "#     print(map.size())\n",
    "#     print(positions.size())\n",
    "    batch_size = map.size()[1]\n",
    "    seq_length =  map.size()[0]\n",
    "    conv = self.conv_mod(map.view((seq_length * batch_size, 1, 84, 84)))\n",
    "#     print('COnv out', conv.size())\n",
    "\n",
    "    flat = conv.view(-1).view(seq_length, batch_size, self.fc_dims - 4)\n",
    "#     print('sizes')\n",
    "#     print(flat.size())\n",
    "#     print(positions.size())\n",
    "#     print(action.size())\n",
    "    total_feats = torch.cat((flat, positions, action), 2)\n",
    "    return self.fc(total_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4Q7eTJfcJ7a",
    "outputId": "bcf864ac-3ba8-41e7-951d-6da52eb54b59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regressor extract critic Sequential(\n",
      "  (0): Linear(in_features=12548, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (5): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "linear_dims = [(256, 128), (128, 1)]\n",
    "conv_dims = [(1, 32, 8), (32, 64, 4), (2, 2), (64, 64, 3), (64, 512, 7), (2, 2), (512, 64, 1)]\n",
    "\n",
    "critic = CNNCritic(conv_dims, linear_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xFMjDGz1N958"
   },
   "outputs": [],
   "source": [
    "\"\"\" Learn a policy using DDPG for the reach task\"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torch.nn import MSELoss\n",
    "import random\n",
    "from skimage.transform import resize\n",
    "import itertools\n",
    "from itertools import zip_longest\n",
    "\n",
    "import gym\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import time\n",
    "\n",
    "# TODO: A function to soft update target networks\n",
    "def weighSync(target_model, source_model, tau=0.001):\n",
    "  for (target, src) in zip(target_model.parameters(), source_model.parameters()):\n",
    "    target.data = (1-tau) * target.data + tau * src.data \n",
    "\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "  '''Collect data into fixed-length chunks or blocks'''\n",
    "  # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
    "  args = [iter(iterable)] * n\n",
    "  return zip_longest(*args, fillvalue=fillvalue)\n",
    "\n",
    "# TODO: Write the ReplayBuffer\n",
    "class Replay():\n",
    "    def __init__(self, buffer_size, init_episodes, max_episode_length, sequence_length, action_dim, env, env_width, env_height):\n",
    "        \"\"\"\n",
    "        A function to initialize the replay buffer.\n",
    "\n",
    "        param: init_length : Initial number of transitions to collect\n",
    "        param: state_dim : Size of the state space\n",
    "        param: action_dim : Size of the action space\n",
    "        param: env : gym environment object\n",
    "        \"\"\"\n",
    "        self.buffer = [{}] * buffer_size\n",
    "        self.noise = MultivariateNormal(torch.zeros(2), torch.diag(torch.tensor([0.05, 0.05])))\n",
    "        self.sequence_length = sequence_length\n",
    "        self.max_episode_length = max_episode_length\n",
    "        self.env = env\n",
    "        state = self.env.reset()\n",
    "        self.env_width = env_width\n",
    "        self.env_height = env_height\n",
    "        self.buffer_idx = 0\n",
    "        self.total_steps = 0\n",
    "        last_state = env.reset()\n",
    "        init_policy = lambda map, pos, lengths: (torch.from_numpy(np.random.uniform(0.1, 0.9, (2,))).unsqueeze(0).unsqueeze(1), None, [1])\n",
    "        self.full_buffer = False\n",
    "        for episode in range(init_episodes):\n",
    "          episode = self.generate_episode(init_policy)\n",
    "\n",
    "    def generate_episode(self, policy):\n",
    "      episode = []\n",
    "      map, position = self.env.reset()\n",
    "      position = position.astype(np.float64)\n",
    "      map = resize(map, (84, 84))\n",
    "      map = ((map - 127) / 255) * 2\n",
    "      # print('position', position)\n",
    "\n",
    "      position[0] = position[0]/ 640.0\n",
    "      position[1] = position[1] / 480.0\n",
    "      last_map = torch.from_numpy(map).float()\n",
    "      last_position = torch.from_numpy(position).float()\n",
    "      # print('start position')\n",
    "      # print(last_position)\n",
    "      terminal = False\n",
    "\n",
    "      total_reward = 0\n",
    "      last_state = None\n",
    "      for i in range(self.max_episode_length):\n",
    "        if last_state is None:\n",
    "          action, last_state, lengths = policy(last_map.unsqueeze(0).unsqueeze(0).to(device='cuda'), last_position.unsqueeze(0).unsqueeze(0).to(device='cuda'), [1])\n",
    "        else:\n",
    "          # print('map size')\n",
    "          # print(last_map.size())\n",
    "          action, last_state, lengths = policy(last_map.unsqueeze(0).unsqueeze(0).to(device='cuda'), last_position.unsqueeze(0).unsqueeze(0).to(device='cuda'), [1], last_state)\n",
    "      \n",
    "      \n",
    "        action = action.cpu().squeeze(0).squeeze(1) + torch.clamp(self.noise.sample(), -0.25, 0.25) #TD3 requires noise to be clamped\n",
    "\n",
    "        action_np = action.detach().numpy().flatten()\n",
    "        # print('action_np')\n",
    "        # print(action_np)\n",
    "        action_np[0] = np.clip(action_np[0], 0, 1)\n",
    "        action_np[1] = np.clip(action_np[1], 0, 1)\n",
    "\n",
    "    \n",
    "\n",
    "        (map, loc), reward, terminal, complete, new_loc, collision, all_map = self.env.step(action_np)\n",
    "        map = resize(map, (84, 84))\n",
    "        map = ((map - 127) / 255) * 2\n",
    "        # print('unnormalized loc', loc)\n",
    "        loc = loc.astype(np.float64)\n",
    "        loc[0] = loc[0] / 640.0\n",
    "        loc[1] = loc[1] / 480.0\n",
    "\n",
    "        map_tensor = torch.from_numpy(map).float()\n",
    "        position_tensor = torch.from_numpy(loc).float()\n",
    "        # print('single position', position_tensor.size())\n",
    "        # print(position_tensor)\n",
    "        reward_tensor = torch.tensor(reward).float()\n",
    "        episode.append({'map': map_tensor, 'position': position_tensor, 'reward': reward_tensor, 'action': action.detach()})\n",
    "        last_map = map_tensor\n",
    "        last_position = position_tensor\n",
    "        total_reward += reward\n",
    "        if terminal:\n",
    "          break\n",
    "      # print('episode', episode)\n",
    "      sequences = self.episode_to_sequences(episode)\n",
    "      for sequence in sequences:\n",
    "        self.buffer[self.buffer_idx] = sequence\n",
    "        self.buffer_idx = (self.buffer_idx + 1) % len(self.buffer)\n",
    "        if self.buffer_idx == 0:\n",
    "          self.full_buffer = True\n",
    "\n",
    "      return total_reward\n",
    "    \n",
    "    def episode_to_sequences(self, episode):\n",
    "      sequences = []\n",
    "      last_idx = 0\n",
    "      for i in np.arange(self.sequence_length, len(episode), self.sequence_length):\n",
    "        window = episode[last_idx:i]\n",
    "        map_tensor = torch.cat([torch.unsqueeze(data['map'], 0) for data in window], 0)\n",
    "        position_tensor = torch.cat([torch.unsqueeze(data['position'], 0) for data in window], 0)\n",
    "        # print('position tensor', position_tensor)\n",
    "        reward_tensor = torch.cat([torch.unsqueeze(data['reward'], 0) for data in window], 0)\n",
    "        action_tensor = torch.cat([torch.unsqueeze(data['action'], 0) for data in window], 0)\n",
    "        sequences.append({'maps':map_tensor, 'positions': position_tensor, 'rewards': reward_tensor, 'actions':action_tensor, 'len':len(window)})\n",
    "        last_idx = i\n",
    "\n",
    "      window = episode[last_idx:]\n",
    "      map_tensor = torch.cat([torch.unsqueeze(data['map'], 0) for data in window], 0)\n",
    "      position_tensor = torch.cat([torch.unsqueeze(data['position'], 0) for data in window], 0)\n",
    "      # print('position tensor', position_tensor)\n",
    "      reward_tensor = torch.cat([torch.unsqueeze(data['reward'], 0) for data in window], 0)\n",
    "      action_tensor = torch.cat([torch.unsqueeze(data['action'], 0) for data in window], 0)\n",
    "      sequences.append({'maps':map_tensor, 'positions': position_tensor, 'rewards': reward_tensor, 'actions':action_tensor, 'len':len(window)})\n",
    "      return sequences\n",
    "    \n",
    "\n",
    "    #TODO: Complete the function\n",
    "    def buffer_sample(self, N):\n",
    "        \"\"\"\n",
    "        A function to sample N points from the buffer\n",
    "        param: N : Number of samples to obtain from the buffer\n",
    "        \"\"\"\n",
    "        # print('buffer idx', self.buffer_idx)\n",
    "        if self.full_buffer:\n",
    "          samples = random.sample(self.buffer, N)\n",
    "        else:\n",
    "          samples = random.sample(self.buffer[:self.buffer_idx], N)\n",
    "\n",
    "        return self.batchify(samples)\n",
    "\n",
    "    def batchify(self, samples):\n",
    "      \n",
    "      map_sequences = []\n",
    "      position_sequences = []\n",
    "      reward_sequences = []\n",
    "      action_sequences = []\n",
    "      seq_lens = []\n",
    "\n",
    "      for sequence in samples:\n",
    "        # print('sequence')\n",
    "        # print(sequence)\n",
    "\n",
    "        map_sequences.append(sequence['maps'])\n",
    "        # print('batchify')\n",
    "        # print('positions', sequence['positions'].size())\n",
    "        # print('rewards', sequence['rewards'].size())\n",
    "        # print('actions', sequence['actions'].size())\n",
    "        # print('maps', sequence['maps'].size())\n",
    "        position_sequences.append(sequence['positions'])\n",
    "        reward_sequences.append(sequence['rewards'])\n",
    "        action_sequences.append(sequence['actions'])\n",
    "        seq_lens.append(sequence['len'])\n",
    "\n",
    "      map_pad = pad_sequence(map_sequences).to(device='cuda').float()\n",
    "      pos_pad = pad_sequence(position_sequences).to(device='cuda').float()\n",
    "      reward_pad = pad_sequence(reward_sequences).to(device='cuda').float()\n",
    "      action_pad = pad_sequence(action_sequences).to(device='cuda').float()\n",
    "      seqs = seq_lens\n",
    "\n",
    "      return map_pad, pos_pad, reward_pad, action_pad, seqs\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ViFylKNVQgZ1"
   },
   "outputs": [],
   "source": [
    "class TD3():\n",
    "    def __init__(\n",
    "            self,\n",
    "            env,\n",
    "            replay,\n",
    "            conv_dims,\n",
    "            lstm_dim,\n",
    "            linear_dims,\n",
    "            sequence_length,\n",
    "            critic_lr=3e-4,\n",
    "            actor_lr=3e-4,\n",
    "            gamma=0.99,\n",
    "            batch_size=100,\n",
    "            buffer_size=10000,\n",
    "            init_episodes=1000,\n",
    "            max_episode_length=300\n",
    "\n",
    "    ):\n",
    "        \"\"\"\n",
    "        param: env: An gym environment\n",
    "        param: action_dim: Size of action space\n",
    "        param: state_dim: Size of state space\n",
    "        param: critic_lr: Learning rate of the critic\n",
    "        param: actor_lr: Learning rate of the actor\n",
    "        param: gamma: The discount factor\n",
    "        param: batch_size: The batch size for training\n",
    "        \"\"\"\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        reward_func = FrontierRewardFunction(1 / 80)\n",
    "        action_space = PolarActionSpace(30)\n",
    "#         self.env = Robot(0, True, False, 'DungeonMaps', action_space, reward_func, False)\n",
    "        self.env = env\n",
    "\n",
    "        self.actor = RNNActor(conv_dims, lstm_dim, sequence_length).to(device='cuda') #TODO conv_dims, lstm_hidden, train_length\n",
    "        self.actor_target = copy.deepcopy(self.actor).to(device='cuda') \n",
    "\n",
    "        self.critic1 = CNNCritic(conv_dims, linear_dims).to(device='cuda') #TODO conv_dims, fc_dims\n",
    "        self.critic1_target = copy.deepcopy(self.critic1).to(device='cuda')\n",
    "\n",
    "        self.critic2 = CNNCritic(conv_dims, linear_dims).to(device='cuda')\n",
    "        self.critic2_target = copy.deepcopy(self.critic2).to(device='cuda')\n",
    "\n",
    "        self.optimizer_actor = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "        self.optimizer_critic1 = optim.Adam(self.critic1.parameters(), lr=critic_lr)\n",
    "        self.optimizer_critic2 = optim.Adam(self.critic2.parameters(), lr=critic_lr)\n",
    "        # self.replay = Replay(buffer_size, init_episodes, max_episode_length, sequence_length, action_dim, env, env_width, env_height)\n",
    "        # self.replay = Replay(10000, 100, 300, 8, 2, robot, 640, 480)\n",
    "        self.replay = replay\n",
    "\n",
    "    def update_target_networks(self):\n",
    "        \"\"\"\n",
    "        A function to update the target networks\n",
    "        \"\"\"\n",
    "        weighSync(self.actor_target, self.actor)\n",
    "        weighSync(self.critic1_target, self.critic1)\n",
    "        weighSync(self.critic2_target, self.critic2)\n",
    "\n",
    "    def update_network(self, iter):\n",
    "        \"\"\"\n",
    "        A function to update the function just once\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        self.optimizer_critic1.zero_grad() \n",
    "        self.optimizer_critic2.zero_grad()\n",
    "\n",
    "        maps, positions, rewards, actions, lengths = self.replay.buffer_sample(self.batch_size)\n",
    "        # print('actions size',actions.size())\n",
    "        actions = actions.squeeze(2)\n",
    "\n",
    "        with torch.no_grad(): #Save gpu vram\n",
    "            target_action, _, _ = self.actor_target(maps, positions, lengths)\n",
    "            target_action = target_action.squeeze(2)\n",
    "            #Should be (seq_len, batch_size, 2)\n",
    "            #Should be (seq_len, batch_size, 1)\n",
    "            # print('target action', target_action.size())\n",
    "            crit1 = self.critic1_target(maps, positions, target_action)\n",
    "            crit2 = self.critic2_target(maps, positions, target_action)\n",
    "            # print('crit', crit1.size())\n",
    "            # print('rewards', rewards.size())\n",
    "        ys = rewards + self.gamma * torch.minimum(crit1.squeeze(2), crit2.squeeze(2)) #Use the minimum critic values\n",
    "\n",
    "        # print('updating')\n",
    "        # print('inputs')\n",
    "        # print(ys)\n",
    "        # print(maps)\n",
    "        # print(positions)\n",
    "        # print(actions)\n",
    "        # print(lengths)\n",
    "\n",
    "        # try:\n",
    "        qs1 = self.critic1(maps, positions, actions).squeeze(2)\n",
    "        #should be (seq_len, batch, 1)\n",
    "        # print('qs1', qs1.size())\n",
    "        #should be (seq_len, batch, 1)\n",
    "        # print('ys', ys.size(), 'qs1', qs1.size())\n",
    "        # critic1_loss = ((ys - qs1)**2).sum() / (self.sequence_length * self.batch_size)\n",
    "        critic1_loss = F.mse_loss(ys, qs1).mean()\n",
    "        critic1_loss.backward(retain_graph=True)\n",
    "        self.optimizer_critic1.step()\n",
    "\n",
    "        qs2 = self.critic2(maps, positions, actions).squeeze(2)\n",
    "        #should be (seq_len, batch, 1)\n",
    "        # print('qs2', qs2.size())\n",
    "        #should be (seq_len, batch, 1)\n",
    "        # print('ys', ys.size(), 'qs2', qs2.size())\n",
    "        # critic2_loss = ((ys - qs2)**2).sum() / (self.sequence_length * self.batch_size)\n",
    "        critic2_loss = F.mse_loss(ys, qs2).mean()\n",
    "        critic2_loss.backward()\n",
    "        self.optimizer_critic2.step()\n",
    "\n",
    "        if iter % 2 == 0: #Only update actor and target networks every two updates\n",
    "            self.optimizer_actor.zero_grad()\n",
    "            new_act, _, _ = self.actor(maps, positions, lengths)\n",
    "            # print('new_act', new_act.size())\n",
    "            qs = self.critic1(maps, positions, new_act)\n",
    "            # actor_loss = qs.sum() / (self.sequence_length * self.batch_size)\n",
    "            actor_loss = -qs.mean()\n",
    "            actor_loss.backward()\n",
    "            self.optimizer_actor.step()\n",
    "\n",
    "            self.update_target_networks()\n",
    "        # except RuntimeError:\n",
    "        #   print(iter)\n",
    "        #   print(\"crit1 loss size\")\n",
    "        #   print(critic1_loss.size())\n",
    "        #   print(\"ys size\")\n",
    "        #   print(ys.size())\n",
    "        #   print(\"qs1 size\")\n",
    "        #   print(qs1.size())\n",
    "        #   raise ValueError\n",
    "\n",
    "    def train(self, num_steps):\n",
    "        \"\"\"\n",
    "        Train the policy for the given number of iterations\n",
    "        :param num_steps:The number of steps to train the policy for\n",
    "        \"\"\"\n",
    "\n",
    "        i = 0\n",
    "        start = time.time()\n",
    "        while i < num_steps:\n",
    "            if i%10 == 0:\n",
    "                reward = self.replay.generate_episode(self.actor) #Generate episode with current actor and store into replay buffer\n",
    "\n",
    "            if i%100 == 0:\n",
    "                print('step {}'.format(i))\n",
    "                print('since start {}'.format(time.time() - start))\n",
    "                print(\"reward\" + str(reward))\n",
    "            self.update_network(i)\n",
    "            i += 1                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xjFt7JBRQVyT"
   },
   "outputs": [],
   "source": [
    "# reward_func = FrontierRewardFunction(1 / 14000)\n",
    "reward_func = PaperRewardFunction()\n",
    "action_space = PolarActionSpace(15)\n",
    "\n",
    "if laptop:\n",
    "    robot = Robot(0, True, False, 'DungeonMaps',action_space,reward_func, False)\n",
    "else:\n",
    "    robot = Robot(0, True, False, 'DRL_robot_exploration/DungeonMaps',action_space,reward_func, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCg-zeJMGV5U",
    "outputId": "f749094a-e496-4b56-96eb-61865a387ddb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "replay = Replay(1000, 50, 300, 8, 2, robot, 640, 480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ieHIP9WFQ0t5",
    "outputId": "2cab71fb-847a-4579-919d-bfe0cfe9d785"
   },
   "outputs": [],
   "source": [
    "linear_dims = [(256, 128), (128, 1)]\n",
    "# conv_dims = [(1, 32, 8), (32, 64, 4), (2, 2), (64, 64, 3), (64, 512, 7), (2, 2), (512, 64, 1)]\n",
    "conv_dims = [(1, 16, 8), (16, 32, 4), (2, 2), (32, 32, 3), (32, 256, 7), (2, 2), (256, 32, 1)]\n",
    "lstm_hidden = 512\n",
    "lstm_out = 2\n",
    "train_length = 8\n",
    "td3 = TD3(robot, replay, conv_dims, lstm_hidden, linear_dims, 8, batch_size=10, actor_lr=1e-4, critic_lr=1e-4) #actor_lr=1e-3, critic_lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbQtpI5A7l2D",
    "outputId": "21e894d7-2dcc-44ff-f0bf-c105e52551ab"
   },
   "outputs": [],
   "source": [
    "print('init seqs', td3.replay.buffer_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hsCYdcqISY73",
    "outputId": "9f659bd7-6df3-4690-da45-fea995f44591",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0\n",
      "since start 0.9378657341003418\n",
      "reward-8.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justinzsun/ece_276c/276cproj/lib/python3.7/site-packages/torch/nn/modules/rnn.py:585: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:775.)\n",
      "  self.num_layers, self.dropout, self.training, self.bidirectional)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 100\n",
      "since start 321.4592409133911\n",
      "reward-24.8727142857143\n",
      "step 200\n",
      "since start 659.3170382976532\n",
      "reward-95.27185714285693\n",
      "step 300\n",
      "since start 976.0433597564697\n",
      "reward-19.449857142857155\n",
      "step 400\n",
      "since start 1288.9768085479736\n",
      "reward-1.6057142857142859\n",
      "step 500\n",
      "since start 1601.539202928543\n",
      "reward-2.0727142857142855\n",
      "step 600\n",
      "since start 1911.1475286483765\n",
      "reward-6.249142857142857\n",
      "step 700\n",
      "since start 2223.096091032028\n",
      "reward-1.58\n",
      "step 800\n",
      "since start 2533.2580666542053\n",
      "reward-3.4000000000000004\n",
      "step 900\n",
      "since start 2841.5766565799713\n",
      "reward-3.4000000000000004\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "td3.train(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting?\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting?\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting?\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.054142857142857145\n",
      "plotting?\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-0.9458571428571428\n"
     ]
    }
   ],
   "source": [
    "test = Robot(0, True, True, 'DungeonMaps',action_space,reward_func, False)\n",
    "\n",
    "map, position = test.reset()\n",
    "position = position.astype(np.float64)\n",
    "map = resize(map, (84, 84))\n",
    "map = ((map - 127) / 255) * 2\n",
    "# print('position', position)\n",
    "\n",
    "position[0] = position[0]/ 640.0\n",
    "position[1] = position[1] / 480.0\n",
    "last_map = torch.from_numpy(map).float()\n",
    "last_position = torch.from_numpy(position).float()\n",
    "\n",
    "terminal = False\n",
    "total_reward = 0\n",
    "list_reward = []\n",
    "last_state = None\n",
    "for i in range(1000):\n",
    "    if last_state is None:\n",
    "      action, last_state, lengths = td3.actor(last_map.unsqueeze(0).unsqueeze(0).to(device='cuda'), last_position.unsqueeze(0).unsqueeze(0).to(device='cuda'), [1])\n",
    "    else:\n",
    "      # print('map size')\n",
    "      # print(last_map.size())\n",
    "      action, last_state, lengths = td3.actor(last_map.unsqueeze(0).unsqueeze(0).to(device='cuda'), last_position.unsqueeze(0).unsqueeze(0).to(device='cuda'), [1], last_state)\n",
    "\n",
    "\n",
    "    action = action.cpu().squeeze(0).squeeze(1) \n",
    "\n",
    "    action_np = action.detach().numpy().flatten()\n",
    "    # print('action_np')\n",
    "    # print(action_np)\n",
    "    action_np[0] = np.clip(action_np[0], 0, 1)\n",
    "    action_np[1] = np.clip(action_np[1], 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "    (map, loc), reward, terminal, complete, new_loc, collision, all_map = test.step(action_np)\n",
    "    map = resize(map, (84, 84))\n",
    "    map = ((map - 127) / 255) * 2\n",
    "    # print('unnormalized loc', loc)\n",
    "    loc = loc.astype(np.float64)\n",
    "    loc[0] = loc[0] / 640.0\n",
    "    loc[1] = loc[1] / 480.0\n",
    "\n",
    "    total_reward += reward\n",
    "    list_reward.append(reward)\n",
    "    print(reward)\n",
    "    if terminal:\n",
    "        print(total_reward)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3KSbEc30VzFm"
   },
   "outputs": [],
   "source": [
    "maps, positions, rewards, actions, lengths = td3.replay.buffer_sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "nqp0IdtswnVY"
   },
   "outputs": [],
   "source": [
    "critic1_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "pKg09-oqzBCz"
   },
   "outputs": [],
   "source": [
    "td3.optimizer_critic1.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "egs2OeckuvWP",
    "outputId": "e9433869-8b72-455c-f221-faa96953e3d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizes\n",
      "torch.Size([8, 2, 84, 84])\n",
      "torch.Size([8, 2, 2])\n",
      "COnv out torch.Size([16, 64, 14, 14])\n",
      "sizes\n",
      "torch.Size([8, 2, 12544])\n",
      "torch.Size([8, 2, 2])\n",
      "state size\n",
      "torch.Size([8, 2, 12546])\n",
      "sizes\n",
      "torch.Size([8, 2, 84, 84])\n",
      "torch.Size([8, 2, 2])\n",
      "COnv out torch.Size([16, 64, 14, 14])\n",
      "sizes\n",
      "torch.Size([8, 2, 12544])\n",
      "torch.Size([8, 2, 2])\n",
      "torch.Size([8, 2, 2])\n",
      "sizes\n",
      "torch.Size([8, 2, 84, 84])\n",
      "torch.Size([8, 2, 2])\n",
      "COnv out torch.Size([16, 64, 14, 14])\n",
      "sizes\n",
      "torch.Size([8, 2, 12544])\n",
      "torch.Size([8, 2, 2])\n",
      "torch.Size([8, 2, 2])\n",
      "sizes\n",
      "torch.Size([8, 2, 84, 84])\n",
      "torch.Size([8, 2, 2])\n",
      "COnv out torch.Size([16, 64, 14, 14])\n",
      "sizes\n",
      "torch.Size([8, 2, 12544])\n",
      "torch.Size([8, 2, 2])\n",
      "torch.Size([8, 2, 2])\n",
      "sizes\n",
      "torch.Size([8, 2, 84, 84])\n",
      "torch.Size([8, 2, 2])\n",
      "COnv out torch.Size([16, 64, 14, 14])\n",
      "sizes\n",
      "torch.Size([8, 2, 12544])\n",
      "torch.Size([8, 2, 2])\n",
      "state size\n",
      "torch.Size([8, 2, 12546])\n",
      "sizes\n",
      "torch.Size([8, 2, 84, 84])\n",
      "torch.Size([8, 2, 2])\n",
      "COnv out torch.Size([16, 64, 14, 14])\n",
      "sizes\n",
      "torch.Size([8, 2, 12544])\n",
      "torch.Size([8, 2, 2])\n",
      "torch.Size([8, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "actions = actions.squeeze(2)\n",
    "\n",
    "with torch.no_grad(): #Save gpu vram\n",
    "  target_action, _, _ = td3.actor_target(maps, positions, lengths)\n",
    "  target_action = target_action.squeeze(2)\n",
    "  #Should be (seq_len, batch_size, 2)\n",
    "  #Should be (seq_len, batch_size, 1)\n",
    "  # print('target action', target_action.size())\n",
    "  crit1 = td3.critic1_target(maps, positions, target_action)\n",
    "  crit2 = td3.critic2_target(maps, positions, target_action)\n",
    "  # print('crit', crit1.size())\n",
    "  # print('rewards', rewards.size())\n",
    "  ys = rewards + td3.gamma * torch.minimum(crit1.squeeze(2), crit2.squeeze(2)) #Use the minimum critic values\n",
    "\n",
    "\n",
    "qs1 = td3.critic1(maps, positions, actions).squeeze(2)\n",
    "#should be (seq_len, batch, 1)\n",
    "# print('qs1', qs1.size())\n",
    "#should be (seq_len, batch, 1)\n",
    "# print('ys', ys.size(), 'qs1', qs1.size())\n",
    "critic1_loss = ((ys - qs1)**2).sum() / (td3.sequence_length * td3.batch_size)\n",
    "\n",
    "new_act, _, _ = td3.actor(maps, positions, lengths)\n",
    "# print('new_act', new_act.size())\n",
    "qs = td3.critic1(maps, positions, new_act)\n",
    "actor_loss = qs.sum() / (td3.sequence_length * td3.batch_size)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DDPG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
