{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DDPG.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJBqQwnOM5hX",
        "outputId": "50de1877-0b91-4f32-df4d-29dd987b1be0"
      },
      "source": [
        "#Install pybind11\n",
        "!git clone https://github.com/pybind/pybind11.git\n",
        "!cd pybind11 && mkdir build && cd build && cmake .. && make install"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pybind11'...\n",
            "remote: Enumerating objects: 13933, done.\u001b[K\n",
            "remote: Total 13933 (delta 0), reused 0 (delta 0), pack-reused 13933\u001b[K\n",
            "Receiving objects: 100% (13933/13933), 5.39 MiB | 23.69 MiB/s, done.\n",
            "Resolving deltas: 100% (9485/9485), done.\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- pybind11 v2.6.2 dev1\n",
            "-- CMake 3.12.0\n",
            "-- Found PythonInterp: /usr/bin/python3.6 (found version \"3.6.9\") \n",
            "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so\n",
            "-- PYTHON 3.6.9\n",
            "-- Performing Test HAS_FLTO\n",
            "-- Performing Test HAS_FLTO - Success\n",
            "-- pybind11::lto enabled\n",
            "-- pybind11::thin_lto enabled\n",
            "-- Setting tests build type to MinSizeRel as none was specified\n",
            "-- Building tests WITHOUT Eigen, use -DDOWNLOAD_EIGEN on CMake 3.11+ to download\n",
            "-- Boost version: 1.65.1\n",
            "-- Found pytest 3.6.4\n",
            "-- Catch not detected. Interpreter tests will be skipped. Install Catch headers manually or use `cmake -DDOWNLOAD_CATCH=ON` to fetch them automatically.\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/pybind11/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target pybind11_cross_module_tests\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_cross_module_tests.dir/pybind11_cross_module_tests.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32m\u001b[1mLinking CXX shared module pybind11_cross_module_tests.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[  4%] Built target pybind11_cross_module_tests\n",
            "\u001b[35m\u001b[1mScanning dependencies of target pybind11_tests\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/pybind11_tests.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_async.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_buffers.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_builtin_casters.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_call_policies.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_callbacks.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_chrono.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_class.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_constants_and_functions.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_copy_move.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_custom_type_casters.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_docstring_options.cpp.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_enum.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_eval.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_exceptions.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_factory_constructors.cpp.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_gil_scoped.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_iostream.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_kwargs_and_defaults.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_local_bindings.cpp.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_methods_and_attributes.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_modules.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_multiple_inheritance.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_array.cpp.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_dtypes.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_numpy_vectorize.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_opaque_types.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_operator_overloading.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_pickling.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_pytypes.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_sequences_and_iterators.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_smart_ptr.cpp.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_stl.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_stl_binders.cpp.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_tagbased_polymorphic.cpp.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_union.cpp.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object tests/CMakeFiles/pybind11_tests.dir/test_virtual_functions.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX shared module pybind11_tests.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "------ pybind11_tests.cpython-36m-x86_64-linux-gnu.so file size: 2032248\n",
            "[ 95%] Built target pybind11_tests\n",
            "\u001b[35m\u001b[1mScanning dependencies of target cross_module_gil_utils\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object tests/CMakeFiles/cross_module_gil_utils.dir/cross_module_gil_utils.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared module cross_module_gil_utils.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[100%] Built target cross_module_gil_utils\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"MinSizeRel\"\n",
            "-- Installing: /usr/local/include/pybind11\n",
            "-- Installing: /usr/local/include/pybind11/eval.h\n",
            "-- Installing: /usr/local/include/pybind11/attr.h\n",
            "-- Installing: /usr/local/include/pybind11/chrono.h\n",
            "-- Installing: /usr/local/include/pybind11/common.h\n",
            "-- Installing: /usr/local/include/pybind11/functional.h\n",
            "-- Installing: /usr/local/include/pybind11/detail\n",
            "-- Installing: /usr/local/include/pybind11/detail/common.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/internals.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/descr.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/class.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/init.h\n",
            "-- Installing: /usr/local/include/pybind11/detail/typeid.h\n",
            "-- Installing: /usr/local/include/pybind11/stl.h\n",
            "-- Installing: /usr/local/include/pybind11/cast.h\n",
            "-- Installing: /usr/local/include/pybind11/embed.h\n",
            "-- Installing: /usr/local/include/pybind11/operators.h\n",
            "-- Installing: /usr/local/include/pybind11/stl_bind.h\n",
            "-- Installing: /usr/local/include/pybind11/complex.h\n",
            "-- Installing: /usr/local/include/pybind11/pytypes.h\n",
            "-- Installing: /usr/local/include/pybind11/numpy.h\n",
            "-- Installing: /usr/local/include/pybind11/eigen.h\n",
            "-- Installing: /usr/local/include/pybind11/iostream.h\n",
            "-- Installing: /usr/local/include/pybind11/options.h\n",
            "-- Installing: /usr/local/include/pybind11/pybind11.h\n",
            "-- Installing: /usr/local/include/pybind11/buffer_info.h\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Config.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11ConfigVersion.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/FindPythonLibsNew.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Common.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Tools.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11NewTools.cmake\n",
            "-- Installing: /usr/local/share/cmake/pybind11/pybind11Targets.cmake\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwAQeZFoM8IL",
        "outputId": "2ca613de-4e86-43e6-d394-0877e55a874a"
      },
      "source": [
        "#Install Eigen\n",
        "!apt install libeigen3-dev\n",
        "!ln -sf /usr/include/eigen3/Eigen /usr/include/Eigen"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libeigen3-doc libmrpt-dev\n",
            "The following NEW packages will be installed:\n",
            "  libeigen3-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 810 kB of archives.\n",
            "After this operation, 7,128 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libeigen3-dev all 3.3.4-4 [810 kB]\n",
            "Fetched 810 kB in 1s (732 kB/s)\n",
            "Selecting previously unselected package libeigen3-dev.\n",
            "(Reading database ... 144865 files and directories currently installed.)\n",
            "Preparing to unpack .../libeigen3-dev_3.3.4-4_all.deb ...\n",
            "Unpacking libeigen3-dev (3.3.4-4) ...\n",
            "Setting up libeigen3-dev (3.3.4-4) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wohYNJjVNAs3",
        "outputId": "5fe769e9-14fc-4118-e906-d645942acca9"
      },
      "source": [
        "# Install dependencies on colab\n",
        "!git clone https://github.com/OttoJursch/DRL_robot_exploration.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DRL_robot_exploration'...\n",
            "remote: Enumerating objects: 170, done.\u001b[K\n",
            "remote: Counting objects: 100% (170/170), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 11219 (delta 101), reused 71 (delta 34), pack-reused 11049\u001b[K\n",
            "Receiving objects: 100% (11219/11219), 286.89 MiB | 34.86 MiB/s, done.\n",
            "Resolving deltas: 100% (194/194), done.\n",
            "Checking out files: 100% (10922/10922), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdbx9dj_zRQ_",
        "outputId": "fb3db2c2-5134-4167-b85f-33694c77bc8a"
      },
      "source": [
        "!#Build the C++/pybind stuff\n",
        "!rm -rf DRL_robot_exploration/build\n",
        "!cd DRL_robot_exploration && mkdir build && cd build && cmake .. && make"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found PythonInterp: /usr/bin/python3 (found version \"3.6.9\") \n",
            "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so\n",
            "-- Performing Test HAS_FLTO\n",
            "-- Performing Test HAS_FLTO - Success\n",
            "-- Found pybind11: /usr/local/include (found version \"2.6.2\" dev1)\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/DRL_robot_exploration/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target astar\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/astar.dir/src/astar.cpp.o\u001b[0m\n",
            "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/astar.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* pybind11_init()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/astar.cpp:140:32:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kpybind11::module_::module_(const char*, const char*)\u001b[m\u001b[K’ is deprecated: Use PYBIND11_MODULE or module_::create_extension_module instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   py::module m(\"astar\", \"astar\"\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/include/pybind11/numpy.h:12:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/include/pybind11/eigen.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/DRL_robot_exploration/src/astar.cpp:4\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/include/pybind11/pybind11.h:897:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "     explicit \u001b[01;36m\u001b[Kmodule_\u001b[m\u001b[K(const char *name, const char *doc = nullptr) {\n",
            "              \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module astar.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[ 50%] Built target astar\n",
            "\u001b[35m\u001b[1mScanning dependencies of target inverse_sensor_model\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/inverse_sensor_model.dir/src/inverse_sensor_model.cpp.o\u001b[0m\n",
            "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/inverse_sensor_model.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* pybind11_init()\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/DRL_robot_exploration/src/inverse_sensor_model.cpp:64:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kpybind11::module_::module_(const char*, const char*)\u001b[m\u001b[K’ is deprecated: Use PYBIND11_MODULE or module_::create_extension_module instead [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   py::module m(\"inverse_sensor_model\", \"inverse_sensor_model\"\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/include/pybind11/numpy.h:12:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/include/pybind11/eigen.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/DRL_robot_exploration/src/inverse_sensor_model.cpp:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/include/pybind11/pybind11.h:897:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "     explicit \u001b[01;36m\u001b[Kmodule_\u001b[m\u001b[K(const char *name, const char *doc = nullptr) {\n",
            "              \u001b[01;36m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared module inverse_sensor_model.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
            "[100%] Built target inverse_sensor_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH4Hccvf4Pdh",
        "outputId": "434cf3f2-3c73-4af2-a57c-85c0164bb5a1"
      },
      "source": [
        "!cd DRL_robot_exploration && git pull"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5BsFx_f9ONI"
      },
      "source": [
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "class PaperRewardFunction:\n",
        "    '''\n",
        "    Reward function from the paper\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def get_reward(self, robot_position, old_op_map, op_map, coll_index):\n",
        "        '''\n",
        "        Takes in map before step and map after step. Measures effect of sensor\n",
        "        input from last step\n",
        "        '''\n",
        "        if not coll_index:\n",
        "            reward = float(\n",
        "                np.size(np.where(op_map == 255)) -\n",
        "                np.size(np.where(old_op_map == 255))) / 14000\n",
        "            if reward > 1:\n",
        "                reward = 1\n",
        "        else:\n",
        "            reward = -1\n",
        "        return reward\n",
        "\n",
        "\n",
        "class FrontierRewardFunction:\n",
        "    def __init__(self, reward_scale):\n",
        "        self.reward_scale = reward_scale\n",
        "        self.paper_reward = PaperRewardFunction()\n",
        "\n",
        "    def frontiers(self, op_map, map_size, points):\n",
        "        y_len = map_size[0]\n",
        "        x_len = map_size[1]\n",
        "        mapping = op_map.copy()\n",
        "        # 0-1 unknown area map\n",
        "        mapping = (mapping == 127) * 1\n",
        "        mapping = np.lib.pad(mapping, ((1, 1), (1, 1)),\n",
        "                             'constant',\n",
        "                             constant_values=0)\n",
        "        fro_map = mapping[2:][:, 1:x_len + 1] + mapping[:y_len][:, 1:x_len + 1] + mapping[1:y_len + 1][:, 2:] + \\\n",
        "                  mapping[1:y_len + 1][:, :x_len] + mapping[:y_len][:, 2:] + mapping[2:][:, :x_len] + mapping[2:][:,\n",
        "                                                                                                      2:] + \\\n",
        "                  mapping[:y_len][:, :x_len]\n",
        "\n",
        "        ind_free = np.where(op_map.ravel(order='F') == 255)[0]\n",
        "        ind_fron_1 = np.where(1 < fro_map.ravel(order='F'))[0]\n",
        "        ind_fron_2 = np.where(fro_map.ravel(order='F') < 8)[0]\n",
        "        ind_fron = np.intersect1d(ind_fron_1, ind_fron_2)\n",
        "        ind_to = np.intersect1d(ind_free, ind_fron)\n",
        "        f = points[ind_to]\n",
        "        f = f.astype(int)\n",
        "        return f\n",
        "\n",
        "    def map_points(self, map_glo):\n",
        "        map_x = map_glo.shape[1]\n",
        "        map_y = map_glo.shape[0]\n",
        "        x = np.linspace(0, map_x - 1, map_x)\n",
        "        y = np.linspace(0, map_y - 1, map_y)\n",
        "        t1, t2 = np.meshgrid(x, y)\n",
        "        points = np.vstack([t1.T.ravel(), t2.T.ravel()]).T\n",
        "        return points\n",
        "\n",
        "    def get_reward(self, robot_pos, old_op_map, op_map, coll_index):\n",
        "        paper_reward = self.paper_reward.get_reward(robot_pos, old_op_map,\n",
        "                                                    op_map, coll_index)\n",
        "\n",
        "        #If there was a collision return the collision reward\n",
        "        if coll_index:\n",
        "            print('collided??')\n",
        "            return paper_reward\n",
        "\n",
        "        frontiers = np.array(\n",
        "            self.frontiers(op_map, op_map.shape, self.map_points(op_map)))\n",
        "\n",
        "        min_frontier_dist = -np.min(np.linalg.norm(robot_pos - frontiers, axis=1))\n",
        "        return self.reward_scale * min_frontier_dist + paper_reward\n",
        "\n",
        "\n",
        "class PolarActionSpace:\n",
        "    '''\n",
        "    Action space is polar representation of vector robot should take from its\n",
        "    current position\n",
        "\n",
        "    This class will take that and add it to the current robot position to get \n",
        "    '''\n",
        "    def __init__(self, max_travel):\n",
        "        self.max_distance = max_travel\n",
        "\n",
        "    def get_action(self, action_polar_coords, robot_position):\n",
        "        angle = action_polar_coords[0] * (2 * np.pi)\n",
        "        dist = action_polar_coords[1] * self.max_distance\n",
        "        dx = dist * np.sin(angle)\n",
        "        dy = dist * np.cos(angle)\n",
        "\n",
        "        return np.array([dx, dy])\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8AD6ZvCPBcj",
        "outputId": "5a8b3136-b2d6-4230-c1dc-c0a0d53b844e"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DRL_robot_exploration  pybind11  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l08KzoEf_xt3"
      },
      "source": [
        "from scipy import spatial\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import numpy.ma as ma\n",
        "import time\n",
        "import sys\n",
        "from scipy import ndimage\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sys.path.append('DRL_robot_exploration')\n",
        "from DRL_robot_exploration.build.inverse_sensor_model import *\n",
        "from DRL_robot_exploration.build.astar import *\n",
        "from random import shuffle\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "class Robot:\n",
        "    def __init__(self,\n",
        "                 index_map,\n",
        "                 train,\n",
        "                 plot,\n",
        "                 root_dir,\n",
        "                 action_space,\n",
        "                 reward_function,\n",
        "                 do_rescue,\n",
        "                 shuffle=True):\n",
        "        self.mode = train\n",
        "        self.action_space = action_space\n",
        "        self.plot = plot\n",
        "        self.root_dir = root_dir\n",
        "        self.index_map = index_map\n",
        "        self.do_rescue = do_rescue\n",
        "        self.reward_function = reward_function\n",
        "        self.reset(index_map, shuffle)\n",
        "\n",
        "    def reset(self, index_map=None, do_shuffle=True):\n",
        "        if self.mode:\n",
        "            self.map_dir = os.path.join(self.root_dir, 'train')\n",
        "        else:\n",
        "            self.map_dir = os.path.join(self.root_dir, 'test')\n",
        "        self.map_list = os.listdir(self.map_dir)\n",
        "        self.map_number = np.size(self.map_list)\n",
        "        if self.mode and do_shuffle:\n",
        "            shuffle(self.map_list)\n",
        "        if index_map is None:\n",
        "            index_map = random.choice(range(len(self.map_list)))\n",
        "        self.li_map = index_map\n",
        "        self.global_map, self.robot_position = self.map_setup(\n",
        "            self.map_dir + '/' + self.map_list[self.li_map])\n",
        "        # print('robot after map load', self.robot_position)\n",
        "        self.op_map = np.ones(self.global_map.shape) * 127\n",
        "        self.map_size = np.shape(self.global_map)\n",
        "        self.finish_percent = 0.985\n",
        "        self.resolution = 1\n",
        "        self.sensor_range = 80\n",
        "        self.old_position = np.zeros([2])\n",
        "        self.old_op_map = np.empty([0])\n",
        "        #current_dir = os.path.dirname(os.path.realpath(__file__))\n",
        "        self.t = self.map_points(self.global_map)\n",
        "        self.free_tree = spatial.KDTree(\n",
        "            self.free_points(self.global_map).tolist())\n",
        "        self.robot_size = 6\n",
        "        self.local_size = 40\n",
        "        if self.plot:\n",
        "            self.xPoint = np.array([self.robot_position[0]])\n",
        "            self.yPoint = np.array([self.robot_position[1]])\n",
        "            self.x2frontier = np.empty([0])\n",
        "            self.y2frontier = np.empty([0])\n",
        "\n",
        "        # print('robot pos returned', self.robot_position)\n",
        "\n",
        "        return self.begin(), self.robot_position\n",
        "\n",
        "    def begin(self):\n",
        "        self.op_map = self.inverse_sensor(self.robot_position,\n",
        "                                          self.sensor_range, self.op_map,\n",
        "                                          self.global_map)\n",
        "        step_map = self.robot_model(self.robot_position, self.robot_size,\n",
        "                                    self.t, self.op_map)\n",
        "        map_local = self.local_map(self.robot_position, step_map,\n",
        "                                   self.map_size,\n",
        "                                   self.sensor_range + self.local_size)\n",
        "        if self.plot:\n",
        "            self.plot_env()\n",
        "        return self.op_map\n",
        "\n",
        "    def step(self, action_index):\n",
        "        terminal = False\n",
        "        complete = False\n",
        "        new_location = False\n",
        "        all_map = False\n",
        "        self.old_position = self.robot_position.copy()\n",
        "        self.old_op_map = self.op_map.copy()\n",
        "\n",
        "        # take action\n",
        "        self.take_action(action_index, self.robot_position)\n",
        "\n",
        "        # collision check\n",
        "        collision_points, collision_index = self.collision_check(\n",
        "            self.old_position, self.robot_position, self.map_size,\n",
        "            self.global_map)\n",
        "\n",
        "        if collision_index:\n",
        "            self.robot_position = self.nearest_free(self.free_tree,\n",
        "                                                    collision_points)\n",
        "            self.op_map = self.inverse_sensor(self.robot_position,\n",
        "                                              self.sensor_range, self.op_map,\n",
        "                                              self.global_map)\n",
        "            step_map = self.robot_model(self.robot_position, self.robot_size,\n",
        "                                        self.t, self.op_map)\n",
        "        else:\n",
        "            self.op_map = self.inverse_sensor(self.robot_position,\n",
        "                                              self.sensor_range, self.op_map,\n",
        "                                              self.global_map)\n",
        "            step_map = self.robot_model(self.robot_position, self.robot_size,\n",
        "                                        self.t, self.op_map)\n",
        "\n",
        "        map_local = self.local_map(self.robot_position, step_map,\n",
        "                                   self.map_size,\n",
        "                                   self.sensor_range + self.local_size)\n",
        "        reward = self.reward_function.get_reward(self.robot_position,\n",
        "                                                 self.old_op_map, self.op_map,\n",
        "                                                 collision_index)\n",
        "\n",
        "        if reward <= 0.02 and not collision_index:\n",
        "            reward = -0.8\n",
        "            new_location = True\n",
        "            #terminal = True\n",
        "\n",
        "        # during training, the robot is relocated if it has a collision\n",
        "        # during testing, the robot will use collision check to avoid the collision\n",
        "        if collision_index:\n",
        "            if not self.mode:\n",
        "                new_location = False\n",
        "                terminal = False\n",
        "            else:\n",
        "                new_location = True\n",
        "                terminal = True\n",
        "            if self.plot and self.mode:\n",
        "                self.xPoint = ma.append(self.xPoint, self.robot_position[0])\n",
        "                self.yPoint = ma.append(self.yPoint, self.robot_position[1])\n",
        "                self.plot_env()\n",
        "            self.robot_position = self.old_position.copy()\n",
        "            self.op_map = self.old_op_map.copy()\n",
        "            if self.plot and self.mode:\n",
        "                self.xPoint[self.xPoint.size - 1] = ma.masked\n",
        "                self.yPoint[self.yPoint.size - 1] = ma.masked\n",
        "        else:\n",
        "            if self.plot:\n",
        "                self.xPoint = ma.append(self.xPoint, self.robot_position[0])\n",
        "                self.yPoint = ma.append(self.yPoint, self.robot_position[1])\n",
        "                self.plot_env()\n",
        "\n",
        "        # check if exploration is finished\n",
        "        if np.size(np.where(self.op_map == 255)) / np.size(\n",
        "                np.where(self.global_map == 255)) > self.finish_percent:\n",
        "            self.li_map += 1\n",
        "            if self.li_map == self.map_number:\n",
        "                self.li_map = 0\n",
        "                all_map = True\n",
        "            self.__init__(self.li_map, self.mode, self.plot)\n",
        "            complete = True\n",
        "            new_location = False\n",
        "            terminal = True\n",
        "\n",
        "        return (\n",
        "            self.op_map, self.robot_position\n",
        "        ), reward, terminal, complete, new_location, collision_index, all_map\n",
        "\n",
        "    def rescuer(self):\n",
        "        complete = False\n",
        "        all_map = False\n",
        "        pre_position = self.robot_position.copy()\n",
        "        self.robot_position = self.frontier(self.op_map, self.map_size, self.t)\n",
        "        self.op_map = self.inverse_sensor(self.robot_position,\n",
        "                                          self.sensor_range, self.op_map,\n",
        "                                          self.global_map)\n",
        "        step_map = self.robot_model(self.robot_position, self.robot_size,\n",
        "                                    self.t, self.op_map)\n",
        "        map_local = self.local_map(self.robot_position, step_map,\n",
        "                                   self.map_size,\n",
        "                                   self.sensor_range + self.local_size)\n",
        "\n",
        "        if self.plot:\n",
        "            path = self.astar_path(self.op_map, pre_position.tolist(),\n",
        "                                   self.robot_position.tolist())\n",
        "            self.x2frontier = ma.append(self.x2frontier, ma.masked)\n",
        "            self.y2frontier = ma.append(self.y2frontier, ma.masked)\n",
        "            self.x2frontier = ma.append(self.x2frontier, path[1, :])\n",
        "            self.y2frontier = ma.append(self.y2frontier, path[0, :])\n",
        "            self.xPoint = ma.append(self.xPoint, ma.masked)\n",
        "            self.yPoint = ma.append(self.yPoint, ma.masked)\n",
        "            self.xPoint = ma.append(self.xPoint, self.robot_position[0])\n",
        "            self.yPoint = ma.append(self.yPoint, self.robot_position[1])\n",
        "            self.plot_env()\n",
        "\n",
        "        if np.size(np.where(self.op_map == 255)) / np.size(\n",
        "                np.where(self.global_map == 255)) > self.finish_percent:\n",
        "            self.li_map += 1\n",
        "            if self.li_map == self.map_number:\n",
        "                self.li_map = 0\n",
        "                all_map = True\n",
        "            self.__init__(self.li_map, self.mode, self.plot)\n",
        "            complete = True\n",
        "            new_location = False\n",
        "            terminal = True\n",
        "        return map_local, complete, all_map\n",
        "\n",
        "    def take_action(self, action_index, robot_position):\n",
        "        move_action = self.action_space.get_action(action_index,\n",
        "                                                   robot_position)\n",
        "        # print('move action', move_action)\n",
        "        # print('robot position', robot_position)\n",
        "        robot_position[0] = np.round(robot_position[0] + move_action[0])\n",
        "        robot_position[1] = np.round(robot_position[1] + move_action[1])\n",
        "\n",
        "    def map_setup(self, location):\n",
        "        global_map = (io.imread(location, 1) * 255).astype(int)\n",
        "        robot_location = np.nonzero(global_map == 208)\n",
        "        robot_location = np.array([\n",
        "            np.array(robot_location)[1, 127],\n",
        "            np.array(robot_location)[0, 127]\n",
        "        ])\n",
        "        global_map = (global_map > 150)\n",
        "        global_map = global_map * 254 + 1\n",
        "        return global_map, robot_location\n",
        "\n",
        "    def map_points(self, map_glo):\n",
        "        map_x = map_glo.shape[1]\n",
        "        map_y = map_glo.shape[0]\n",
        "        x = np.linspace(0, map_x - 1, map_x)\n",
        "        y = np.linspace(0, map_y - 1, map_y)\n",
        "        t1, t2 = np.meshgrid(x, y)\n",
        "        points = np.vstack([t1.T.ravel(), t2.T.ravel()]).T\n",
        "        return points\n",
        "\n",
        "    def local_map(self, robot_location, map_glo, map_size, local_size):\n",
        "        minX = robot_location[0] - local_size\n",
        "        maxX = robot_location[0] + local_size\n",
        "        minY = robot_location[1] - local_size\n",
        "        maxY = robot_location[1] + local_size\n",
        "\n",
        "        if minX < 0:\n",
        "            maxX = abs(minX) + maxX\n",
        "            minX = 0\n",
        "        if maxX > map_size[1]:\n",
        "            minX = minX - (maxX - map_size[1])\n",
        "            maxX = map_size[1]\n",
        "        if minY < 0:\n",
        "            maxY = abs(minY) + maxY\n",
        "            minY = 0\n",
        "        if maxY > map_size[0]:\n",
        "            minY = minY - (maxY - map_size[0])\n",
        "            maxY = map_size[0]\n",
        "\n",
        "        map_loc = map_glo[minY:maxY][:, minX:maxX]\n",
        "        return map_loc\n",
        "\n",
        "    def free_points(self, op_map):\n",
        "        index = np.where(op_map == 255)\n",
        "        free = np.asarray([index[1], index[0]]).T\n",
        "        return free\n",
        "\n",
        "    def nearest_free(self, tree, point):\n",
        "        pts = np.atleast_2d(point)\n",
        "        index = tuple(tree.query(pts)[1])\n",
        "        nearest = tree.data[index]\n",
        "        return nearest\n",
        "\n",
        "    def robot_model(self, position, robot_size, points, map_glo):\n",
        "        map_copy = map_glo.copy()\n",
        "        robot_points = self.range_search(position, robot_size, points)\n",
        "        for i in range(0, robot_points.shape[0]):\n",
        "            rob_loc = np.int32(robot_points[i, :])\n",
        "            rob_loc = np.flipud(rob_loc)\n",
        "            map_copy[tuple(rob_loc)] = 76\n",
        "        map_with_robot = map_copy\n",
        "        return map_with_robot\n",
        "\n",
        "    def range_search(self, position, r, points):\n",
        "        nvar = position.shape[0]\n",
        "        r2 = r**2\n",
        "        s = 0\n",
        "        for d in range(0, nvar):\n",
        "            s += (points[:, d] - position[d])**2\n",
        "        idx = np.nonzero(s <= r2)\n",
        "        idx = np.asarray(idx).ravel()\n",
        "        inrange_points = points[idx, :]\n",
        "        return inrange_points\n",
        "\n",
        "    def collision_check(self, start_point, end_point, map_size, map_glo):\n",
        "        x0, y0 = start_point.round()\n",
        "        x1, y1 = end_point.round()\n",
        "        dx, dy = abs(x1 - x0), abs(y1 - y0)\n",
        "        x, y = x0, y0\n",
        "        error = dx - dy\n",
        "        # print('coll dx', dx)\n",
        "        # print('coll dy', dy)\n",
        "        x_inc = 1 if x1 > x0 else -1\n",
        "        y_inc = 1 if y1 > y0 else -1\n",
        "        dx *= 2\n",
        "        dy *= 2\n",
        "\n",
        "        coll_points = np.ones((1, 2), np.uint8) * -1\n",
        "\n",
        "        while 0 <= x < map_size[1] and 0 <= y < map_size[0]:\n",
        "            k = map_glo.item(y, x)\n",
        "            if k == 1:\n",
        "                coll_points.itemset((0, 0), x)\n",
        "                coll_points.itemset((0, 1), y)\n",
        "                break\n",
        "\n",
        "            if x == end_point[0] and y == end_point[1]:\n",
        "                break\n",
        "\n",
        "            if error > 0:\n",
        "                x += x_inc\n",
        "                error -= dy\n",
        "            else:\n",
        "                y += y_inc\n",
        "                error += dx\n",
        "        if np.sum(coll_points) == -2:\n",
        "            coll_index = False\n",
        "        else:\n",
        "            coll_index = True\n",
        "\n",
        "        return coll_points, coll_index\n",
        "\n",
        "    def inverse_sensor(self, robot_position, sensor_range, op_map, map_glo):\n",
        "        op_map = inverse_sensor_model(robot_position[0], robot_position[1],\n",
        "                                      sensor_range, op_map, map_glo)\n",
        "        return op_map\n",
        "\n",
        "    def frontier(self, op_map, map_size, points):\n",
        "        y_len = map_size[0]\n",
        "        x_len = map_size[1]\n",
        "        mapping = op_map.copy()\n",
        "        # 0-1 unknown area map\n",
        "        mapping = (mapping == 127) * 1\n",
        "        mapping = np.lib.pad(mapping, ((1, 1), (1, 1)),\n",
        "                             'constant',\n",
        "                             constant_values=0)\n",
        "        fro_map = mapping[2:][:, 1:x_len + 1] + mapping[:y_len][:, 1:x_len + 1] + mapping[1:y_len + 1][:, 2:] + \\\n",
        "                  mapping[1:y_len + 1][:, :x_len] + mapping[:y_len][:, 2:] + mapping[2:][:, :x_len] + mapping[2:][:,\n",
        "                                                                                                      2:] + \\\n",
        "                  mapping[:y_len][:, :x_len]\n",
        "        ind_free = np.where(op_map.ravel(order='F') == 255)[0]\n",
        "        ind_fron_1 = np.where(1 < fro_map.ravel(order='F'))[0]\n",
        "        ind_fron_2 = np.where(fro_map.ravel(order='F') < 8)[0]\n",
        "        ind_fron = np.intersect1d(ind_fron_1, ind_fron_2)\n",
        "        ind_to = np.intersect1d(ind_free, ind_fron)\n",
        "        f = points[ind_to]\n",
        "        f = f.astype(int)\n",
        "        return f[0]\n",
        "\n",
        "    def unique_rows(self, a):\n",
        "        a = np.ascontiguousarray(a)\n",
        "        unique_a = np.unique(a.view([('', a.dtype)] * a.shape[1]))\n",
        "        result = unique_a.view(a.dtype).reshape(\n",
        "            (unique_a.shape[0], a.shape[1]))\n",
        "        result = result[~np.isnan(result).any(axis=1)]\n",
        "        return result\n",
        "\n",
        "    def astar_path(self, weights, start, goal, allow_diagonal=True):\n",
        "        temp_start = [start[1], start[0]]\n",
        "        temp_goal = [goal[1], goal[0]]\n",
        "        temp_weight = (weights < 150) * 254 + 1\n",
        "        # For the heuristic to be valid, each move must cost at least 1.\n",
        "        if temp_weight.min(axis=None) < 1.:\n",
        "            raise ValueError(\"Minimum cost to move must be 1, but got %f\" %\n",
        "                             (temp_weight.min(axis=None)))\n",
        "        # Ensure start is within bounds.\n",
        "        if (temp_start[0] < 0 or temp_start[0] >= temp_weight.shape[0]\n",
        "                or temp_start[1] < 0 or temp_start[1] >= temp_weight.shape[1]):\n",
        "            raise ValueError(\"Start lies outside grid.\")\n",
        "        # Ensure goal is within bounds.\n",
        "        if (temp_goal[0] < 0 or temp_goal[0] >= temp_weight.shape[0]\n",
        "                or temp_goal[1] < 0 or temp_goal[1] >= temp_weight.shape[1]):\n",
        "            raise ValueError(\"Goal of lies outside grid.\")\n",
        "\n",
        "        height, width = temp_weight.shape\n",
        "        start_idx = np.ravel_multi_index(temp_start, (height, width))\n",
        "        goal_idx = np.ravel_multi_index(temp_goal, (height, width))\n",
        "\n",
        "        path = astar(\n",
        "            temp_weight.flatten(),\n",
        "            height,\n",
        "            width,\n",
        "            start_idx,\n",
        "            goal_idx,\n",
        "            allow_diagonal,\n",
        "        )\n",
        "        return path\n",
        "\n",
        "    def plot_env(self):\n",
        "        print('plotting?')\n",
        "        plt.cla()\n",
        "        plt.imshow(self.op_map, cmap='gray')\n",
        "        plt.axis((0, self.map_size[1], self.map_size[0], 0))\n",
        "        plt.plot(self.xPoint, self.yPoint, 'b', linewidth=2)\n",
        "        plt.plot(self.x2frontier, self.y2frontier, 'r', linewidth=2)\n",
        "        plt.plot(self.robot_position[0],\n",
        "                 self.robot_position[1],\n",
        "                 'mo',\n",
        "                 markersize=8)\n",
        "        plt.plot(self.xPoint[0], self.yPoint[0], 'co', markersize=8)\n",
        "        plt.pause(0.05)\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edUqbZxCxIKW",
        "outputId": "95aca8ac-6479-475a-c15c-838155343484"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "np.random.seed(1000)\n",
        "random.seed(10)\n",
        "\n",
        "reward_func = FrontierRewardFunction(1 / 80)\n",
        "action_space = PolarActionSpace(30)\n",
        "\n",
        "robot = Robot(0, True, False, 'DRL_robot_exploration/DungeonMaps',action_space,reward_func, False)\n",
        "\n",
        "test_action = np.array([0.75, 0.5])\n",
        "print('start')\n",
        "print(robot.robot_position)\n",
        "\n",
        "for i in range(10):\n",
        "  (map, loc), reward, terminal, complete, new_loc, collision, all_map = robot.step(test_action)\n",
        "  print('reward', reward)\n",
        "  print('robot loc', loc)\n",
        "  print(collision)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start\n",
            "[399 295]\n",
            "coll dx 15\n",
            "coll dy 0\n",
            "min_frontier_dist -66.73080248281148\n",
            "paper reward 0.03428571428571429\n",
            "reward -0.8\n",
            "robot loc [384 295]\n",
            "False\n",
            "coll dx 15\n",
            "coll dy 0\n",
            "min_frontier_dist -61.032778078668514\n",
            "paper reward 0.013285714285714286\n",
            "reward -0.8\n",
            "robot loc [369 295]\n",
            "False\n",
            "coll dx 15\n",
            "coll dy 0\n",
            "min_frontier_dist -58.137767414994535\n",
            "paper reward 0.0018571428571428571\n",
            "reward -0.8\n",
            "robot loc [354 295]\n",
            "False\n",
            "coll dx 15\n",
            "coll dy 0\n",
            "collided??\n",
            "reward -1\n",
            "robot loc [354 295]\n",
            "True\n",
            "coll dx 15\n",
            "coll dy 0\n",
            "collided??\n",
            "reward -1\n",
            "robot loc [354 295]\n",
            "True\n",
            "coll dx 15\n",
            "coll dy 0\n",
            "collided??\n",
            "reward -1\n",
            "robot loc [354 295]\n",
            "True\n",
            "coll dx 15\n",
            "coll dy 0\n",
            "collided??\n",
            "reward -1\n",
            "robot loc [354 295]\n",
            "True\n",
            "coll dx 15\n",
            "coll dy 0\n",
            "collided??\n",
            "reward -1\n",
            "robot loc [354 295]\n",
            "True\n",
            "coll dx 15\n",
            "coll dy 0\n",
            "collided??\n",
            "reward -1\n",
            "robot loc [354 295]\n",
            "True\n",
            "coll dx 15\n",
            "coll dy 0\n",
            "collided??\n",
            "reward -1\n",
            "robot loc [354 295]\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO_EJKEoNC6T"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchsummary\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
        "\n",
        "def build_conv_feature_extractor(conv_dims, act):\n",
        "  #Create Conv2D + MaxPool layers\n",
        "  conv_layers = [nn.Conv2d(*conv_dim) if len(conv_dim) == 3 else nn.MaxPool2d(conv_dim) for conv_dim in conv_dims]\n",
        "  total_layers = []\n",
        "\n",
        "  #Add ReLU activations after each conv layer\n",
        "  for layer in conv_layers:\n",
        "    total_layers.append(layer)\n",
        "    if type(layer) == nn.Conv2d:\n",
        "      total_layers.append(act())\n",
        "  return nn.Sequential(*total_layers)\n",
        "  \n",
        "\n",
        "def get_output_shape(model, image_dim):\n",
        "    return model(torch.rand(*(image_dim))).data.shape\n",
        "\n",
        "class RNNActor(nn.Module):\n",
        "  #TODO Determine if the action space allows negative numbers\n",
        "  #Potentially replace tanh with sigmoid\n",
        "  def __init__(self, conv_dims, lstm_hidden, train_length, input_size=(1, 1,84,84), act=nn.ReLU, final_act=nn.Sigmoid):\n",
        "    super(RNNActor, self).__init__()\n",
        "\n",
        "    self.conv_mod = build_conv_feature_extractor(conv_dims, act)\n",
        "    \n",
        "    #Silly way to determine the size going into the RNN\n",
        "    with torch.no_grad():\n",
        "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
        "\n",
        "    print('LSTM Input Size', feature_size)\n",
        "\n",
        "    #Construct LSTM\n",
        "    self.lstm_hidden = lstm_hidden\n",
        "    self.lstm_input = np.prod(list(feature_size)) + 2\n",
        "    self.lstm = nn.LSTM(self.lstm_input, lstm_hidden)\n",
        "    self.linear = nn.Linear(lstm_hidden, 2)\n",
        "    self.train_length = train_length\n",
        "    self.final_act = final_act()\n",
        "\n",
        "  def forward(self, image, positions, lengths, hidden_state=None):\n",
        "    print('sizes')\n",
        "    print(image.size())\n",
        "    print(positions.size())\n",
        "    batch_size = image.size()[1]\n",
        "    seq_length = image.size()[0]\n",
        "    conv = self.conv_mod(image.view((seq_length * batch_size, 1, 84, 84)))\n",
        "    print('COnv out', conv.size())\n",
        "\n",
        "    flat = conv.view(-1).view(seq_length, batch_size, self.lstm_input - 2)\n",
        "    print('sizes')\n",
        "    print(flat.size())\n",
        "    print(positions.size())\n",
        "    state = torch.cat((flat, positions), 2)\n",
        "    print('state size')\n",
        "    print(state.size())\n",
        "    packed = pack_padded_sequence(state, lengths, enforce_sorted=False)\n",
        "    if hidden_state is not None:\n",
        "      states, final_state = self.lstm(packed, hidden_state)\n",
        "    else:\n",
        "      states, final_state = self.lstm(packed)\n",
        "\n",
        "    unpacked, lengths = pad_packed_sequence(states)\n",
        "\n",
        "    final = self.linear(unpacked)\n",
        "    return self.final_act(final), final_state, lengths"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMUxifkjVCJE",
        "outputId": "5618c7dc-e3d6-4784-fbae-c5a56cc118c1"
      },
      "source": [
        "conv_dims = [(1, 32, 8), (32, 64, 4), (2, 2), (64, 64, 3), (64, 512, 7), (2, 2), (512, 64, 1)]\n",
        "\n",
        "lstm_hidden = 512\n",
        "lstm_out = 2\n",
        "train_length = 8\n",
        "\n",
        "rnn = RNNActor(conv_dims, lstm_hidden, train_length).to(device='cuda')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM Input Size torch.Size([1, 64, 49, 49])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8RtwJ4Hhk65",
        "outputId": "bde5e4f7-cbec-4344-a075-037ac345948c"
      },
      "source": [
        "test_batch = torch.rand((train_length, 10, 1, 84, 84)).to(device='cuda')\n",
        "test_positions = torch.rand((train_length, 10, 2)).to(device='cuda')\n",
        "hidden = (torch.zeros((1, 10, lstm_hidden)).to(device='cuda'), torch.zeros((1, train_length, lstm_hidden)).to(device='cuda'))\n",
        "print(hidden[0].size())\n",
        "\n",
        "test, _ = rnn(test_batch, test_positions, [train_length] * 10)\n",
        "test.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10, 512])\n",
            "COnv out torch.Size([80, 64, 49, 49])\n",
            "Flattened COnv Feats torch.Size([8, 10, 153664])\n",
            "Conv Feats w/ Position Size torch.Size([8, 10, 153666])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 10, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgxUtoeMJ8Pa"
      },
      "source": [
        "def build_dense_regression(linear_dims, act, final_act=None):\n",
        "  linear_layers = [nn.Linear(*linear_dim)  for linear_dim in linear_dims]\n",
        "  activations = [act() for layer in range(len(linear_layers) - 1)]\n",
        "  if final_act is not None:\n",
        "    activations.append(final_act)\n",
        "  else:\n",
        "    activations.append(nn.Identity())\n",
        "  return nn.Sequential(*[val for tup in zip(*[linear_layers, activations]) for val in tup]\n",
        ")\n",
        "\n",
        "class CNNCritic(nn.Module):\n",
        "  def __init__(self, conv_dims, fc_dims, input_size=(1, 1,84,84), conv_act=nn.ReLU, fc_act=nn.ReLU):\n",
        "    super(CNNCritic, self).__init__()\n",
        "    self.conv_mod = build_conv_feature_extractor(conv_dims, conv_act)\n",
        "\n",
        "    #Silly way to determine the size going into the RNN\n",
        "    with torch.no_grad():\n",
        "      feature_size = get_output_shape(self.conv_mod, input_size)\n",
        "\n",
        "    #Add 4 for action + position\n",
        "    feature_size = np.prod(list(feature_size)) + 4\n",
        "    first_output = fc_dims[0][0]\n",
        "    fc_dims.insert(0, (feature_size, first_output))\n",
        "\n",
        "    self.fc = build_dense_regression(fc_dims, fc_act)\n",
        "    print('regressor extract critic', self.fc)\n",
        "    self.fc_dims = feature_size\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self, map, positions, action):\n",
        "    print('sizes')\n",
        "    print(map.size())\n",
        "    print(positions.size())\n",
        "    batch_size = map.size()[1]\n",
        "    seq_length =  map.size()[0]\n",
        "    conv = self.conv_mod(map.view((seq_length * batch_size, 1, 84, 84)))\n",
        "    print('COnv out', conv.size())\n",
        "\n",
        "    flat = conv.view(-1).view(seq_length, batch_size, self.fc_dims - 4)\n",
        "    print('sizes')\n",
        "    print(flat.size())\n",
        "    print(positions.size())\n",
        "    print(action.size())\n",
        "    total_feats = torch.cat((flat, positions, action), 2)\n",
        "    return self.fc(total_feats)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4Q7eTJfcJ7a",
        "outputId": "bcf864ac-3ba8-41e7-951d-6da52eb54b59"
      },
      "source": [
        "linear_dims = [(256, 128), (128, 1)]\n",
        "conv_dims = [(1, 32, 8), (32, 64, 4), (2, 2), (64, 64, 3), (64, 512, 7), (2, 2), (512, 64, 1)]\n",
        "\n",
        "critic = CNNCritic(conv_dims, linear_dims)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "regressor extract critic Sequential(\n",
            "  (0): Linear(in_features=12548, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (5): Identity()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFMjDGz1N958"
      },
      "source": [
        "\"\"\" Learn a policy using DDPG for the reach task\"\"\"\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import MultivariateNormal\n",
        "from torch.nn import MSELoss\n",
        "import random\n",
        "from skimage.transform import resize\n",
        "import itertools\n",
        "from itertools import zip_longest\n",
        "\n",
        "import gym\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import time\n",
        "\n",
        "# TODO: A function to soft update target networks\n",
        "def weighSync(target_model, source_model, tau=0.001):\n",
        "  for (target, src) in zip(target_model.parameters(), source_model.parameters()):\n",
        "    target.data = (1-tau) * target.data + tau * src.data \n",
        "\n",
        "def grouper(iterable, n, fillvalue=None):\n",
        "  '''Collect data into fixed-length chunks or blocks'''\n",
        "  # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
        "  args = [iter(iterable)] * n\n",
        "  return zip_longest(*args, fillvalue=fillvalue)\n",
        "\n",
        "# TODO: Write the ReplayBuffer\n",
        "class Replay():\n",
        "    def __init__(self, buffer_size, init_episodes, max_episode_length, sequence_length, action_dim, env, env_width, env_height):\n",
        "        \"\"\"\n",
        "        A function to initialize the replay buffer.\n",
        "\n",
        "        param: init_length : Initial number of transitions to collect\n",
        "        param: state_dim : Size of the state space\n",
        "        param: action_dim : Size of the action space\n",
        "        param: env : gym environment object\n",
        "        \"\"\"\n",
        "        self.buffer = [{}] * buffer_size\n",
        "        self.noise = MultivariateNormal(torch.zeros(2), torch.diag(torch.tensor([0.05, 0.05])))\n",
        "        self.sequence_length = sequence_length\n",
        "        self.max_episode_length = max_episode_length\n",
        "        self.env = env\n",
        "        state = self.env.reset()\n",
        "        self.env_width = env_width\n",
        "        self.env_height = env_height\n",
        "        self.buffer_idx = 0\n",
        "        self.total_steps = 0\n",
        "        last_state = env.reset()\n",
        "        init_policy = lambda map, pos, lengths: (torch.from_numpy(np.random.uniform(0.1, 0.9, (2,))).unsqueeze(0).unsqueeze(1), None, [1])\n",
        "        self.full_buffer = False\n",
        "        for episode in range(init_episodes):\n",
        "          episode = self.generate_episode(init_policy)\n",
        "\n",
        "    def generate_episode(self, policy):\n",
        "      episode = []\n",
        "      map, position = self.env.reset()\n",
        "      position = position.astype(np.float64)\n",
        "      map = resize(map, (84, 84))\n",
        "      map = ((map - 127) / 255) * 2\n",
        "      # print('position', position)\n",
        "\n",
        "      position[0] = position[0]/ 640.0\n",
        "      position[1] = position[1] / 480.0\n",
        "      last_map = torch.from_numpy(map).float()\n",
        "      last_position = torch.from_numpy(position).float()\n",
        "      # print('start position')\n",
        "      # print(last_position)\n",
        "      terminal = False\n",
        "\n",
        "      total_reward = 0\n",
        "      last_state = None\n",
        "      for i in range(self.max_episode_length):\n",
        "        if last_state is None:\n",
        "          action, last_state, lengths = policy(last_map.unsqueeze(0).unsqueeze(0).to(device='cuda'), last_position.unsqueeze(0).unsqueeze(0).to(device='cuda'), [1])\n",
        "        else:\n",
        "          # print('map size')\n",
        "          # print(last_map.size())\n",
        "          action, last_state, lengths = policy(last_map.unsqueeze(0).unsqueeze(0).to(device='cuda'), last_position.unsqueeze(0).unsqueeze(0).to(device='cuda'), [1], last_state)\n",
        "      \n",
        "      \n",
        "        action = action.cpu().squeeze(0).squeeze(1) + torch.clamp(self.noise.sample(), -0.25, 0.25) #TD3 requires noise to be clamped\n",
        "\n",
        "        action_np = action.detach().numpy().flatten()\n",
        "        # print('action_np')\n",
        "        # print(action_np)\n",
        "        action_np[0] = np.clip(action_np[0], 0, 1)\n",
        "        action_np[1] = np.clip(action_np[1], 0, 1)\n",
        "\n",
        "    \n",
        "\n",
        "        (map, loc), reward, terminal, complete, new_loc, collision, all_map = self.env.step(action_np)\n",
        "        map = resize(map, (84, 84))\n",
        "        map = ((map - 127) / 255) * 2\n",
        "        # print('unnormalized loc', loc)\n",
        "        loc = loc.astype(np.float64)\n",
        "        loc[0] = loc[0] / 640.0\n",
        "        loc[1] = loc[1] / 480.0\n",
        "\n",
        "        map_tensor = torch.from_numpy(map).float()\n",
        "        position_tensor = torch.from_numpy(loc).float()\n",
        "        # print('single position', position_tensor.size())\n",
        "        # print(position_tensor)\n",
        "        reward_tensor = torch.tensor(reward).float()\n",
        "        episode.append({'map': map_tensor, 'position': position_tensor, 'reward': reward_tensor, 'action': action})\n",
        "        last_map = map_tensor\n",
        "        last_position = position_tensor\n",
        "        total_reward += reward\n",
        "        if terminal:\n",
        "          break\n",
        "      # print('episode', episode)\n",
        "      sequences = self.episode_to_sequences(episode)\n",
        "      for sequence in sequences:\n",
        "        self.buffer[self.buffer_idx] = sequence\n",
        "        self.buffer_idx = (self.buffer_idx + 1) % len(self.buffer)\n",
        "        if self.buffer_idx == 0:\n",
        "          full_buffer = True\n",
        "\n",
        "      return reward\n",
        "    \n",
        "    def episode_to_sequences(self, episode):\n",
        "      sequences = []\n",
        "      last_idx = 0\n",
        "      for i in np.arange(self.sequence_length, len(episode), self.sequence_length):\n",
        "        window = episode[last_idx:i]\n",
        "        map_tensor = torch.cat([torch.unsqueeze(data['map'], 0) for data in window], 0)\n",
        "        position_tensor = torch.cat([torch.unsqueeze(data['position'], 0) for data in window], 0)\n",
        "        # print('position tensor', position_tensor)\n",
        "        reward_tensor = torch.cat([torch.unsqueeze(data['reward'], 0) for data in window], 0)\n",
        "        action_tensor = torch.cat([torch.unsqueeze(data['action'], 0) for data in window], 0)\n",
        "        sequences.append({'maps':map_tensor, 'positions': position_tensor, 'rewards': reward_tensor, 'actions':action_tensor, 'len':len(window)})\n",
        "        last_idx = i\n",
        "\n",
        "      window = episode[last_idx:]\n",
        "      map_tensor = torch.cat([torch.unsqueeze(data['map'], 0) for data in window], 0)\n",
        "      position_tensor = torch.cat([torch.unsqueeze(data['position'], 0) for data in window], 0)\n",
        "      # print('position tensor', position_tensor)\n",
        "      reward_tensor = torch.cat([torch.unsqueeze(data['reward'], 0) for data in window], 0)\n",
        "      action_tensor = torch.cat([torch.unsqueeze(data['action'], 0) for data in window], 0)\n",
        "      sequences.append({'maps':map_tensor, 'positions': position_tensor, 'rewards': reward_tensor, 'actions':action_tensor, 'len':len(window)})\n",
        "      return sequences\n",
        "    \n",
        "\n",
        "    #TODO: Complete the function\n",
        "    def buffer_sample(self, N):\n",
        "        \"\"\"\n",
        "        A function to sample N points from the buffer\n",
        "        param: N : Number of samples to obtain from the buffer\n",
        "        \"\"\"\n",
        "        # print('buffer idx', self.buffer_idx)\n",
        "        if self.full_buffer:\n",
        "          samples = random.sample(self.buffer, N)\n",
        "        else:\n",
        "          samples = random.sample(self.buffer[:self.buffer_idx], N)\n",
        "\n",
        "        return self.batchify(samples)\n",
        "\n",
        "    def batchify(self, samples):\n",
        "      \n",
        "      map_sequences = []\n",
        "      position_sequences = []\n",
        "      reward_sequences = []\n",
        "      action_sequences = []\n",
        "      seq_lens = []\n",
        "\n",
        "      for sequence in samples:\n",
        "        # print('sequence')\n",
        "        # print(sequence)\n",
        "\n",
        "        map_sequences.append(sequence['maps'])\n",
        "        # print('batchify')\n",
        "        # print('positions', sequence['positions'].size())\n",
        "        # print('rewards', sequence['rewards'].size())\n",
        "        # print('actions', sequence['actions'].size())\n",
        "        # print('maps', sequence['maps'].size())\n",
        "        position_sequences.append(sequence['positions'])\n",
        "        reward_sequences.append(sequence['rewards'])\n",
        "        action_sequences.append(sequence['actions'])\n",
        "        seq_lens.append(sequence['len'])\n",
        "\n",
        "      map_pad = pad_sequence(map_sequences).to(device='cuda').float()\n",
        "      pos_pad = pad_sequence(position_sequences).to(device='cuda').float()\n",
        "      reward_pad = pad_sequence(reward_sequences).to(device='cuda').float()\n",
        "      action_pad = pad_sequence(action_sequences).to(device='cuda').float()\n",
        "      seqs = seq_lens\n",
        "\n",
        "      return map_pad, pos_pad, reward_pad, action_pad, seqs\n",
        "\n",
        "      \n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViFylKNVQgZ1"
      },
      "source": [
        "class TD3():\n",
        "    def __init__(\n",
        "            self,\n",
        "            env,\n",
        "            replay,\n",
        "            conv_dims,\n",
        "            lstm_dim,\n",
        "            linear_dims,\n",
        "            sequence_length,\n",
        "            critic_lr=3e-4,\n",
        "            actor_lr=3e-4,\n",
        "            gamma=0.99,\n",
        "            batch_size=100,\n",
        "            buffer_size=10000,\n",
        "            init_episodes=1000,\n",
        "            max_episode_length=300\n",
        "\n",
        "    ):\n",
        "        \"\"\"\n",
        "        param: env: An gym environment\n",
        "        param: action_dim: Size of action space\n",
        "        param: state_dim: Size of state space\n",
        "        param: critic_lr: Learning rate of the critic\n",
        "        param: actor_lr: Learning rate of the actor\n",
        "        param: gamma: The discount factor\n",
        "        param: batch_size: The batch size for training\n",
        "        \"\"\"\n",
        "        self.gamma = gamma\n",
        "        self.batch_size = batch_size\n",
        "        self.sequence_length = sequence_length\n",
        "        reward_func = FrontierRewardFunction(1 / 80)\n",
        "        action_space = PolarActionSpace(30)\n",
        "        self.env = Robot(0, True, False, 'DRL_robot_exploration/DungeonMaps', action_space, reward_func, False)\n",
        "        # self.env = env\n",
        "\n",
        "        self.actor = RNNActor(conv_dims, lstm_dim, sequence_length).to(device='cuda') #TODO conv_dims, lstm_hidden, train_length\n",
        "        self.actor_target = copy.deepcopy(self.actor).to(device='cuda') \n",
        "\n",
        "        self.critic1 = CNNCritic(conv_dims, linear_dims).to(device='cuda') #TODO conv_dims, fc_dims\n",
        "        self.critic1_target = copy.deepcopy(self.critic1).to(device='cuda')\n",
        "\n",
        "        self.critic2 = CNNCritic(conv_dims, linear_dims).to(device='cuda')\n",
        "        self.critic2_target = copy.deepcopy(self.critic2).to(device='cuda')\n",
        "\n",
        "        self.optimizer_actor = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
        "        self.optimizer_critic1 = optim.Adam(self.critic1.parameters(), lr=critic_lr)\n",
        "        self.optimizer_critic2 = optim.Adam(self.critic2.parameters(), lr=critic_lr)\n",
        "        # self.replay = Replay(buffer_size, init_episodes, max_episode_length, sequence_length, action_dim, env, env_width, env_height)\n",
        "        # self.replay = Replay(10000, 100, 300, 8, 2, robot, 640, 480)\n",
        "        self.replay = replay\n",
        "\n",
        "    def update_target_networks(self):\n",
        "        \"\"\"\n",
        "        A function to update the target networks\n",
        "        \"\"\"\n",
        "        weighSync(self.actor_target, self.actor)\n",
        "        weighSync(self.critic1_target, self.critic1)\n",
        "        weighSync(self.critic2_target, self.critic2)\n",
        "\n",
        "    def update_network(self, iter):\n",
        "        \"\"\"\n",
        "        A function to update the function just once\n",
        "        \"\"\"\n",
        "        self.optimizer_critic1.zero_grad() \n",
        "        self.optimizer_critic2.zero_grad()\n",
        "\n",
        "        reward = self.replay.generate_episode(self.actor) #Generate episode with current actor and store into replay buffer\n",
        "        maps, positions, rewards, actions, lengths = self.replay.buffer_sample(self.batch_size)\n",
        "        # print('actions size',actions.size())\n",
        "        actions = actions.squeeze(2)\n",
        "\n",
        "        with torch.no_grad(): #Save gpu vram\n",
        "            target_action, _, _ = self.actor_target(maps, positions, lengths)\n",
        "            target_action = target_action.squeeze(2)\n",
        "            #Should be (seq_len, batch_size, 2)\n",
        "            #Should be (seq_len, batch_size, 1)\n",
        "            # print('target action', target_action.size())\n",
        "            crit1 = self.critic1_target(maps, positions, target_action)\n",
        "            crit2 = self.critic2_target(maps, positions, target_action)\n",
        "            # print('crit', crit1.size())\n",
        "            # print('rewards', rewards.size())\n",
        "        ys = rewards + self.gamma * torch.minimum(crit1.squeeze(2), crit2.squeeze(2)) #Use the minimum critic values\n",
        "\n",
        "        # print('updating')\n",
        "        # print('inputs')\n",
        "        # print(ys)\n",
        "        # print(maps)\n",
        "        # print(positions)\n",
        "        # print(actions)\n",
        "        # print(lengths)\n",
        "\n",
        "        qs1 = self.critic1(maps, positions, actions).squeeze(2)\n",
        "        #should be (seq_len, batch, 1)\n",
        "        # print('qs1', qs1.size())\n",
        "        #should be (seq_len, batch, 1)\n",
        "        # print('ys', ys.size(), 'qs1', qs1.size())\n",
        "        critic1_loss = ((ys - qs1)**2).sum() / (self.sequence_length * self.batch_size)\n",
        "        critic1_loss.backward(retain_graph=True)\n",
        "        self.optimizer_critic1.step()\n",
        "\n",
        "        qs2 = self.critic2(maps, positions, actions).squeeze(2)\n",
        "        #should be (seq_len, batch, 1)\n",
        "        # print('qs2', qs2.size())\n",
        "        #should be (seq_len, batch, 1)\n",
        "        # print('ys', ys.size(), 'qs2', qs2.size())\n",
        "        critic2_loss = ((ys - qs2)**2).sum() / (self.sequence_length * self.batch_size)\n",
        "        critic2_loss.backward()\n",
        "        self.optimizer_critic2.step()\n",
        "\n",
        "        if iter % 2 == 0: #Only update actor and target networks every two updates\n",
        "            self.optimizer_actor.zero_grad()\n",
        "            new_act, _, _ = self.actor(maps, positions, lengths)\n",
        "            # print('new_act', new_act.size())\n",
        "            qs = self.critic1(maps, positions, new_act)\n",
        "            actor_loss = qs.sum() / (self.sequence_length * self.batch_size)\n",
        "            (-actor_loss).backward()\n",
        "            self.optimizer_actor.step()\n",
        "\n",
        "            self.update_target_networks()\n",
        "\n",
        "        if iter%100==0:\n",
        "            print('reward', reward)\n",
        "\n",
        "    def train(self, num_steps):\n",
        "        \"\"\"\n",
        "        Train the policy for the given number of iterations\n",
        "        :param num_steps:The number of steps to train the policy for\n",
        "        \"\"\"\n",
        "\n",
        "        i = 0\n",
        "        start = time.time()\n",
        "        while i < num_steps:\n",
        "            i += 1\n",
        "            self.update_network(i)\n",
        "            # if i % 100 == 0:\n",
        "            #     print('step {}'.format(i))\n",
        "            #     print('since start {}'.format(time.time() - start))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjFt7JBRQVyT"
      },
      "source": [
        "reward_func = FrontierRewardFunction(1 / 14000)\n",
        "action_space = PolarActionSpace(15)\n",
        "\n",
        "robot = Robot(0, True, False, 'DRL_robot_exploration/DungeonMaps',action_space,reward_func, False)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCg-zeJMGV5U",
        "outputId": "d76512b0-2872-485d-d4d2-02487e771528"
      },
      "source": [
        "replay = Replay(1000, 100, 300, 8, 2, robot, 640, 480)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n",
            "collided??\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "ieHIP9WFQ0t5",
        "outputId": "4f31d48b-4229-4ab0-c6ae-e294b2b6e838"
      },
      "source": [
        "linear_dims = [(256, 128), (128, 1)]\n",
        "conv_dims = [(1, 32, 8), (32, 64, 4), (2, 2), (64, 64, 3), (64, 512, 7), (2, 2), (512, 64, 1)]\n",
        "lstm_hidden = 512\n",
        "lstm_out = 2\n",
        "train_length = 8\n",
        "td3 = TD3(robot, replay, conv_dims, lstm_hidden, linear_dims, 8, batch_size=10)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM Input Size torch.Size([1, 64, 14, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-292ae0e4e77b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtd3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTD3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrobot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-65-81fdf173f3bd>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, replay, conv_dims, lstm_dim, linear_dims, sequence_length, critic_lr, actor_lr, gamma, batch_size, buffer_size, init_episodes, max_episode_length)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# self.env = env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNNActor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#TODO conv_dims, lstm_hidden, train_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# Flattens params (on CUDA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cudnn_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                         self.batch_first, bool(self.bidirectional))\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbQtpI5A7l2D",
        "outputId": "70fca43e-2a88-4327-f449-6f90b76140f7"
      },
      "source": [
        "print('init seqs', td3.replay.buffer_idx)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init seqs 519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hsCYdcqISY73",
        "outputId": "a745cea6-ce48-4c55-d834-71fd768bea2d"
      },
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n",
        "td3.train(50000)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sizes\n",
            "torch.Size([1, 1, 84, 84])\n",
            "torch.Size([1, 1, 2])\n",
            "COnv out torch.Size([1, 64, 14, 14])\n",
            "sizes\n",
            "torch.Size([1, 1, 12544])\n",
            "torch.Size([1, 1, 2])\n",
            "state size\n",
            "torch.Size([1, 1, 12546])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-4793354c755c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtd3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-81fdf173f3bd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_steps)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;31m# if i % 100 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m#     print('step {}'.format(i))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-81fdf173f3bd>\u001b[0m in \u001b[0;36mupdate_network\u001b[0;34m(self, iter)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_critic2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Generate episode with current actor and store into replay buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mmaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# print('actions size',actions.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-5270e29dee94>\u001b[0m in \u001b[0;36mgenerate_episode\u001b[0;34m(self, policy)\u001b[0m\n\u001b[1;32m     77\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_episode_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlast_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m           \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_position\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m           \u001b[0;31m# print('map size')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-d6fb8f089b78>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image, positions, lengths, hidden_state)\u001b[0m\n\u001b[1;32m     63\u001b[0m       \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m       \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0munpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0;32m--> 585\u001b[0;31m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    586\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KSbEc30VzFm"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 37,
      "outputs": []
    }
  ]
}